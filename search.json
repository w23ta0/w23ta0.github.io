[{"categories":["人工智能","编码工具"],"content":"在代码编辑器与AI技术深度融合的今天，Cursor 0.48版本以多任务并行处理、个性化交互为核心，通过一系列创新功能重新定义了开发者的工作流。本文将从功能革新、用户体验优化及未来潜力三个维度，深度解析这一版本的突破性价值。 核心功能革新：效率跃迁的关键 1. 聊天标签：并行任务的革命性突破 多线程工作流：通过快捷键 ⌘N 可快速创建独立聊天标签，实现代码重构、API查询等任务的并行处理。例如，可同时在标签A让AI优化算法，标签B询问单元测试建议。 可视化管理：标签上的橙色圆点提示机制，确保开发者能直观捕捉任务进展，避免上下文切换干扰。 场景价值：对于需要频繁切换任务的全栈开发者，效率提升可达30%以上（基于Cursor官方测试数据）。 2. 模式系统2.0：从标准化到个性化 模式重构： Ask模式：默认集成代码库搜索功能，@Codebase指令被自然语言查询取代 Manual模式（原Edit模式）：专注手动控制的精准交互场景 Agent模式：持续保留的自动化任务处理入口 自定义模式（Beta）：开发者可创建专属模式，例如： 设定专属快捷键（如⌘K触发测试模式） 配置特定工具组合（如禁用搜索的\"专注编码模式\"） 通过Settings → Features → Chat → Custom modes进行配置 快捷键适配：默认模式绑定⌘I，支持侧边栏快速切换 3. 声音通知：注意力管理的智能助手 场景痛点解决：当AI任务完成时，系统通过声音提示（设置路径：Settings → Features → Chat → Play sound on finish）主动通知开发者 用户价值：减少开发者因等待任务而进行的无意义页面刷新，据内测反馈可降低25%的无效操作 体验优化：细节决定效率 1. 长上下文优化 智能分段机制：当聊天历史接近上下文窗口限制时，系统自动建议创建新聊天窗口 技术价值：保持LLM推理质量，避免因token过载导致的响应质量下降 2. 成本透明化 使用追踪：历史记录中可查看每次交互的token消耗及成本分类 企业级价值：对于团队用户，支持生成月度使用报告，优化预算分配 3. 索引性能飞跃 团队协作优化：大型代码库索引速度提升40%，搜索响应时间缩短至\u003c2秒 技术实现：通过改进分布式索引算法，支持万级文件项目的实时导航 系统级改进：为专业开发者而生 1. 界面与交互 侧边栏统一化：移除垂直布局选项，采用统一水平侧边栏提升跨设备一致性 快捷键微调： 拒绝所有差异改为Cmd+Shift+Backspace，降低误触风险 新增Cmd+L侧边栏快速切换键 2. 开发者友好性增强 MCP提示系统：自动检测并提示启用Model Control Protocol服务器，确保最佳性能 错误信息升级：MCP配置错误时提供带解决方案的诊断代码（如E048-MCP-02） 3. 稳定性保障 功能取舍：移除不稳定的自动运行提示功能，确保核心体验流畅 跨平台优化：Windows用户MCP连接稳定性提升至与macOS同等水平 未来潜力：AI编码工具的进化方向 1. 个性化定制深化 模式市场：未来可能开放社区模式共享平台，开发者可下载/贡献预设模式 AI辅助配置：通过分析用户行为推荐最佳模式组合 2. 团队协作场景 知识库集成：计划与Confluence等工具联动，实现团队文档智能引用 协作模式：允许多人实时编辑同一聊天会话，支持代码审查协同 3. 成本控制智能化 预算警报：当月度使用接近阈值时主动触发优化建议 动态模型选择：根据任务类型自动切换成本效益最优的LLM 总结：开发者效率的下一个里程碑 Cursor 0.48版本通过任务并行化、交互个性化、成本透明化三大支柱，将AI辅助开发推向新高度。其价值不仅在于功能创新，更在于对开发者工作流的深刻理解： 即时价值：聊天标签可减少30%的上下文切换时间 长期价值：自定义模式系统为不同开发场景提供专属解决方案 商业价值：成本追踪功能使企业用户可节省15%-20%的AI调用成本 对于追求极致效率的开发者，升级至0.48版本已是必然选择。而Cursor团队对稳定性的执着（如主动移除不成熟功能），更让我们对其后续版本充满期待。 本文引用来源标注： Cursor官方Changelog对0.48版本的描述 LINUX DO对0.48版本的中文解读 53AI对0.48版本功能的深度拆解 知乎专栏对Cursor产品的技术分析 Cursor 0.47版本的技术演进背景 ","date":"2025-03-25","objectID":"/posts/1fb1842/:0:0","tags":["Cursor","AI","编码工具"],"title":"Cursor 0.48 版本深度解析：AI 编码工具的效率革命","uri":"/posts/1fb1842/"},{"categories":["人工智能","MCP"],"content":"近年来，随着 AI 模型（如 GPT-4、Claude 等）的迅速发展，如何高效地将 AI 与企业级系统及各类第三方服务进行集成，成为了开发者和企业亟待解决的难题。传统方式依赖于单次的 Function Calling 实现模型与 API 的交互，但在复杂场景下，上下文传递不足以及各个服务之间的碎片化实现，使得全链路自动化成为难题。为了解决这一痛点，Model Context Protocol（MCP） 应运而生，为我们提供了一种全新的开放标准。 1. 背景与技术挑战 在过去的开发实践中，主要存在以下几个挑战： 碎片化的接口调用：各个平台与服务采用不同的 API 设计，导致集成工作重复且效率低下。 上下文信息难以贯通：传统 Function Calling 难以在多步任务中维持连续的上下文，限制了 AI Agent 的自主决策能力。 重复造轮子问题：开发者需要为每个服务单独编写集成代码，资源浪费严重，且系统维护困难。 企业在面对敏感数据和安全要求时，这些问题尤为突出。迫切需要一种开放、通用且具有共识的协议标准，来统一各类服务的能力描述和调用方式。 2. MCP 的技术突破 MCP 的设计理念类似于电子设备中的 Type-C 接口，它的核心优势包括： 统一标准化能力描述 MCP 通过明确描述各项服务的功能、输入参数与返回格式，为 AI Agent 构建了一份详细的“能力清单”，使不同服务之间可以无缝协作。 上下文传递与自动化决策 借助 MCP，AI Agent 能够跨服务维持上下文信息，实现从单次函数调用到全自动任务执行的转变。这使得 AI 系统不仅仅提供建议，而是能够在多步任务中自主决策并执行。 开放生态与复用性 标准化协议促使各大服务商和开源社区共同构建生态系统，开发者无需重复造轮子，可以直接使用现有的 MCP 服务，显著降低了集成门槛和开发成本。 3. MCP 与传统 Function Calling / AI Agent 的对比 在理解 MCP 的优势之前，我们先来明确传统技术之间的差异： Function Calling：主要用于将 AI 模型的请求转化为单次 API 调用，适用于简单任务，但难以应对复杂场景。 AI Agent：在 Function Calling 基础上增加了决策逻辑，实现一定程度的自动化；然而，上下文传递与多步决策依旧存在局限。 MCP：在上述基础上，通过标准化描述和上下文管理，支持跨系统、跨服务的连续任务执行，实现了真正的全链路自动化。 4. MCP 架构解析 MCP 的架构主要包括以下四个核心组件： MCP Hosts：指运行 AI 模型的应用程序，例如 Cursor、Claude Desktop 等。 MCP Clients：在 Host 内部维护与 MCP Server 的 1:1 通信，负责请求转发和响应处理。 MCP Servers：作为协议的核心，MCP Server 提供各项服务的能力描述、工具列表以及上下文信息，充当 AI Agent 与各类服务之间的桥梁。 Local Data Sources \u0026 Remote Services：分别对应本地数据和远程 API，提供实际的数据支撑和功能实现。 这种设计使得不同服务可以在 MCP 标准下互通，AI Agent 能够根据任务需求，自动选择并调用合适的服务，实现多系统间的无缝集成。 5. 示例代码解读 以下代码展示了如何基于 MCP 实现一个 GitHub 集成服务。该示例定义了搜索仓库、搜索 Issue 以及创建 Issue 的能力，并通过标准化的接口描述完成了与 GitHub API 的交互。 import { z } from 'zod'; import { Server, ListToolsRequestSchema, CallToolRequestSchema, StdioServerTransport } from 'mcp-sdk'; import * as repository from './repository'; import * as issues from './issues'; import * as search from './search'; const VERSION = '1.0.0'; const server = new Server( { name: \"github-mcp-server\", version: VERSION }, { capabilities: { tools: {} } } ); // 定义工具列表，告知 AI Agent 可用的功能 server.setRequestHandler(ListToolsRequestSchema, async () =\u003e { return { tools: [ { name: \"search_repositories\", description: \"搜索 GitHub 仓库\", inputSchema: repository.SearchRepositoriesSchema, }, { name: \"create_issue\", description: \"在 GitHub 仓库中创建 Issue\", inputSchema: issues.CreateIssueSchema, }, { name: \"search_issues\", description: \"搜索 GitHub Issue 和 Pull Request\", inputSchema: search.SearchIssuesSchema, } ], }; }); // 处理具体工具调用请求 server.setRequestHandler(CallToolRequestSchema, async (request) =\u003e { if (!request.params.arguments) { throw new Error(\"缺少必要的参数\"); } switch (request.params.name) { case \"search_repositories\": { const args = repository.SearchRepositoriesSchema.parse(request.params.arguments); const results = await repository.searchRepositories(args.query, args.page, args.perPage); return { content: [{ type: \"text\", text: JSON.stringify(results, null, 2) }] }; } case \"create_issue\": { const args = issues.CreateIssueSchema.parse(request.params.arguments); const issue = await issues.createIssue(args.owner, args.repo, args.options); return { content: [{ type: \"text\", text: JSON.stringify(issue, null, 2) }] }; } case \"search_issues\": { const args = search.SearchIssuesSchema.parse(request.params.arguments); const results = await search.searchIssues(args); return { content: [{ type: \"text\", text: JSON.stringify(results, null, 2) }] }; } default: throw new Error(`未知的工具：${request.params.name}`); } }); async function runServer() { const transport = new StdioServerTransport(); await server.connect(transport); console.error(\"GitHub MCP Server 已启动，通过 stdio 进行通信\"); } runServer().catch((error) =\u003e { console.error(\"启动服务器时发生致命错误：\", error); process.exit(1); }); 上述代码充分展示了 MCP 如何通过标准化协议描述服务能力，并在 AI Agent 的请求下自动调用相应的 API，从而实现跨服务的任务自动化。 6. 实际应用与生态构建 基于 MCP 的开放标准，当前已有越来越多的第三方平台和开源社区开始提供 MCP 服务器实现，典型应用场景包括： 企业级自动化运维：通过整合本地日志、数据库查询等功能，实现从问题监控到自动化故障修复的闭环管理。 跨平台工具集成：如 GitHub、Slack、AWS、Google Calendar 等服务均已有对应的 MCP 实现，方便开发者快速构建多平台协同的 AI Agent。 生态系统构建：统一的接口标准有助于降低各服务之间的集成难度，促进企业、开发者与开源社区之间的协同创新。 7. 展望与思考 从技术演进角度看，MCP 的推出标志着 AI 应用集成进入了全新的阶段。未来，我们有理由相信： 上下文","date":"2025-03-08","objectID":"/posts/9fvdvwz1/:0:0","tags":["AI","MCP","技术","Agent","Function Calling"],"title":"MCP：从 Function Calling 到 AI Agent 的技术演进与生态构建","uri":"/posts/9fvdvwz1/"},{"categories":["人工智能","AI Agent"],"content":"AI Agent 是什么？ AI Agent 是一个人工智能的概念，它是由多个组成部分（包括智能模型和自动化工具）组合实现的。具体来说，AI Agent 通常包含以下几个核心要素： 1. 智能模型（Intelligent Models） 这些模型通常是负责感知、决策和学习的核心。例如，大语言模型（如 GPT-4）、深度神经网络、强化学习模型等，都可以作为智能模型的组成部分。它们使得 AI Agent 能够处理复杂的任务，如语言理解与生成、图像识别、模式识别、决策推理等。 智能模型赋予 AI Agent 一定的“智能”，使它能够根据环境变化作出相应的决策，模拟人类的推理和决策过程。 2. 自动化工具（Automation Tools） 自动化工具用于执行实际的任务和操作，例如工作流自动化、任务管理和执行等。自动化工具（如 n8n、Make、Zapier 等）帮助 AI Agent 自动执行任务，如发送邮件、更新数据库、控制硬件、触发其他应用等。 这些工具通常提供的是无代码或低代码的方式，允许用户方便地创建和管理工作流，用以连接不同的系统和服务。 3. 环境感知与决策执行 AI Agent 需要通过感知层（传感器、API接口等）收集外部环境信息（例如传感器数据、用户输入等）。然后，它将这些信息与智能模型相结合，做出相应的决策，并通过自动化工具执行操作。这样，AI Agent 能够根据环境变化自主作出反应。 总结 AI Agent 是一种综合性的智能系统，由 智能模型（如大语言模型、深度学习模型等）和 自动化工具（如工作流自动化平台）组成。它通过智能模型进行决策、感知和学习，通过自动化工具执行具体任务。 例如，虚拟助手（如 Siri、Google Assistant）就是一个典型的 AI Agent，它使用大语言模型来理解用户输入（语言理解和生成），并通过自动化工具（如连接日程安排、发送消息等）执行任务。 ","date":"2025-03-08","objectID":"/posts/nhjiemn7/:0:0","tags":["AI Agent","人工智能","自动化","智能模型"],"title":"AI Agent 概念解析","uri":"/posts/nhjiemn7/"},{"categories":["人工智能","多模态模型"],"content":"引言 随着人工智能（AI）技术的不断发展，传统的大语言模型（LLM）虽然在文本处理方面取得了突破性进展，但面对图像、视频、音频等多模态数据时，单一模态的 AI 仍然存在局限性。为此，多模态（Multimodal）模型 和 混合模型（Hybrid Models） 应运而生，它们能够同时处理多种数据形式，实现更丰富的智能交互。 本篇文章将介绍 多模态与混合模型的概念、技术原理、主流模型以及实际应用场景，并探讨未来的发展趋势。 什么是多模态与混合模型？ 多模态模型是一类能够同时处理文本、图像、音频、视频等不同类型数据的人工智能系统。例如，GPT-4V 可以理解图像中的内容并回答相关问题，而 Whisper 则可以将音频转换为文本。 混合模型则是指结合不同架构（如 Transformer、CNN、RNN）或不同数据类型的 AI 模型，增强跨领域学习能力。例如，OpenAI 的 DALL·E 结合了文本生成和图像生成能力，使得用户可以通过文本指令生成高质量图像。 主要技术原理 多模态 AI 的核心在于 跨模态数据表示与融合，主要采用以下几种技术： 联合表示学习（Joint Representation Learning） 直接将不同模态的数据映射到相同的特征空间，例如 CLIP 通过共享的嵌入空间学习文本和图像之间的关系。 对齐（Alignment） 通过训练模型来建立不同模态之间的联系，例如 GPT-4V 能够理解图像中的对象并生成相应的文本描述。 生成（Generation） 让 AI 能够基于输入模态生成新内容，如 DALL·E 能够根据文本描述生成图像。 转换（Transformation） 允许不同模态之间进行转换，例如 Whisper 可将语音转换为文本，而 Text-to-Speech（TTS）可以将文本转换为语音。 主要应用场景 1. 视觉与文本结合 📷 AI 视觉理解 多模态 AI 在计算机视觉领域的应用主要包括： 智能问答（如 GPT-4V、Qwen-VL）：用户上传图片，AI 识别并提供解释。 医学影像分析（如 Med-PaLM）：辅助医生进行医学影像诊断，如 X 光、CT 扫描分析。 自动字幕生成（如 Whisper + GPT）：在短视频或会议记录中，自动为视频添加字幕。 2. 音频与文本结合 🎙️ 语音识别与生成 语音转文本（ASR）：如 OpenAI Whisper、讯飞星火，支持多语言语音转录。 文本转语音（TTS）：如 VALL-E、科大讯飞的 AI 语音合成，实现自然的 AI 朗读。 语音助手：如 Siri、Google Assistant 以及国产的 小米小爱同学、百度小度、华为小艺。 3. 文本、图像、音频、视频的融合 📹 多模态内容创作 多模态 AI 可以用于生成完整的内容，例如： 文本生成视频（Text-to-Video）：如 Runway Gen-2、Pika Labs，可根据文本描述生成动画或视频。 AI 讲解员：结合 AI 语音和 3D 建模技术，可生成虚拟人物进行讲解，如百度的 数字人 AI。 4. 工业与自动化 🤖 机器人与自动驾驶 自动驾驶：Tesla FSD、Waymo 依赖多模态 AI 进行道路感知和决策。 智能监控：如 Hikvision（海康威视）结合 AI 进行视频分析，识别异常行为。 主流多模态模型对比 模型名称 开发公司 模态类型 主要功能 应用场景 GPT-4V OpenAI 文本 + 图像 图像理解、视觉问答 AI 助手、图像描述 CLIP OpenAI 文本 + 图像 视觉语义搜索 搜索、内容检索 Whisper OpenAI 语音 + 文本 语音识别 自动字幕、语音助手 DALL·E OpenAI 文本 + 图像 生成图像 创意设计、AI 艺术 Gemini 1.5 Google 文本 + 图像 + 视频 跨模态交互 AI 助手、数据分析 Qwen-VL 阿里巴巴 文本 + 图像 视觉问答 AI 搜索、智能客服 ERNIE-ViLG 百度 文本 + 图像 AI 绘画 视觉创意、广告 Pika Labs 独立开发 文本 + 视频 文字生成视频 短视频制作 Tesla FSD Tesla 图像 + 传感器数据 自动驾驶 智能交通 未来展望 随着多模态 AI 技术的进步，未来的趋势包括： 更强的跨模态理解能力：未来 AI 能够更深层次理解文本、图像、视频和语音之间的关系。 增强个性化生成：基于用户数据的个性化 AI 生成将成为主流，如定制化 AI 数字人。 更高效的计算模型：降低计算成本，使得手机、IoT 设备也能运行强大的多模态 AI。 开源与生态发展：更多国产开源多模态模型，如 DeepSeek-VL、GLM-MultiModality 逐步发展。 结论 多模态与混合模型代表了 AI 发展的新方向，它们不仅突破了单一模态的限制，还让 AI 能够像人类一样理解和处理不同类型的信息。随着技术的不断进步，未来多模态 AI 预计将在智能交互、内容创作、自动驾驶、医疗健康等领域发挥越来越重要的作用。 ","date":"2025-03-08","objectID":"/posts/xvjaji9x/:0:0","tags":["多模态AI","LLM","计算机视觉","语音处理","人工智能"],"title":"多模态与混合模型：AI 未来的重要方向","uri":"/posts/xvjaji9x/"},{"categories":["人工智能","大语言模型"],"content":"引言 近年来，随着计算能力提升和大规模数据积累，大语言模型（Large Language Models, LLM）已成为推动人工智能技术发展的核心驱动力。这些模型在自然语言理解、文本生成、知识问答、多模态处理等多个领域展现出卓越性能，并在全球范围内推动智能化应用的落地。本文将从模型类别、使用场景以及主流模型对比三个角度出发，对当前前沿LLM的发展现状、技术特点与未来趋势进行系统分析。 模型类别 本文按照模型架构、训练策略及应用方向，将当前大语言模型主要划分为以下几类： 1. 自回归模型（Autoregressive Models） 采用自回归方式逐步生成文本，适用于对话和内容生成任务。代表模型包括： GPT-4：全球知名模型，以卓越的生成能力和多语言支持著称。 GLM（智谱）：在中文处理上进行了针对性优化。 DeepSeek（深度求索）：国产模型，在数学、编码、逻辑推理等任务上表现突出，具有高性价比。 GPT-4.5：OpenAI最新推出的迭代产品，幻觉率降低，生成文本更连贯。 2. 自编码器模型（Autoencoder Models） 采用遮蔽语言建模（MLM）技术，主要用于自然语言理解任务。代表模型包括： BERT：谷歌推出的双向编码模型，对上下文的理解能力显著提升。 ERNIE（文心）：百度基于BERT结构进一步优化，重点增强中文语义理解。 3. 编码器-解码器模型（Encoder-Decoder Models） 结合编码器和解码器架构，既能理解输入文本，又能生成输出文本，适合机器翻译和摘要生成。代表模型包括： T5、BART、mT5：国际上较为成熟的模型家族。 盘古（PanGu）：华为推出的国产系列，针对中文处理进行了优化。 4. 多模态与混合模型 能够同时处理文本、图像、音频等多种数据形式，实现跨模态信息融合。代表模型包括： CLIP、GPT-4V：将视觉与文本理解结合。 Qwen-VL（通义千问）：阿里在多模态领域的重要探索。 Gemini 系列：Google最新的多模态模型产品。 5. 代码生成模型 专注于生成代码、代码自动补全、调试与解释。代表模型包括： GPT-4 Turbo（Code Interpreter）：支持Python代码解释和调试。 Code Llama：Meta针对代码任务优化的开源版本。 StarCoder 2：基于大量开源代码训练，支持多种编程语言。 DeepSeek-Coder：深度求索推出的专注于代码生成与自动补全的模型。 WizardCoder：基于Code Llama优化，强化推理能力。 Codex：OpenAI的代码生成基础模型，用于GitHub Copilot。 Claude 3.7 Sonnet：Anthropic近期推出，通过混合推理技术增强代码生成与逻辑推理。 使用场景 LLM 的广泛应用场景包括但不限于： 智能客服与对话系统 如 ChatGPT、通义千问、讯飞星火等，用于自动问答、客户服务和对话生成。 内容生成与创意写作 用于新闻报道、小说创作、广告文案等文本生成任务，代表模型包括 GPT 系列、文心一言等。 知识问答与信息检索 企业知识库、智能搜索系统等，借助大模型实现高效信息抽取和问答。 机器翻译与多语言支持 跨境电商、全球化业务中实现自动翻译和多语言服务。 数据分析与报告生成 自动化报表生成、商业智能等领域，通过大模型对海量数据进行高效分析。 代码生成与自动化编程 在编程助手、自动补全、代码调试等领域发挥作用，代表产品包括 GPT-4 Turbo、DeepSeek-Coder、Claude 3.7 Sonnet 等。 主流大语言模型对比分析 下面以表格形式简要对比各模型的主要特点、开发机构、架构及应用场景： 模型 开发机构 架构类型 主要特点 应用场景 GPT-4 OpenAI 自回归 强大的生成能力，多语言支持 对话、创意写作、代码生成 GPT-4.5 OpenAI 自回归 幻觉率降低、生成文本更连贯 对话、文本生成、研究预览 Claude 3.7 Sonnet Anthropic 混合推理/自回归 高级推理、代码生成、逻辑任务优化 专业问答、编程、逻辑推理 Grok 3 xAI 自回归/混合 对话交互能力强，推理和生成表现优秀 聊天机器人、复杂任务处理 DeepSeek R1 深度求索 自回归 + 专家混合MoE 高性价比，擅长数学、编程和逻辑推理，开放性较好 数学推理、代码生成、企业应用 Qwen 2.5-Max 阿里巴巴 自回归 在数学和编程任务上表现优异，综合性能突出 企业智能助手、内容生成 Ernie 5 百度 自编码器/多模态 计划整合文本、图像、音频和视频处理能力 搜索、知识问答、多模态处理 Doubao 1.5 Pro 字节跳动 自回归 优化中文处理，成本较低，适合大规模部署 对话系统、内容生成、编码任务 Mistral 7B-Instruct Mistral AI 开源自回归 参数量较小但效率高，适合资源受限场景 边缘计算、移动设备、实时应用 Gemini 2.0 Flash Google 多模态 文本与图像处理兼顾，具备较强的跨模态能力 搜索、翻译、多模态交互 未来展望 未来大语言模型的发展将主要体现在以下几个方面： 高效与低资源消耗 优化推理算法和硬件利用率，降低训练与运行成本，使模型更易于在企业和移动设备上部署。 多模态融合 结合文本、图像、音频和视频数据，实现更丰富的交互和跨领域应用。 可控性与安全性 加强生成内容的质量控制和安全机制，减少幻觉现象，并确保生成内容符合人类价值观。 开源与国产化 国产模型（如DeepSeek、通义千问、文心系列等）不断崛起，推动开放权重和开源生态的发展，形成更加多元的技术竞争格局。 代码生成与自动化 随着编程任务自动化需求的增长，代码生成模型将进一步提升在自动补全、调试与解释方面的能力，加速软件开发效率。 结论 从Transformer架构的引入到GPT-3、ChatGPT的普及，再到DeepSeek-R1等国产模型的快速崛起，大语言模型的演进展示了人工智能技术的巨大变革。各类模型在生成、理解和推理方面不断突破，为智能客服、内容生成、代码自动化及多模态应用等领域提供了前所未有的工具和可能性。未来，随着技术的不断迭代和跨模态融合的深入，LLM将在更多行业实现应用普及，并推动全球科技创新与产业升级。 ","date":"2025-03-08","objectID":"/posts/64nm0qk8/:0:0","tags":["LLM","大语言模型","人工智能","模型对比"],"title":"关于大语言模型（LLM）的介绍：模型类别、使用场景与主流模型对比分析","uri":"/posts/64nm0qk8/"},{"categories":["android"],"content":"准备Android-x86的iso镜像 可以在http://www.android-x86.org/download 处下载 [root@localhost ~]# cd /opt [root@localhost ~]# wget https://nchc.dl.sourceforge.net/project/android-x86/Release%209.0/android-x86_64-9.0-r2.iso --no-check-certificate 准备kvm虚拟化环境 检测是否支持KVM KVM 是基于 x86 虚拟化扩展(Intel VT 或者 AMD-V) 技术的虚拟机软件，所以查看 CPU 是否支持 VT 技术，就可以判断是否支持KVM。有返回结果，如果结果中有vmx（Intel）或svm(AMD)字样，就说明CPU的支持的。 [root@localhost ~]# cat /proc/cpuinfo | egrep 'vmx|svm' flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm arat epb pln pts dtherm tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc 关闭SELinux，将 /etc/sysconfig/selinux 中的 SELinux=enforcing 修改为 SELinux=disabled [root@localhost ~]# vi /etc/sysconfig/selinux 安装 KVM 环境 通过 yum 安装 kvm 基础包和管理工具 kvm相关安装包及其作用: qemu-kvm 主要的KVM程序包 python-virtinst 创建虚拟机所需要的命令行工具和程序库 virt-manager GUI虚拟机管理工具 virt-top 虚拟机统计命令 virt-viewer GUI连接程序，连接到已配置好的虚拟机 libvirt C语言工具包，提供libvirt服务 libvirt-client 为虚拟客户机提供的C语言工具包 virt-install 基于libvirt服务的虚拟机创建命令 bridge-utils 创建和管理桥接设备的工具 # 安装 kvm # ------------------------ # yum -y install qemu-kvm python-virtinst libvirt libvirt-python virt-manager libguestfs-tools bridge-utils virt-install [root@localhost ~]# yum -y install qemu-kvm libvirt virt-install bridge-utils # 重启宿主机，以便加载 kvm 模块 # ------------------------ [root@localhost ~]# reboot # 查看KVM模块是否被正确加载 # ------------------------ [root@localhost ~]# lsmod | grep kvm kvm_intel 162153 0 kvm 525259 1 kvm_intel 开启kvm服务，并且设置其开机自动启动 [root@localhost ~]# systemctl start libvirtd [root@localhost ~]# systemctl enable libvirtd 查看状态操作结果，如Active: active (running)，说明运行情况良好 [root@localhost ~]# systemctl status libvirtd [root@localhost ~]# systemctl is-enabled libvirtd ● libvirtd.service - Virtualization daemon Loaded: loaded (/usr/lib/systemd/system/libvirtd.service; enabled; vendor preset: enabled) Active: active (running) since 二 2001-01-02 11:29:53 CST; 1h 41min ago Docs: man:libvirtd(8) http://libvirt.org 虚拟化嵌套（VM-in-VM） 安装X86模拟器需要CPU开启虚拟化功能，而KVM虚拟机已经是虚拟机了，虚拟机中的CPU默认情况下不带有虚拟化功能，这就需要nested kvm功能，即可以在虚拟机中再次进行虚拟化（VM-in-VM）。 使用嵌套虚拟化，我们首先要看下当前的系统中有没有配置支持嵌套，查看当前系统是否支持 nested [root@localhost ~]# systool -m kvm_intel -v | grep -i nested nested = \"N\" #或者这样查看 [root@localhost ~]# cat /sys/module/kvm_intel/parameters/nested N Y : 结果为 Y 表示当前的操作系统已经支持了嵌套虚拟化 N : 表示当前操作系统未配置嵌套虚拟化 如果结果为 N，可以通过以下方式开启 开启 nested 方法 编辑或创建文件 /etc/modprobe.d/kvm-nested.conf，文件包含以下内容： options kvm_intel nested=1 options kvm-intel enable_shadow_vmcs=1 options kvm-intel enable_apicv=1 options kvm-intel ept=1 重新加载内核模块 [root@localhost ~]# modprobe -r kvm_intel #协助掉内核中的 kvm_intel 模块，注意要在所有虚拟机都关闭的情况下执行 [root@localhost ~]# modprobe -a kvm_intel #重新加载该模块 创建kvm虚拟机 创建虚拟机磁盘 [root@localhost ~]# qemu-img create -f raw /opt/android.img 8G 创建虚拟机 [root@localhost ~]# virt-install \\ --virt-type=kvm \\ --name android \\ --cpu host-passthrough \\ --vcpus=2 \\ --memory=4096 \\ --disk /opt/android-x86_64-9.0-r2.iso,device=cdrom,bus=ide \\ --disk /opt/android.img,device=disk,bus=virtio \\ --network network=default,model=virtio \\ --video=qxl \\ --graphics vnc,listen=0.0.0.0,port=5902 \\ --noautoconsole \\ --import \\ --force 安装Android-x86系统 通过vnc连接宿主机5902端口 看到如下如，表示android x86的镜像已经读取成功，接下来按照虚拟机创建流程来安装系统。 选择Auto_Installation自动安装操作系统到空白磁盘 扫描到磁盘/dev/vda，选择yes继续 看到下图表示安装完毕，选择Run即可进去系统。 可以看到系统已经正常启动，界面如下： 开始初始化，选择START 连接网络，KVM默认会给android生成名称为VritWifi的WI-FI 配置日期时间 配置google服务 设置密码，这里选择Not now 选择跳过 选择桌面，我这里选择的是Taskbar 点击ALWAYS，进入桌面后会有个导航栏。 Android 调试桥 (adb) 下载Android SDK Platform-Tools是安卓SDK的一个组件，包括安卓的平台界面工具（如adb、fastboot、systrace） [root@localhost ~]# wget https://dl.google.com/android/repository/platform","date":"2022-05-10","objectID":"/posts/6dccc734/:0:0","tags":["android","kvm","linux"],"title":"在KVM虚拟机中安装Android-x86模拟器","uri":"/posts/6dccc734/"},{"categories":["android"],"content":"平台代号、版本、API 级别和 NDK 版本 下表列出了代号、对应的版本号以及关联的 API 级别。 代号 版本 API 级别/NDK 版本 Android12L 12.1 API 级别 32 Android12 12 API 级别 31 Android11 11 API 级别 30 Android10 10 API 级别 29 Pie 9 API 级别 28 Oreo 8.1.0 API 级别 27 Oreo 8.0.0 API 级别 26 Nougat 7.1 API 级别 25 Nougat 7.0 API 级别 24 Marshmallow 6.0 API 级别 23 Lollipop 5.1 API 级别 22 Lollipop 5.0 API 级别 21 KitKat 4.4 - 4.4.4 API 级别 19 Jelly Bean 4.3.x API 级别 18 Jelly Bean 4.2.x API 级别 17 Jelly Bean 4.1.x API 级别 16 Ice Cream Sandwich 4.0.3 - 4.0.4 API 级别 15，NDK 8 Ice Cream Sandwich 4.0.1 - 4.0.2 API 级别 14，NDK 7 Honeycomb 3.2.x API 级别 13 Honeycomb 3.1 API 级别 12，NDK 6 Honeycomb 3.0 API 级别 11 Gingerbread 2.3.3 - 2.3.7 API 级别 10 Gingerbread 2.3 - 2.3.2 API 级别 9，NDK 5 Froyo 2.2.x API 级别 8，NDK 4 Eclair 2.1 API 级别 7，NDK 3 Eclair 2.0.1 API 级别 6 Eclair 2.0 API 级别 5 Donut 1.6 API 级别 4，NDK 2 Cupcake 1.5 API 级别 3，NDK 1 （无代号） 1.1 API 级别 2 （无代号） 1.0 API 级别 1 安装JDK环境 root@w23ta0-virtual-machine# wget https://mirrors.huaweicloud.com/java/jdk/8u202-b08/jdk-8u202-linux-x64.tar.gz root@w23ta0-virtual-machine# tar zxvf jdk-8u202-linux-x64.tar.gz -C /opt export JAVA_HOME=\"/opt/jdk1.8.0_202\" export PATH=\"$PATH:$JAVA_HOME/bin\" export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 安装 Android 模拟器 Command line tools root@w23ta0-virtual-machine# wget https://dl.google.com/android/repository/commandlinetools-linux-8092744_latest.zip root@w23ta0-virtual-machine# unzip commandlinetools-linux-8092744_latest.zip -d /opt/ root@w23ta0-virtual-machine# cd /opt/cmdline-tools/bin sdkmanager sdkmanager 是一个命令行工具，您可以用它来查看、安装、更新和卸载 Android SDK 的软件包。 初始化目录 root@w23ta0-virtual-machine# ./sdkmanager --sdk_root=opt/android-sdk --install 接受所有许可证 root@w23ta0-virtual-machine# ./sdkmanager --sdk_root=opt/android-sdk --licenses 安装的基本工具 root@w23ta0-virtual-machine# ./sdkmanager --sdk_root=opt/android-sdk --install \"platforms;android-29\" \"build-tools;29.0.0\" \"platform-tools\" \"emulator\" \"cmdline-tools;latest\" \"system-images;android-29;default;x86\" avdmanager avdmanager是一个命令行工具，可以用于从命令行创建和管理 Android 虚拟设备 (AVD)。借助 AVD，您可以定义要在 Android 模拟器中模拟的 Android 手机、Wear OS 手表或 Android TV 设备的特性。 添加Android SDK环境变量 export ANDROID_SDK_ROOT=/opt/android-sdk export PATH=$PATH:$ANDROID_SDK_ROOT/emulator export PATH=$PATH:$ANDROID_SDK_ROOT/platform-tools/ export PATH=$PATH:$ANDROID_SDK_ROOT/cmdline-tools/latest/bin/ export PATH=$PATH:$ANDROID_SDK_ROOT/build-tools/29.0.0/ 创建新的 AVD root@w23ta0-virtual-machine# echo \"no\" | avdmanager --verbose create avd --force --name \"android-29\" --package \"system-images;android-29;default;x86\" 列出现有的 Android 虚拟设备 root@w23ta0-virtual-machine# avdmanager list avd Available Android Virtual Devices: Name: android-29 Path: /root/.android/avd/android-29.avd Target: Default Android System Image Based on: Android 10.0 (Q) Tag/ABI: default/x86 Sdcard: 512 MB 从命令行启动模拟器 查看 AVD 名称的列表 root@w23ta0-virtual-machine# emulator -list-avds android-29 启动模拟器 root@w23ta0-virtual-machine# emulator @android-29 -no-boot-anim -netdelay none -accel on -no-snapshot -wipe-data \u0026 Android 调试桥 (adb) Android 调试桥 (adb) 是一种功能多样的命令行工具，可让您与设备进行通信。adb 命令可用于执行各种设备操作（例如安装和调试应用），并提供对 Unix shell（可用来在设备上运行各种命令）的访问权限。 使用 devices 命令获取目标设备的序列号 root@w23ta0-virtual-machine# adb devices List of devices attached emulator-5554 device 使用 adb 的 install 命令在模拟器或连接的设备上安装 APK root@w23ta0-virtual-machine# adb install v2rayNG_1.1.14.apk Performing Streamed Install Success 获取应用的软件包名称 root@w23ta0-virtual-machine# adb shell pm list packages |grep v2ray package:com.v2ray.ang 获取到APP的详细信息 root@w23ta0-virtual-machine# adb shell dumpsys package com.v2ray.ang Activity Resolver Table: Full MIME Types: text/plain: 9317857 com.v2ray.ang/.ui.MainActivity filter eb50f9f Action: \"android.intent.action.SEND\" Category: \"android.intent.category.DEFAULT\" Type: \"text/plain\" 启动应用程序 root@w23ta0-virtual-machine# adb shell am start -n com.v2ray.ang/com.v2ray.ang.ui.MainActivity Starting: Intent { cmp=com.v2ray.ang/.ui.MainActivity } 关闭指定包名的应用程序 root@w23ta0-virtual-machine# adb shell am force-stop com.v2ray.ang ","date":"2022-05-06","objectID":"/posts/a864c7bd/:0:0","tags":["android","kvm","ubuntu"],"title":"Ubuntu下全命令行部署Android模拟器","uri":"/posts/a864c7bd/"},{"categories":["大数据","kafka"],"content":"环境说明 客户端与Kafka服务端不在同一个网络区域，无法直接访问。需要通过NAT进行地址映射，将Kafka服务端10.0.0.182地址映射为172.25.0.190，从而客户端与服务端可以正常通信。 Kafka客户端 NAT映射地址 Kafka服务端 172.16.0.233 172.25.0.190 10.0.0.182 问题现象 防火墙策略已经开通，客户端可以ping通服务端映射后的地址172.25.0.190。也可以telnet通映射地址的9092端口kafka服务端口。但是从客户端向kafka服务端对应的topic发送消息，无法收到任何消息。 Kafka安装 安装JDK yum install java-1.8.0-openjdk 下载并解压kafka软件包 cd /opt wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.6.0/kafka_2.12-2.6.0.tgz tar zxvf kafka_2.12-2.6.0.tgz 启动kakfa服务 cd kafka_2.12-2.6.0 bin/zookeeper-server-start.sh config/zookeeper.properties \u0026 bin/kafka-server-start.sh config/server.properties \u0026 检查服务监听 [root@kafka-test ~]# ss -lntp State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* users:((\"sshd\",pid=3231,fd=3)) LISTEN 0 50 :::40881 :::* users:((\"java\",pid=6647,fd=105)) LISTEN 0 50 :::46162 :::* users:((\"java\",pid=4152,fd=106)) LISTEN 0 128 :::22 :::* users:((\"sshd\",pid=3231,fd=4)) LISTEN 0 50 :::9092 :::* users:((\"java\",pid=4513,fd=122)) LISTEN 0 50 :::2181 :::* users:((\"java\",pid=4152,fd=117)) 本机访问测试 没有发现问题 #发送消息 bin/kafka-console-producer.sh --broker-list 172.25.0.190:9092 --topic test1 //注意这里不能在用localhost #查看消息 bin/kafka-console-consumer.sh --bootstrap-server 172.25.0.190:9092 --topic test1 通过客户端连接 #通过客户端发送消息 bin/kafka-console-producer.sh --broker-list 172.25.0.190:9092 --topic test1 错误信息如下： [2020-10-30 17:04:18,795] WARN [Producer clientId=console-producer] Error connecting to node kafka-test:9092 (id: 0 rack: null) (org.apache.kafka.clients.NetworkClient) java.net.UnknownHostException: kafka-test: Name or service not known at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method) at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928) at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323) at java.net.InetAddress.getAllByName0(InetAddress.java:1276) at java.net.InetAddress.getAllByName(InetAddress.java:1192) at java.net.InetAddress.getAllByName(InetAddress.java:1126) at org.apache.kafka.clients.ClientUtils.resolve(ClientUtils.java:110) at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.currentAddress(ClusterConnectionStates.java:403) at org.apache.kafka.clients.ClusterConnectionStates$NodeConnectionState.access$200(ClusterConnectionStates.java:363) at org.apache.kafka.clients.ClusterConnectionStates.currentAddress(ClusterConnectionStates.java:151) at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:958) at org.apache.kafka.clients.NetworkClient.access$600(NetworkClient.java:74) at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:1131) at org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater.maybeUpdate(NetworkClient.java:1019) at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:542) at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:325) at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:240) at java.lang.Thread.run(Thread.java:748) 解决方法 发现一直卡在那里，最终以超时异常退出，或者报broker找不到的错误。如果返回的是IP地址，那么肯定是无法访问的，这就是为什么在kafka的配置文件中不推荐使用IP地址的原因。现在返回的是主机名，很简单，在客户端的hosts文件中添加： 172.25.0.190 kafka-test ","date":"2020-10-30","objectID":"/posts/3a642ee8/:0:0","tags":["kakfa"],"title":"解决Kafka跨网络NAT传输问题","uri":"/posts/3a642ee8/"},{"categories":["虚拟化","OpenStack"],"content":"前置条件 准备一台主机。用于运行KVM虚拟机和制作镜像 准备一张系统镜像ISO文件 确保您的系统具有硬件虚拟化扩展 #基于Intel的主机，请使用以下命令验证CPU虚拟化扩展[vmx]是否可用。 [user@host]# grep -e 'vmx' /proc/cpuinfo #基于AMD的主机，请验证CPU虚拟化扩展[svm]是否可用。 [user@host]# grep -e 'svm' /proc/cpuinfo #验证内核是否加载kvm模块 [user@host]# lsmod | grep kvm kvm_intel 170086 0 kvm 566340 1 kvm_intel irqbypass 13503 1 kvm 关闭SELinux，将 /etc/sysconfig/selinux 中的 SELinux=enforcing 修改为 SELinux=disabled 两种方式安装KVM虚拟化 通过手动方式安装 安装KVM虚拟化程序 qemu-kvm：提供了user-level KVM仿真器，以及宿主机和虚拟机之间的通信。 qemu-img：虚拟机磁盘管理。 libvirt：提供服务器和主机端的库，用于与管理程序和主机系统进行交互，以及处理库调用，管理虚拟机和控制libvirtd守护程序。 [user@host]# yum install qemu-kvm libvirt [user@host]# systemctl start libvirtd \u0026\u0026 systemctl enable libvirtd 以下是附加的虚拟化管理程序包。 virt-install：提供了virt-install用于从命令行创建虚拟机的命令。 libvirt-python：该软件包包含一个模块，该模块允许以Python编程语言编写的应用程序使用libvirt API提供的接口。 virt-manager：提供GUI工具来管理虚拟机，它使用libvirt-client库API进行管理。 libvirt-client：提供CL工具来管理虚拟机，该工具称为virsh [user@host]# yum install virt-install libvirt-python virt-manager virt-install libvirt-client 对于RHEL / CentOS7用户，还需要安装其他软件`Virtualization Client`、`Virtualization Platform`和`Virtualization Tools`。 ```bash [user@host]# yum groupinstall virtualization-client virtualization-platform virtualization-tools 通过软件包组安装 包组名称 描述 强制安装 可选包 Virtualization Host 最小的虚拟化主机安装 libvirt，qemu-kvm，qemu-img qemu-kvm-tools Virtualization Client 用于安装和管理虚拟化实例的客户端 gnome-boxes，virt-install，virt-manager，virt-viewer，qemu-img virt-top，libguestfs-tools，libguestfs-tools-c Virtualization Platform 提供用于访问和控制虚拟机和容器的界面 libvirt, libvirt-client, virt-who, qemu-img fence-virtd-libvirt，fence-virtd-multicast，fence-virtd-serial，libvirt-cim，libvirt-java，libvirt-snmp，perl-Sys-Virt Virtualization Tools 离线虚拟映像管理工具 libguestfs，qemu-img libguestfs-java，libguestfs-tools，libguestfs-tools-c 命令如下： [user@host]# yum groupinstall \"Virtualization Host\" [user@host]# yum groupinstall \"Virtualization Client\" [user@host]# yum groupinstall \"Virtualization Platform\" [user@host]# yum groupinstall \"Virtualization Tools\" 开始制作镜像 创建虚拟机 使用 qemu-img 创建8G大小的虚拟磁盘 [user@host]# qemu-img create -f qcow2 /tmp/centos7.qcow2 8G 使用 virt-install 创建并启动虚拟机 [user@host]# virt-install --virt-type kvm --name centos7 --ram 2048 \\ --cdrom /tmp/CentOS-7-x86_64-Minimal-2003.iso \\ --disk /tmp/centos7.qcow2,format=qcow2,bus=virtio \\ --network network=default --graphics vnc,listen=0.0.0.0 \\ --noautoconsole --os-type=linux 启动完成后，使用vnc client连接或者使用virt-manager、virt-viewer连接。 [user@host]# virsh list --all [user@host]# virt-viewer centos7 安装操作系统 进入虚拟机控制台可以看到CentOS的启动菜单 选择Install CentOS 7，敲Tab键出现字时，接着输入 net.ifnames=0 biosdevname=0 ，然后回车 选择语言和键盘选项 软件选择Minimal Install 需要选择手动配置分区。只需要一个根分区即可，不需要swap分区，存储驱动选择Virtio Block Device 安装完成后，重启实例并以 root 用户身份登录。 修改 /etc/sysconfig/network-scripts/ifcfg-eth0 文件，内容如下： TYPE=Ethernet DEVICE=eth0 ONBOOT=yes BOOTPROTO=dhcp NM_CONTROLLED=no 重启网卡 # systemctl restart network 查看虚拟机自动获取的IP地址，通过宿主机ssh连接进入虚拟机。 配置OS 安装常用的软件 # yum install -y mlocate lrzsz tree vim nc nmap bash-completion bash-completion-extras cowsay sl htop iotop iftop lsof net-tools sysstat unzip bc psmisc ntpdate wc telnet-server bind-utils 关闭防火墙和SELinux # setenforce 0 # sed -i 's#enforcing#disabled#' /etc/sysconfig/selinux # systemctl stop firewalld \u0026\u0026 systemctl disable firewalld sshd优化加速 # vim /etc/ssh/sshd_config UseDNS no GSSAPIAuthentication no UseDNS 会对客户端进行DNS反向解析，然后在比对正向解析的结果查看是否一致。 GSSAPIAuthentication大多数情况下使用密码验证或者秘钥验证所以关闭GSSAPI验证即可 安装 cloud-init 软件包，并设置开机启动 # yum install -y cloud-utils-growpart cloud-init # systemctl enable cloud-init 默认情况下，cloud-init 在虚拟机启动时，会关闭ssh 的密码认证方式，使用key 方式连接。修改cloud-init 的配置文件，使其打开ssh 密码认证方式。方法如下： # vi /etc/cloud/cloud.cfg users: - default disable_root: 1 ssh_pwauth: 1 // 将默认的0,改为1。 为了支持软操作，虚拟机需要安装acpid服务，并设置开机自启动 # yum install -y acpid # systemctl enable acpid 为了nova console-log能获取虚拟机启动时的日志，修改配置文件/etc/default/grub，删掉GRUB_CMDLINE_LINUX 一行中 rhgb quiet,添加 console=tty0 console=ttyS0,115200n8 , 修改后的结果如下： GRUB_CMDLINE_LINUX=\"crashkernel=auto console=tty0 console=ttyS0,115200n8\" 运行以下命令，保存修改 # grub2-mkconfig -o /boot/grub2/grub.cfg ","date":"2020-10-26","objectID":"/posts/e4a4f171/:0:0","tags":["openstack","qcow2","kvm"],"title":"创建OpenStack兼容的qcow2格式镜像","uri":"/posts/e4a4f171/"},{"categories":["容器","Kubernetes"],"content":"环境准备 IP地址 系统 主机名 172.16.0.245 CentOS7.6 k8s-master 172.16.0.246 CentOS7.6 k8s-node1 172.16.0.247 CentOS7.6 k8s-node2 在主节点上执行以下步骤 停用SELinux和防火墙服务 使用以下命令登录到您的kubernetes主节点并设置主机名并禁用selinux ~]# hostnamectl set-hostname 'k8s-master' ~]# exec bash ~]# setenforce 0 ~]# sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux 停用防火墙服务 [root@k8s-master ~]# systemctl stop firewalld [root@k8s-master ~]# systemctl disable firewalld 创建/etc/sysctl.d/k8s.conf 文件 cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF 把以上配置修改的使其生效。 [root@k8s-master ~]# modprobe br_netfilter [root@k8s-master ~]# sysctl -p /etc/sysctl.d/k8s.conf 使用swapoff -a命令禁用所有节点的swap分区，并从/etc/fstab文件中删除或注释掉交换分区或交换文件 [root@k8s-master ~]# sed -i '/swap/ s/^/#/' /etc/fstab [root@k8s-master ~]# swapoff -a 注意：如果您没有自己的dns服务器，请在主节点和工作节点上更新/etc/hosts文件 cat \u003c\u003c EOF \u003e\u003e /etc/hosts 172.16.0.245 k8s-master 172.16.0.246 k8s-node1 172.16.0.247 k8s-node2 EOF 配置Kubernetes存储库 Kubernetes包在默认的CentOS 7和RHEL 7存储库中不可用，请使用下面的命令来配置它的包存储库 [root@k8s-master ~]# cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF [root@k8s-master ~]# 安装Kubeadm和Docker 配置软件包存储库后，运行下面的命令来安装kubeadm和docker软件包。 [root@k8s-master ~]# yum install kubeadm docker -y 启动并启用Kubectl和Docker服务 [root@k8s-master ~]# systemctl restart docker \u0026\u0026 systemctl enable docker [root@k8s-master ~]# systemctl restart kubelet \u0026\u0026 systemctl enable kubelet 使用\"kubeadm init\"初始化Kubernetes Master 运行下面的命令以初始化和设置kubernetes master。 [root@k8s-master ~]# kubeadm init \\ --apiserver-advertise-address=172.16.0.245 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.18.0 \\ --service-cidr=10.233.0.0/16 --pod-network-cidr=10.244.0.0/16 参数说明 --apiserver-advertise-address：表示apiserver对外的地址是什么，默认是0.0.0.0 --apiserver-bind-port：表示apiserver的端口是什么，默认是6443 --cert-dir：加载证书的目录，默认在/etc/kubernetes/pki --config：配置文件 --ignore-preflight-errors：在预检中如果有错误可以忽略掉，比如忽略 IsPrivilegedUser,Swap.等 --kubernetes-version：指定要初始化k8s的版本信息是什么 --pod-network-cidr ：指定pod使用哪个网段，默认使用10.244.0.0/16 --service-cidr：指定service组件使用哪个网段，默认10.96.0.0/12 上面命令的输出如下所示 正如我们在输出中看到的那样，kubernetes master已成功初始化。 执行以下命令以将群集用作root用户。 [root@k8s-master ~]# mkdir -p $HOME/.kube [root@k8s-master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@k8s-master ~]# chown $(id -u):$(id -g) $HOME/.kube/config 将pod网络部署到集群 尝试运行以下命令以获取集群和Pod的状态。 要准备好群集状态并运行kube-dns状态，请部署Pod网络，以使不同主机的容器相互通信。 POD网络是工作节点之间的覆盖网络。 运行下面的命令来部署网络 [root@k8s-master ~]# export kubever=$(kubectl version | base64 | tr -d '\\n') [root@k8s-master ~]# kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$kubever\" serviceaccount \"weave-net\" created clusterrole \"weave-net\" created clusterrolebinding \"weave-net\" created daemonset \"weave-net\" created [root@k8s-master ~]# 现在运行以下命令以验证状态 [root@k8s-master ~]# kubectl get node NAME STATUS ROLES AGE VERSION k8s-master Ready master 27m v1.18.3 [root@k8s-master ~]# kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-7ff77c879f-fqrrb 1/1 Running 0 26m kube-system coredns-7ff77c879f-hwrv6 1/1 Running 0 26m kube-system etcd-k8s-master 1/1 Running 0 27m kube-system kube-apiserver-k8s-master 1/1 Running 0 27m kube-system kube-controller-manager-k8s-master 1/1 Running 0 27m kube-system kube-proxy-sbssp 1/1 Running 0 26m kube-system kube-scheduler-k8s-master 1/1 Running 0 27m kube-system weave-net-mm2xz 2/2 Running 0 6m51s [root@k8s-master ~]# 现在，我们将工作程序节点添加到Kubernetes主节点。 在每个工作节点上执行以下步骤 停用SELinux和防火墙服务 在禁用SELinux之前，将两个节点上的主机名分别设置为k8s-node1和k8s-node2 ~]# hostnamectl set-hostname 'k8s-node{1 or 2}' ~]# exec bash ~]# setenforce 0 ~]# sed -i --follow-symlinks 's/SEL","date":"2020-05-30","objectID":"/posts/e481e229/:0:0","tags":["docker","k8s","Kubernetes"],"title":"如何在CentOS7上安装Kubernetes (k8s) 1.8","uri":"/posts/e481e229/"},{"categories":["编程语言","代码质量"],"content":"环境准备 SonarQube：sonarqube-7.9.3 数据库：PostgreSQL 10.10 操作系统：CentOS 7.6 JDK版本：java-11-openjdk sonarqube从7.8起，不再支持mysql sonarqube从7.9起，不再支持jdk11以下版本 安装JDK yum install java-11-openjdk -y 安装PostgreSQL 安装RPM源 yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm 安装客户端 yum install postgresql10 安装服务端 yum install postgresql10-server 初始化数据和设置自动启动 /usr/pgsql-10/bin/postgresql-10-setup initdb systemctl enable postgresql-10 systemctl start postgresql-10 登录数据库 su - postgres psql -U postgres 创建sonarqube用户 create user sonarqube with password 'sonarqube'; create database sonarqube owner sonarqube; grant all on database sonarqube to sonarqube; create schema my_schema; 退出psql（输入 \\q 再按回车键即可） \\q 开启远程访问 修改/var/lib/pgsql/10/data/postgresql.conf文件，取消 listen_addresses 的注释，将参数值改为“*” 修改/var/lib/pgsql/10/data/pg_hba.conf文件，增加下图红框部分内容 切换到root用户，重启postgresql服务 systemctl restart postgresql-10.service 常用命令 systemctl start postgresql-10.service // 启动服务 systemctl stop postgresql-10.service // 关闭服务 systemctl restart postgresql-10.service // 重启服务 systemctl status postgresql-10.service // 查看状态 安装SonarQube 添加系统用户 useradd sonarqube passwd sonarqube SonarQube内置elasticsearch不允许使用root用户启动 下载并解压安装包 cd /opt wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-7.9.3.zip unzip sonarqube-7.9.3.zip 修改目录权限 chown -R sonarqube.sonarqube /opt/sonarqube-7.9.3 -R 创建软连接 ln -s /opt/sonarqube-7.9.3/bin/linux-x86-64/sonar.sh /etc/init.d/sonar chmod +x /etc/init.d/sonar 修改配置 vi /opt/sonarqube-7.9.3/conf/sonar.properties sonar.jdbc.username=sonarqube sonar.jdbc.password=sonarqube sonar.jdbc.url=jdbc:postgresql://172.16.0.92/sonarqube 登陆启动用户，启动程序 su - sonarqube service sonar start 登录访问 访问url：http://172.16.0.92:9000 默认用户名/密码：admin/admin 中文语言包 常用命令 service sonar start // 启动服务 service sonar stop // 关闭服务 service sonar restart // 重启服务 chkconfig sonar on // 设置开机启动 chkconfig sonar off // 关闭开机启动 安装SonarScanner 下载地址：https://docs.sonarqube.org/latest/analysis/scan/sonarscanner/ 下载并解压安装包 cd /opt wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.2.0.1873-linux.zip unzip sonar-scanner-cli-4.2.0.1873-linux.zip 创建软连接 ln -s sonar-scanner-cli-4.2.0.1873-linux sonar-scanner 配置PATH cat \u003e /etc/profile.d/sonar-scanner.sh \u003c\u003cEOF export SONAR_RUNNER_HOME=/opt/sonar-scanner export PATH=$PATH:/opt/sonar-scanner/bin EOF source /etc/profile.d/sonar-scanner.sh 开始扫描 ","date":"2020-04-27","objectID":"/posts/6aa4d5ee/:0:0","tags":["CentOS7","SonaeQube"],"title":"如何在CentOS7上安装SonaeQube7.9","uri":"/posts/6aa4d5ee/"},{"categories":["虚拟化","OpenStack"],"content":"在执行时init-runonce 时，报错误如下: Traceback (most recent call last): File \"/usr/bin/openstack\", line 7, in \u003cmodule\u003e from openstackclient.shell import main File \"/usr/lib/python2.7/site-packages/openstackclient/shell.py\", line 23, in \u003cmodule\u003e from osc_lib import shell File \"/usr/lib/python2.7/site-packages/osc_lib/shell.py\", line 33, in \u003cmodule\u003e from osc_lib.cli import client_config as cloud_config File \"/usr/lib/python2.7/site-packages/osc_lib/cli/client_config.py\", line 18, in \u003cmodule\u003e from openstack.config import exceptions as sdk_exceptions File \"/usr/lib/python2.7/site-packages/openstack/__init__.py\", line 17, in \u003cmodule\u003e import openstack.connection File \"/usr/lib/python2.7/site-packages/openstack/connection.py\", line 166, in \u003cmodule\u003e from openstack.cloud import openstackcloud as _cloud File \"/usr/lib/python2.7/site-packages/openstack/cloud/openstackcloud.py\", line 35, in \u003cmodule\u003e import dogpile.cache File \"/usr/lib/python2.7/site-packages/dogpile/cache/__init__.py\", line 1, in \u003cmodule\u003e from .region import CacheRegion, register_backend, make_region # noqa File \"/usr/lib/python2.7/site-packages/dogpile/cache/region.py\", line 15, in \u003cmodule\u003e from decorator import decorate ImportError: cannot import name decorate 按照官方教程操作，openstack已经是搭建成功。 执行openstack命令也报上述错误，之前提示安装成功了，于是卸载pip uninstall命令，再重新安装，问题依旧。 最后综合分析，该问题是openstackclient出的问题，可能是相关依赖没有安装，于是执行 pip install --ignore-installed python-openstackclient 问题解决！ ","date":"2018-12-14","objectID":"/posts/2cae80fc/:0:0","tags":["openstack","openstackclient"],"title":"openstackclient命令执行报错","uri":"/posts/2cae80fc/"},{"categories":["容器","Docker"],"content":"执行docker pull过程中报错： Error response from daemon: Get https://xxx.xxx.xxx.xxx:5000/v2/ : http: server gave HTTP response to HTTPS client 这是由于Registry为了安全性考虑，默认是需要https证书支持的。 解决方法： 在/etc/docker/daemon.json文件中新增一行\"insecure-registries\":[“xxx.xxx.xxx:5000”]，没有则新建此文件。 vi /etc/docker/daemon.json { \"insecure-registries\":[\"xxx.xxx.xxx.xxx:5000\"] } #重启docker sudo /etc/init.d/docker restart 需要访问私有registry的节点都需要执行此操作。 参考：","date":"2017-12-29","objectID":"/posts/3bf7d2bc/:0:0","tags":["docker","registry"],"title":"Docker私有仓库pull镜像报错：server gave HTTP response to HTTPS client","uri":"/posts/3bf7d2bc/"},{"categories":["身份认证","kerberos"],"content":"Kerberos 服务(kerberos官网)是一种通过网络提供安全验证处理的客户机/服务器体系结构。通过验证，可保证网络事务的发送者和接收者的身份真实。该服务还可以检验来回传递的数据的有效性（完整性），并在传输过程中对数据进行加密（保密性）。使用 Kerberos 服务，可以安全登录到其他计算机、执行命令、交换数据以及传输文件。此外，该服务还提供授权服务，这样，管理员便可限制对服务和计算机的访问。而且，作为 Kerberos 用户，您还可以控制其他用户对您帐户的访问。 Kerberos原理 Kerberos 服务是单点登录系统，这意味着您对于每个会话只需向服务进行一次自我验证，即可自动保护该会话过程中所有后续事务的安全。服务对您进行验证后，即无需在每次使用基于 Kerberos 的服务时进行验证。因此，无需在每次使用这些服务时都在网络上发送口令（增强了安全性）。MIT写了一段故事型的对话，比较生动得表述了Kerberos协议的工作原理： Athena和欧里庇得斯关于地狱之门守护者的对话。简而言之，kerbores V5的工作原理如下： Kerbores中有三种角色： KDC：负责分发密钥的密钥分配中心 Client：需要使用kerbores服务的客户端 Service：提供具体服务的服务端 其中，Client需要和KDC和Service都进行通信。协议授权流程分两个部分： 获取原始票据 首先，Client向KDC发送自己的身份信息，KDC从授予票据服务(Ticket Granting Service)得到可用的票据(ticket-granting ticket)，并用协议开始前KDC与Client之间的密钥将票据加密回复给client，client收到KDC回复的加密票据后利用与client先前协议的密钥将票据解密，从而获得票据，此步骤主要是允许client进行Kerberos的验证，是进行访问服务的先决条件。 获取服务票据以及访问服务 client利用之前获得的票据向KDC请求服务票据，从而通过服务的身份验证。获取服务票据以及访问服务总共有如下四步： client将之前获得的票据和要请求的服务信息发送给KDC，KDC中的授予票据服务将client和service之间生成一个会话密钥(Session Key)用于服务器与client的身份验证。然后KDC将这个会话密钥和用户名，用户地址(IP)，服务名，有效期，时间戳一起包装成一个票据(这张票据用于service对client的身份验证)通过client转发给service。 为了让票据对client保密，所以KDC用协议开始之前KDC与服务端之间的密钥将票据加密后再发给client，同时为了让client与service之间共享那个会话密钥，KDC用client与它之间的密钥将会话密钥加密返回给client 为了完成票据的传递，client将刚才收到的票据转发到service，由于client不知道KDC与service的密钥，所以它无法修改票据的信息，同时client将收到的会话密钥解压出来，然后将自己的用户名，用户地址(IP)打包成验证包用会话密钥加密也发给service Service收到票据后利用它与KDC之间的密钥将票据中的信息解密出来，从而获得会话密钥和用户名，用户地址(IP)，服务名，有效期。然后再用会话密钥将验证包解密从而获得用户名，用户地址(IP)将其与之前票据中解密出来的用户名，用户地址(IP)做比较从而验证client的身份，如果service有返回结果，将其返回给client 安装Kerberos 安装package 在CentOS中可以使用yum来安装 yum install -y krb5-libs krb5-server krb5-client 或者使用源代码构建: wget http://web.mit.edu/kerberos/dist/krb5/1.12/krb5-1.12.2-signed.tar tar xvf krb5-1.12.2-signed.tar \u0026\u0026 tar xvzf krb5-1.12.2.tar.gz cd krb5-1.12.2/src ./configure yum install -y byacc make -j \u0026\u0026 make install 配置DNS 使用dnsmasq配置一个简单的本地DNS，保证需要解析的主机名在/etc/hosts中。 yum install -y dnsmasq vim /etc/dnsmasq.conf domain=expmale.com local=/expmale.com/ expand-hosts no-resolv cache-size=500 log-queries service dnsmasq start Starting dnsmasq: [ OK ] 设置客户端DNS Server 修改网卡配置文件或/etc/resolv.conf DNS1=192.168.1.221 检查域名解析 nslookup kerberos.expmale.com Server: 192.168.1.221 Address: 192.168.1.221#53 Name: kerberos.expmale.com Address: 192.168.1.221 这样DNS已经OK。 配置/etc/krb5.conf,使其指定到正确的realm中 [logging] default = FILE:/var/log/krb5libs.log kdc = FILE:/var/log/krb5kdc.log admin_server = FILE:/var/log/kadmind.log [libdefaults] default_realm = EXPMALE.COM dns_lookup_realm = false dns_lookup_kdc = false ticket_lifetime = 24h renew_lifetime = 7d forwardable = true [realms] EXPMALE.COM = { kdc = kerberos.expmale.com admin_server = kerberos.expmale.com } [domain_realm] .expmale.com = EXPMALE.COM expmale.com = EXPMALE.COM 创建KDC配置文件 vim /var/kerberos/krb5kdc/kdc.conf [kdcdefaults] kdc_ports = 88 kdc_tcp_ports = 88 [realms] EXPMALE.COM = { #master_key_type = aes256-cts acl_file = /var/kerberos/krb5kdc/kadm5.acl dict_file = /usr/share/dict/words admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab supported_enctypes = aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal } 配置acl文件 vim /var/kerberos/krb5kdc/kadm5.acl */admin@EXPMALE.COM * 使用kdb5_util创建kdc数据库 kdb5_util create -r EXPMALE.COM -s Loading random data Initializing database '/usr/local/var/krb5kdc/principal' for realm 'EXPMALE.COM', master key name 'K/M@EXPMALE.COM' You will be prompted for the database Master Password. It is important that you NOT FORGET this password. Enter KDC database master key: Re-enter KDC database master key to verify: 出现 Loading random data 的时候另开个终端执行点消耗CPU的命令如 cat /dev/sda \u003e /dev/urandom 可以加快随机数采集。 kadmin.local Authenticating as principal root/admin@EXPMALE.COM with password. 首先有介绍一个术语（参考kerberos 认证配置）： Principal：在 Kerberos 中，Principal 是参加认证的基本实体。一般来说有两种，一种用来表示 Kerberos 数据库中的用户，另一种用来代表某一特定主机，也就是说 Principal是用来表示客户端和服务端身份的实体, Principal 的格式采用 ASN.1 标准,即 Abstract Syntax Notation One，来准确定义)，Principal 是由三个部分组成：名字（name），实例（instan","date":"2017-09-25","objectID":"/posts/fabd135a/:0:0","tags":["kerberos","krb5","kinit","kdc"],"title":"Kerberos安装和管理","uri":"/posts/fabd135a/"},{"categories":["身份认证","LDAP"],"content":"LDAP最经常遇到的就是ldap_bind: Invalid credentials (49)错误，本文阐述了错误原因及解决办法： 比如在某LDAP客户端，使用rootdn(管理员)权限为某用户修改密码时 $ ldappasswd -H ldap://172.16.0.21 -x -D \"cn=admin,ou=People,dc=expmale,dc=com\" -W -S \"uid=zhang3,ou=People,dc=expmale,dc=com\" New password: Re-enter new password: Enter LDAP Password: ldap_bind: Invalid credentials (49) 错误原因1：管理员DN或者用户DN错误 管理员DN是在/etc/openldap/slapd.conf中指定的rootdn，其格式 应该是”cn=admin,dc=expmale,dc=com” 而不是”cn=admin,ou=People,dc=expmale,dc=com” 而普通用户的DN才应该是”uid=zhang3,ou=People,dc=expmale,dc=com”。 也可以执行如下命令查看该用户的DN是否存在 查询用户列表,不需要密码 $ ldapsearch -H ldap://172.16.0.21 -x -b \"ou=People,dc=expmale,dc=com\" | grep dn 错误原因2：管理员密码错误 这个需要自行判断，如需要修改rootdn的密码，在/etc/openldap/slapd.conf中改掉roodn的rootpw项，然后执行如下操作 $ rm -fr /etc/openldap/slapd.d/* $ slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d #测试配置文件语法是否有错误，如果提示testing succeeded则可以进入下一步 $ chown -R ldap:ldap /etc/openldap/slapd.d/ $ /etc/init.d/slapd restart 提示：删除/etc/openldap/slapd.d/目录下的内容，并不会导致ldap数据库的丢失，实际上，ldap数据库存储位置（通常位于/var/lib/ldap目录下）由主配置文件里的directory项指定。 ","date":"2017-03-14","objectID":"/posts/1ad460a4/:0:0","tags":["ldap","error"],"title":"解决LDAP出现ldap_bind: Invalid credentials (49)错误","uri":"/posts/1ad460a4/"},{"categories":["身份认证","LDAP"],"content":"安装及配置 首先使用如下命令查看是否已经安装 openldap： # rpm -qa | grep openldap openldap-2.4.40-16.el6.x86_64 openldap-servers-sql-2.4.40-16.el6.x86_64 openldap-clients-2.4.40-16.el6.x86_64 openldap-servers-2.4.40-16.el6.x86_64 openldap-devel-2.4.40-16.el6.x86_64 若已经安装过，可以忽略此步骤 导入epel源 wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm rpm –ivh epel-release-6-8.noarch.rpm 安装openldap yum -y install openldap openldap-* 配置openldap，包括准备DB_CONFIG和slapd.conf cd /etc/openldap/ cp /usr/share/openldap-servers/slapd.conf.obsolete slapd.conf cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG 设置 openldap的管理员密码 首先要生成经处理后的明文密码： slappasswd -s 123456 {SSHA}2TuB7EJeC1pUXDrGoxY1qqKg3ScgAvFC 其中 {SSHA}xxxxxxxxxxxxxxxxxxxxxxxx 就是加密处理后的明文密码，之后会用到这个密码。 设置自己的 Domain Name 修改slapd.conf，主要配置dc和rootpw，rootpw配置为上述步骤中的密码 vi /etc/openldap/slapd.conf database bdb suffix \"dc=expmale,dc=com\" checkpoint 1024 15 rootdn \"cn=Manager,dc=expmale,dc=com\" rootpw {SSHA}2TuB7EJeC1pUXDrGoxY1qqKg3ScgAvFC 修改目录权限 chown -R ldap:ldap /etc/openldap/ chown -R ldap:ldap /var/lib/ldap/ 启动slapd服务 /etc/init.d/slapd start 一定要先启动slapd服务，否则测试会报错，提示某数据库文件不存在，只有启动服务后才能生产该文件。 验证测试 slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d/ config file testing succeeded 使用perl脚本将本地用户转换为ldap用户 从本地系统添加用户到ldap的方法，其实就是先添加用户到本地操作系统中，然后通过pl脚本将这些用户转换为ldap能够识别的ldif文件格式，最后通过ldapadd命令导入到ldap中，从而完成ldap数据的导入，要使用pl脚本将本地用户信息转换为ldif文件格式，首先需要安装一个软件，名字为migrationtools。 安装migrationtools yum install migrationtools -y 编辑/usr/share/migrationtools/migrate_common.ph并修改相关配置 vim /usr/share/migrationtools/migrate_common.ph $DEFAULT_MAIL_DOMAIN = \"expmale.com\"; $DEFAULT_BASE = \"dc=expmale,dc=com\"; 生成base.ldif、passwd.ldif、group.ldif文件 /usr/share/migrationtools/migrate_base.pl \u003e /tmp/base.ldif /usr/share/migrationtools/migrate_group.pl /etc/group \u003e /tmp/group.ldif /usr/share/migrationtools/migrate_passwd.pl /etc/passwd \u003e /tmp/passwd.ldif ls /tmp/ base.ldif group.ldif passwd.ldif 导入base.ldif、passwd.ldif、group.ldif文件 ldapadd -x -D \"cn=Manager,dc=expmale,dc=com\" -W -f /tmp/base.ldif ldapadd -x -D \"cn=Manager,dc=expmale,dc=com\" -W -f /tmp/group.ldif ldapadd -x -D \"cn=Manager,dc=expmale,dc=com\" -W -f /tmp/passwd.ldif 需要输入管理员密码 测试数据导入是否成功 ldapsearch -LLL -W -x -H ldap://localhost -D \"cn=Manager,dc=expmale,dc=com\" -b \"dc=expmale,dc=com\" Enter LDAP Password: dn: dc=expmale,dc=com dc: expmale objectClass: top objectClass: domain dn: ou=Hosts,dc=expmale,dc=com ou: Hosts objectClass: top objectClass: organizationalUnit dn: ou=Rpc,dc=expmale,dc=com ou: Rpc objectClass: top objectClass: organizationalUnit dn: ou=Services,dc=expmale,dc=com ou: Services objectClass: top objectClass: organizationalUnit dn: nisMapName=netgroup.byuser,dc=expmale,dc=com nisMapName: netgroup.byuser objectClass: top objectClass: nisMap dn: ou=Mounts,dc=expmale,dc=com ou: Mounts objectClass: top objectClass: organizationalUnit dn: ou=Networks,dc=expmale,dc=com ou: Networks objectClass: top objectClass: organizationalUnit dn: ou=People,dc=expmale,dc=com ou: People objectClass: top objectClass: organizationalUnit dn: ou=Group,dc=expmale,dc=com ou: Group objectClass: top objectClass: organizationalUnit dn: ou=Netgroup,dc=expmale,dc=com ou: Netgroup objectClass: top objectClass: organizationalUnit dn: ou=Protocols,dc=expmale,dc=com ou: Protocols objectClass: top objectClass: organizationalUnit dn: ou=Aliases,dc=expmale,dc=com ou: Aliases objectClass: top objectClass: organizationalUnit dn: nisMapName=netgroup.byhost,dc=expmale,dc=com nisMapName: netgroup.byhost objectClass: top objectClass: nisMap 此处省略。。。 Ldap Browser 连接 Jarek Gawor发布的LDAP Browser/Editor v2.8.2 - 虽然最后一次更新于2001年，但仍然是最好工具的之一！与当前的Java版本5和6完美兼容。 所有之前的下载链接似乎都被关闭了，给像我一样喜欢高速和简约工具的小伙伴们，附下载链接。{% btn https://www.netiq.com/communities/cool-solutions/wp-content/uploads/sites/2/2009/07/Gawor_ldapbrowser_282.zip, 下载Gawor_ldapbrowser_282.zip, download fa-lg fa-fw %} 访问LDAP Browser 登录成功界面 ","date":"2017-03-14","objectID":"/posts/6fab04f7/:0:0","tags":["ldap","centos","linux"],"title":"CentOS6 安装配置OpenLDAP Server","uri":"/posts/6fab04f7/"},{"categories":["身份认证","LDAP"],"content":"目录服务 目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。 目录服务是由目录数据库和一套访问协议组成的系统。类似以下的信息适合储存在目录中： 企业员工信息，如姓名、电话、邮箱等； 公用证书和安全密钥； 公司的物理设备信息，如服务器，它的IP地址、存放位置、厂商、购买时间等； LDAP是轻量目录访问协议(Lightweight Directory Access Protocol)的缩写，LDAP是从X.500目录访问协议的基础上发展过来的，目前的版本是v3.0。与LDAP一样提供类似的目录服务软件还有ApacheDS、Active Directory、Red Hat Directory Service 。 LDAP特点 LDAP的结构用树来表示，而不是用表格。正因为这样，就不能用SQL语句了 LDAP可以很快地得到查询结果，不过在写方面，就慢得多 LDAP提供了静态数据的快速查询方式 Client/server模型，Server 用于存储数据，Client提供操作目录信息树的工具 这些工具可以将数据库的内容以文本格式（LDAP 数据交换格式，LDIF）呈现在您的面前 LDAP是一种开放Internet标准，LDAP协议是跨平台的Interent协议 LDAP组织数据的方式 基本概念 在浏览LDAP相关文档时经常会遇见一些概念，下面是常见概念的简单解释。 Entry 条目，也叫记录项，是LDAP中最基本的颗粒，就像字典中的词条，或者是数据库中的记录。通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的。 dn：每一个条目都有一个唯一的标识名（distinguished Name ，DN），如上图中一个 dn：“cn=baby,ou=marketing,ou=people,dc=mydomain,dc=org” 。通过DN的层次型语法结构，可以方便地表示出条目在LDAP树中的位置，通常用于检索。 rdn：一般指dn逗号最左边的部分，如cn=baby。它与RootDN不同，RootDN通常与RootPW同时出现，特指管理LDAP中信息的最高权限用户。 Base DN：LDAP目录树的最顶部就是根，也就是所谓的“Base DN\"，如\"dc=mydomain,dc=org\"。 Attribute 每个条目都可以有很多属性（Attribute），比如常见的人都有姓名、地址、电话等属性。每个属性都有名称及对应的值，属性值可以有单个、多个，比如你有多个邮箱。 属性不是随便定义的，需要符合一定的规则，而这个规则可以通过schema制定。比如，如果一个entry没有包含在 inetorgperson 这个 schema 中的objectClass: inetOrgPerson，那么就不能为它指定employeeNumber属性，因为employeeNumber是在inetOrgPerson中定义的。 LDAP为人员组织机构中常见的对象都设计了属性(比如commonName，surname)。下面有一些常用的别名： 属性 别名 语法 描述 值(举例) commonName cn Directory String 姓名 sean surname sn Directory String 姓 Chow organizationalUnitName ou Directory String 单位（部门）名称 IT_SECTION organization o Directory String 组织（公司）名称 example telephoneNumber Telephone Number 电话号码 110 objectClass 内置属性 organizationalPerson ObjectClass 对象类是属性的集合，LDAP预想了很多人员组织机构中常见的对象，并将其封装成对象类。比如人员（person）含有姓（sn）、名（cn）、电话(telephoneNumber)、密码(userPassword)等属性，单位职工(organizationalPerson)是人员(person)的继承类，除了上述属性之外还含有职务（title）、邮政编码（postalCode）、通信地址(postalAddress)等属性。 通过对象类可以方便的定义条目类型。每个条目可以直接继承多个对象类，这样就继承了各种属性。如果2个对象类中有相同的属性，则条目继承后只会保留1个属性。对象类同时也规定了哪些属性是基本信息，必须含有(Must 活Required，必要属性)：哪些属性是扩展信息，可以含有（May或Optional，可选属性）。 对象类有三种类型：结构类型（Structural）、抽象类型(Abstract)和辅助类型（Auxiliary）。结构类型是最基本的类型，它规定了对象实体的基本属性，每个条目属于且仅属于一个结构型对象类。抽象类型可以是结构类型或其他抽象类型父类，它将对象属性中共性的部分组织在一起，称为其他类的模板，条目不能直接集成抽象型对象类。辅助类型规定了对象实体的扩展属性。每个条目至少有一个结构性对象类。 对象类本身是可以相互继承的，所以对象类的根类是top抽象型对象类。以常用的人员类型为例，他们的继承关系： 下面是inetOrgPerson对象类的在schema中的定义，可以清楚的看到它的父类SUB和可选属性MAY、必要属性MUST(继承自organizationalPerson)，关于各属性的语法则在schema中的attributetype定义。 # inetOrgPerson # The inetOrgPerson represents people who are associated with an # organization in some way. It is a structural class and is derived # from the organizationalPerson which is defined in X.521 [X521]. objectclass ( 2.16.840.1.113730.3.2.2 NAME 'inetOrgPerson' DESC 'RFC2798: Internet Organizational Person' SUP organizationalPerson STRUCTURAL MAY ( audio $ businessCategory $ carLicense $ departmentNumber $ displayName $ employeeNumber $ employeeType $ givenName $ homePhone $ homePostalAddress $ initials $ jpegPhoto $ labeledURI $ mail $ manager $ mobile $ o $ pager $ photo $ roomNumber $ secretary $ uid $ userCertificate $ x500uniqueIdentifier $ preferredLanguage $ userSMIMECertificate $ userPKCS12 ) ) Schema 对象类（ObjectClass）、属性类型（AttributeType）、语法（Syntax）分别约定了条目、属性、值，他们之间的关系如下图所示。所以这些构成了模式(Schema)——对象类的集合。条目数据在导入时通常需要接受模式检查，它确保了目录中所有的条目数据结构都是一致的。 schema（一般在/etc/ldap/schema/目录）在导入时要注意前后顺序。 backend \u0026 database ldap的后台进程slapd接收、响应请求，但实际存储数据、获取数据的操作是由Backends做的，而数据是存放在database中，所以你可以看到往往你可以看到backend和database指令是一样的值如 bdb 。一个 backend 可以有多个 database instance，但每个 database 的 suffix 和 rootdn 不一样。openldap 2.4版本的模块是动态加载的，所以在使用backend时需要moduleload back_bdb指令。 bdb是一个高性能的支持事务和故障恢复的数据库后端，可以满足绝大部分需求。许多旧文档里（包括官方）说建议将bdb作为首选后端服务（primary backend），但2.4版文档明确说hdb才是被首先推荐使用的，这从 2.4.40 版默认安装后的配置文件里也可以看出。hdb是基于bdb的，但是它通过扩展的索引和缓存技术可以加快数据访问，修改entries会更有效率，有兴趣可以访问上的链接或slapd.backends。 另外config是特殊的backend，用来在运行时管理slapd的配置，它只能有一个实例，甚至无需显式在slapd.conf中配置。 TLS \u0026 SASL 分布式LDAP 是以明文的格式通过网络来发送信息的，包括client访问ldap的密码（当然一般密码已然是二进制的），SSL/TLS 的加密协议就是来保证数据传送的保密性和完整性。 SASL （Simp","date":"2017-03-12","objectID":"/posts/77e94e45/:0:0","tags":["ldap","auth"],"title":"LDAP服务器的概念和原理简单介绍","uri":"/posts/77e94e45/"},{"categories":["编程语言","Python"],"content":"问题描述 在MySQL-python-1.2.5源码包根目录下执行安装命令： # python setup.py install 出现以下信息： error: command ‘gcc’ failed with exit status 1 解决方法 在安装MySQLdb前安装以下依赖库： # yum install python-devel mysql-devel zlib-devel openssl-devel 安装完以上依赖库后， 再在MySQL-python-1.2.3源码包根目录下执行以下安装命令即可： # python setup.py install 如下信息表示MySQLdb安装成功： Installed /usr/lib64/python2.6/site-packages/MySQL_python-1.2.5-py2.6-linux-x86_64.egg Processing dependencies for MySQL-python==1.2.5 Finished processing dependencies for MySQL-python==1.2.5 检测模块MySQLdb是否可正常使用 [root@gateway ~]# python Python 2.6.6 (r266:84292, Aug 18 2016, 15:13:37) [GCC 4.4.7 20120313 (Red Hat 4.4.7-17)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e import MySQLdb \u003e\u003e\u003e 没消息就是好消息！ OK， Enjoy it!!! ","date":"2015-11-18","objectID":"/posts/73cebd2e/:0:0","tags":["python","gcc","centos","mysqldb"],"title":"Centos6下安装MySQL-python时出现“error: command 'gcc' failed with exit status 1”","uri":"/posts/73cebd2e/"},{"categories":["Web相关"],"content":"近几天在学习 HTML5 与 CSS3 时，偶然看到了 CSS 中自动为标题添加编号的特性。仔细阅读过 W3Schools 上提供的文档之后，试验了一下，确实非常好用。从此不需再花费精力校对标题编号，可以将时间集中到真正需要做的事情，也避免了手动编号出错的窘态。 这篇博文整理了我搜集的相关知识点，方便希望详细了解的人查看。 涉及内容 首先介绍一下本文涉及到的相关 CSS 知识点。其中用到的 CSS 伪元素和属性皆基于 CSS2.1 标准，所以基本不需要担心浏览器的兼容性问题。如果你对此还不够放心，可以在不同浏览器中打开文末给出的样例进行测试。 before 伪元素选择器 before伪元素选择器用于在某个元素之前插入一些内容。所插入的内容由content属性指定，可以是字符串、图片、音频甚至视频文件等。 与之对应的，还有after伪元素，用于在某个元素的后面插入一些内容。 其用法如： /* insert a word before anchor */ a:before { content: 'goto: ' } /* add a icon after an url end by mp4*/ a[href$=mp4]:after { content: url(moive.png) } counter-increment 属性 counter-increment属性用于递增计数器，该属性可接受的输入有： 其中值的意义为： none：不递增计数器； id：需递增的计数器ID； initial：递增的步长，默认为 1； inherit：从父元素继承。 counter-reset 属性 counter-reset属性用于重置计数器，比如在每篇文章开始前将计数器重置为 0。该属性可接受的输入有： counter-reset: none|name-number|initial|inherit; 其中值的意义为： none：不重置计数器； name-number：需重置的计数器ID； initial：重置的值，默认为 0； inherit：从父元素继承。 示例代码 以下面的网页作为示例： \u003c!doctype html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003e自动编号演示\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"counter.css\"\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003e文章大标题\u003c/h1\u003e \u003ch2\u003e前言\u003c/h2\u003e \u003ch2\u003e数据准备\u003c/h2\u003e \u003ch3\u003e观测数据准备\u003c/h3\u003e \u003ch3\u003e表文件准备\u003c/h3\u003e \u003ch2\u003e参数设置\u003c/h2\u003e \u003ch3\u003e高度角\u003c/h3\u003e \u003ch3\u003e模型设置\u003c/h3\u003e \u003ch2\u003e开始解算\u003c/h2\u003e \u003ch2\u003e成果查看\u003c/h2\u003e \u003c/body\u003e \u003c/html\u003e 其中引入的 counter.css 中的代码为： /* reset h2 counter to -1 when meet a h1 element */ h1 { counter-reset: h2Counter -1; } /* insert number before h2 element */ h2:before { content: counter(h2Counter)'. ' } /* increase h2 counter and reset h3 counter when meet a h2 element */ h2 { counter-increment: h2Counter; counter-reset: h3Counter; } h3:before { content: counter(h2Counter) '.' counter(h3Counter) ' ' } h3 { counter-increment: h3Counter; } 将以上两块代码分别保存为 counter.html 和 counter.css，确保这两个文件位于同一目录内，然后使用浏览器打开其中的 counter.html 文件即可预览效果。 ","date":"2015-10-23","objectID":"/posts/283c0c55/:0:0","tags":["css","html"],"title":"使用 CSS 实现标题自动编号","uri":"/posts/283c0c55/"},{"categories":["容器","Docker"],"content":"docker images往往不知不觉就占满了硬盘空间，为了清理冗余的image，可采用以下方法： 进入root权限 sudo su 停止所有的container，这样才能够删除其中的images： docker stop $(docker ps -a -q) 如果想要删除所有container的话再加一个指令： docker rm $(docker ps -a -q) 查看当前有些什么images docker images 删除images，通过image的id来指定删除谁 docker rmi \u003cimage id\u003e 想要删除untagged images，也就是那些id为的image的话可以用 docker rmi $(docker images | grep \"^\u003cnone\u003e\" | awk \"{print $3}\") 要删除全部image的话 docker rmi $(docker images -q) ","date":"2015-09-08","objectID":"/posts/eb62b0d0/:0:0","tags":["docker","images"],"title":"如何删除docker images/containers","uri":"/posts/eb62b0d0/"},{"categories":["数据库","Oracle"],"content":"**INSTR用法：**INSTR(源字符串, 要查找的字符串, 从第几个字符开始, 要找到第几个匹配的序号) 返回找到的位置，如果找不到则返回0. 默认查找顺序为从左到右。当起始位置为负数的时候，从右边开始查找。若起始位置为0，返回值为0。 SELECT INSTR('CORPORATE FLOOR', 'OR', 0, 1) FROM DUAL; 返回值为0 SELECT INSTR('CORPORATE FLOOR', 'OR', 2, 1) FROM DUAL; 返回值为2 SELECT INSTR('CORPORATE FLOOR', 'OR', 2, 2) FROM DUAL; 返回值为5 SELECT INSTR('CORPORATE FLOOR', 'OR', -1, 1) FROM DUAL; 返回值为14 SELECT INSTR('CORPORATE FLOOR', 'OR', -5, 1) FROM DUAL; 返回值为5 **SUBSTR用法：**SUBSTR( 源字符串, 查找起始位置, [ 长度 ] ) 返回值为源字符串中指定起始位置和长度的字符串。 SELECT SUBSTR('This is a test', 0, 2) value from dual; 返回值Th SELECT SUBSTR('This is a test', 1, 2) value from dual; 返回值Hi SELECT SUBSTR('This is a test', -1, 2) value from dual; 返回值t SELECT SUBSTR('This is a test', -2, 2) value from dual; 返回值st **NVL用法：**NVL(eExpression1, eExpression2) 从两个表达式返回一个非 null 值。如果eExpression1的计算结果为null值，则 NVL( ) 返回eExpression2。如果eExpression1的计算结果不是null值，则返回eExpression1。eExpression1 和eExpression2可以是任意一种数据类型。如果eExpression1与eExpression2 的结果皆为 null值，则NVL( )返回NULL。 SELECT nvl('pos1',null) from dual; 返回值为pos1 SELECT nvl(null,'pos2') from dual; 返回值为pos1 SELECT nvl(null,null) from dual; 返回值为null ","date":"2015-09-07","objectID":"/posts/51f21f40/:0:0","tags":["oracle"],"title":"Oracle中INSTR、SUBSTR和NVL的用法","uri":"/posts/51f21f40/"},{"categories":["容器","Docker-Compose"],"content":"Docker Compose是用于定义和运行复杂Docker应用的工具。你可以在一个文件中定义一个多容器的应用，然后使用一条命令来启动你的应用，然后所有相关的操作都会被自动完成。 Docker Compose具有管理应用程序整个生命周期的命令： 启动，停止和重建服务 查看正在运行的服务的状态 流式传输运行服务的日志输出 在服务上运行一次性命令 Docker Compose 安装 # 当前最新的Docker是1.6.2，Compose为1.2.0 curl -s https://get.docker.io/ubuntu/ | sudo sh sudo apt-get update sudo apt-get install lxc-docker # 参考http://docs.docker.com/compose/install/#install-compose curl -L https://github.com/docker/compose/releases/download/1.2.0/docker-compose-`uname -s`-`uname -m` \u003e /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose ### 上面这个方法真的慢出翔，可以通过Python pip安装。 apt-get install python-pip python-dev pip install -U docker-compose 这样compose就安装好了，查看一下compose的版本信息： chmod +x /usr/local/bin/docker-compose docker-compose -version docker-compose 1.2.0 Docker Compose 使用 使用Compose只需要简单的三个步骤： 首先，使用Dockerfile来定义你的应用环境： FROM python:2.7 ADD ./code WORKDIR /code RUN pip install -r requirements.txt 其中，requirements.txt中的内容包括： flask redis 再用Python写一个简单的app.py from flask importFlaskfrom redis importRedisimport os app =Flask(__name__) redis =Redis(host='redis', port=6379)@app.route('/')def hello(): redis.incr('hits')return'Hello World! I have been seen %s times.'% redis.get('hits')if __name__ ==\"__main__\": app.run(host=\"0.0.0.0\", debug=True) 第二步，用一个compose.yaml来定义你的应用服务，他们可以把不同的服务生成不同的容器中组成你的应用。 web: build:. command: python app.py ports: - \"5000:5000\" volumes: - .:/code links: - redis redis: image: redis 第三步，执行docker-compose up来启动你的应用，它会根据compose.yaml的设置来pull/run这俩个容器，然后再启动。 Creating myapp_redis_1... Creating myapp_web_1... Building web... Step 0 : FROM python:2.7 2.7: Pulling from python ... Status: Downloaded newer image for python:2.7 ---\u003e d833e0b23482 Step 1 : ADD . /code ---\u003e 1c04b1b15808 Removing intermediate container 9dab91b4410d Step 2 : WORKDIR /code ---\u003e Running in f495a62feac9 ---\u003e ffea89a7b090 Attaching to myapp_redis_1, myapp_web_1 ...... redis_1 | [1] 17 May 10:42:38.147 * The server is now ready to accept connections on port 6379 web_1 | * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit) web_1 | * Restarting with stat Yaml文件参考 在上面的yaml文件中，我们可以看到compose文件的基本结构。首先是定义一个服务名，下面是yaml服务中的一些选项条目： image:镜像的ID build:直接从pwd的Dockerfile来build，而非通过image选项来pull links:连接到那些容器。每个占一行，格式为SERVICE[:ALIAS],例如 – db[:database] external_links:连接到该compose.yaml文件之外的容器中，比如是提供共享或者通用服务的容器服务。格式同links command:替换默认的command命令 ports: 导出端口。格式可以是： ports:-\"3000\"-\"8000:8000\"-\"127.0.0.1:8001:8001\" expose：导出端口，但不映射到宿主机的端口上。它仅对links的容器开放。格式直接指定端口号即可。 volumes：加载路径作为卷，可以指定只读模式： volumes:-/var/lib/mysql - cache/:/tmp/cache -~/configs:/etc/configs/:ro volumes_from：加载其他容器或者服务的所有卷 environment:- RACK_ENV=development - SESSION_SECRET env_file：从一个文件中导入环境变量，文件的格式为RACK_ENV=development extends:扩展另一个服务，可以覆盖其中的一些选项。一个sample如下： common.yml webapp: build:./webapp environment:- DEBUG=false- SEND_EMAILS=false development.yml web:extends: file: common.yml service: webapp ports:-\"8000:8000\" links:- db environment:- DEBUG=true db: image: postgres net：容器的网络模式，可以为”bridge”, “none”, “container:[name or id]”, “host”中的一个。 dns：可以设置一个或多个自定义的DNS地址。 dns_search:可以设置一个或多个DNS的扫描域。 其他的working_dir, entrypoint, user, hostname, domainname, mem_limit, privileged, restart, stdin_open, tty, cpu_shares，和docker run命令是一样的，这些命令都是单行的命令。例如： cpu_shares:73 working_dir:/code entrypoint: /code/entrypoint.sh user: postgresql hostname: foo domainname: foo.com mem_limit:1000000000 privileged:true restart: always stdin_open:true tty:true 常用命令 在第二节中的docker-compose up,这两个容器都是在前台运行的。我们可以指定-d命令以daemon的方式启动容器。 除此之外，docker-compose还支持下面参数： --verbose：输出详细信息 -f 制定一个非docker-compose.yml命名的yaml文件 -p 设置一个项目名称（默认是directory名） docker-compose的动作包括： build：构建服务 kill -s SIGINT：给服务发送特定的信号。 logs：输出日志 port：输出绑定的端口 ps：输出运行的容器 pull：pull服务的image rm：删除停止的容器 run: 运行某个服务，例如docker-compose run web python manage.py shell start：运行某个服务中存在的容器。 stop:停止某个服务中存在的容器。 up：create + run + attach容器到服务。 scale：设置服务运行的容器数量。例如：docker-compose scale web=2 worker=3 参考 Compose Document ","date":"2015-08-30","objectID":"/posts/5bdb99b1/:0:0","tags":["docker","compose"],"title":"Docker Compose简化复杂应用的利器","uri":"/posts/5bdb99b1/"},{"categories":["容器","Docker Registry"],"content":"通常情况下我们可以使用Docker Hub作为docker image的仓库，但是有些场景下，我们希望能够有本地的仓库。比如： 代码中含有保密的信息，比如环境的账号，密码等等； 代码本身作为公司的资产，不能对外公开，否则有法律风险。 在创建本地仓库之前，请确保已经在目的机器上安装了Docker。这里我们使用docker容器运行registry镜像的方式，来创建registry。 一般情况下安装的docker已经自带了registry镜像，如果没有可以从docker hub上获取。 环境准备 关闭防火墙 systemctl stop firewalld.service systemctl disable firewalld.service 关闭selinux sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/sysconfig/selinux setenforce 0 搭建私有仓库 下载registry镜像 首先，在192.168.0.200机器上下载registry镜像 docker pull registry 基于私有仓库镜像运行容器 下载完之后我们通过该镜像启动一个容器 docker run -d -p 5000:5000 localregistry registry 其中 localregistry表示此容器的名称，registry表示了镜像本身。可以运行docker ps查看结果： CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES afae402eb9ae registry \"/entrypoint.sh /e...\" 4 hours ago Up 20 minutes 0.0.0.0:5000-\u003e5000/tcp localregistry 默认情况下，会将仓库存放于容器的/tmp/registry目录下，这样如果容器被删除，则存放于容器中的镜像也会丢失，所以我们一般情况下会指定本地一个目录挂载到容器的/tmp/registry下，如下： docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry --name localregistry registry 自动启动仓库 如果想让registry作为永久的可用仓库，应该在Docker machine重启或退出之后，设置registry仍然能够自动重启或保持使用状态。可以使用–restart=always达到此目的。 docker run -d -p 5000:5000 --restart=always -v /opt/data/registry:/tmp/registry --name localregistry registry 访问私有仓库 网上都用这个curl http://127.0.0.1:5000/v1/search,但是报404 page not found，后查证是v1版本的api查看方式，我们现在的版本是v2，所以用如下方法查看： curl -X GET http://127.0.0.1:5000/v2/_catalog {\"repositories\":[]} #私有仓库为空，没有提交新镜像到仓库中 详细 curl 操作docker仓库 从Docker Hub获取nginx镜像 docker pull nginx:alpine 接下来我们尝试将上面的 nginx:alpine 上传到本地的 registry 服务器， 首先为这个镜像定义一个新的标签： docker tag nginx:alpine 127.0.0.1:5000/nginx:alpine 然后通过docker images查看，确认是否存在这个标签，输出如下： REPOSITORY TAG IMAGE ID CREATED SIZE 127.0.0.1:5000/nginx alpine 0ae090dba3ab 3 months ago 54.3 MB nginx alpine 0ae090dba3ab 3 months ago 54.3 MB 现在可以上传这个镜像： docker push 127.0.0.1:5000/nginx:alpine 输出如下 ： The push refers to a repository [127.0.0.1:5000/nginx] 4a8d9a67e458: Pushed c0ab80890b7f: Pushed d4930e247b49: Pushed 9f8566ee5135: Pushed alpine: digest: sha256:bf63c02f35f7f8d0a95af4904d38ea17ef3f0c86e6b95d716200bdd9963f5ec5 size: 1154 现在来浏览 http://127.0.0.1:5000/v2/_catalog ， 将会看到这样的结果： {\"repositories\":[\"nginx\"]} 表示已经有了 nginx 这个镜像， 如果要看这个镜像有什么版本， 需要输入地址 http://127.0.0.1:5000/v2/nginx/tags/list ， 结果如下： {\"name\":\"nginx\",\"tags\":[\"alpine\"]} 如果要在其它装了 docker 的电脑上获取这个镜像， 或者下载局域网其它 registry 服务器上的镜像， 有两个选择： 配置 HTTPS 证书， 因为是内网分发， 没有必要去折腾证书。 如果需要的话， 可以参考这个教程来配置域证书或者这个教程来配置自签名证书; 参考这个教程修改 docker 的 daemon.json 文件， 配置 insecure-registries 选项。 ","date":"2015-08-28","objectID":"/posts/49dab0f1/:0:0","tags":["docker","registry"],"title":"如何搭建Docker Registry本地私有仓库","uri":"/posts/49dab0f1/"},{"categories":["容器","Docker"],"content":"我最近在玩Docker，一种应用程序容器和Linux的虚拟技术。它太酷了，创建Docker镜像和容器只需要几分钟。所有的工作都是开箱即用的。 在结束我一天的工作之前，我希望能保存下我的工作。但我在Docker的save和export命令之间，我凌乱了。我不知道它们之间有什么区别。所以，我上StackOverflow问了一个问题，接着得到mbarthelemy很棒的回复。 以下是我发掘到的内容： 开源项目Docker，Red Hat新的虚拟化选择 http://www.linuxidc.com/Linux/2013-10/91051.htm dockerlite: 轻量级 Linux 虚拟化 http://www.linuxidc.com/Linux/2013-07/87093.htm Docker的搭建Gitlab CI 全过程详解 http://www.linuxidc.com/Linux/2013-12/93537.htm Docker 和一个正常的虚拟机有何区别? http://www.linuxidc.com/Linux/2013-12/93740.htm Docker 将改变所有事情 http://www.linuxidc.com/Linux/2013-12/93998.htm Docker是如何工作的（简单说明） Docker是基于镜像的。镜像类似于已经包含了文件、配置和安装好的程序的虚拟机镜像。同样的，你可以像启动虚拟机一样启动多个镜像实例。运行中的镜像称为容器。你可以修改容器（比如删除一个文件），但这些修改不会影响到镜像。不过，你使用docker commit 命令可以把一个正在运行的容器变成一个新的镜像。 举个例子： # 像Docker官方的hello world例子一样，拉取一个叫busybox的镜像 sudo docker pull busybox # 查看本地已经有哪些镜像 # 我们可以看到busybox sudo docker images # 现在让我们来修改下busybox镜像的容器 # 这次，我们创建一个文件夹 sudo docker run busybox mkdir /home/test # 让我们再看看我们有哪些镜像了。 # 注意每条命令执行后容器都会停止 # 可以看到有一个busybox容器 sudo docker ps -a # 现在，可以提交修改了。 # 提交后会看到一个新的镜像busybox-1 # \u003cCONTAINER ID\u003e 是刚刚修改容器后得到的ID sudo docker commit \u003cCONTAINER ID\u003e busybox-1 # 再看看我们有哪些镜像。 # 我们现在同时有busybox和busybox-1镜像了。 sudo docker images # 我们执行以下命令，看看这两个镜像有什么不同 sudo docker run busybox [ -d /home/test ] \u0026\u0026 echo 'Directory found' || echo 'Directory not found' sudo docker run busybox-1 [ -d /home/test ] \u0026\u0026 echo 'Directory found' || echo 'Directory not found' 现在，我们有两个不同的镜像了（busybox和busybox-1），还有一个通过修改busybox容器得来的容器（多了一个/home/test文件夹）。下面来看看，是如何持久化这些修改的。 导出(Export) Export命令用于持久化容器（不是镜像）。所以，我们就需要通过以下方法得到容器ID： sudo docker ps -a 接着执行导出： sudo docker export \u003e /home/export.tar 最后的结果是一个2.7MB大小的Tar文件（比使用save命令稍微小些）。 保存(Save) Save命令用于持久化镜像（不是容器）。所以，我们就需要通过以下方法得到镜像名称： sudo docker images 接着执行保存： sudo docker save busybox-1 \u003e /home/save.tar 最后的结果是一个2.8MB大小的Tar文件（比使用export命令稍微大些）。 它们之间的不同 现在我们创建了两个Tar文件，让我们来看看它们是什么。首先做一下小清理——把所有的容器和镜像都删除： # 查看所有的容器 sudo docker ps -a # 删除它们 sudo docker rm # 查看所有的镜像 sudo docker images # 删除它们 sudo docker rmi busybox-1 sudo docker rmi busybox 译注：可以使用 docker rm $(docker ps -q -a) 一次性删除所有的容器，docker rmi $(docker images -q) 一次性删除所有的镜像。 现在开始导入刚刚导出的容器： # 导入export.tar文件 cat /home/export.tar | sudo docker import - busybox-1-export:latest # 查看镜像 sudo docker images # 检查是否导入成功，就是启动一个新容器，检查里面是否存在/home/test目录（是存在的） sudo docker run busybox-1-export [ -d /home/test ] \u0026\u0026 echo 'Directory found' || echo 'Directory not found' 使用类似的步骤导入镜像： # 导入save.tar文件 docker load \u003c /home/save.tar # 查看镜像 sudo docker images # 检查是否导入成功，就是启动一个新容器，检查里面是否存在/home/test目录（是存在的） sudo docker run busybox-1 [ -d /home/test ] \u0026\u0026 echo 'Directory found' || echo 'Directory not found' 那它们之间到底存在什么不同呢？我们发现导出后的版本会比原来的版本稍微小一些。那是因为导出后，会丢失历史和元数据。执行下面的命令就知道了： # 显示镜像的所有层(layer) sudo docker images --tree 执行命令，显示下面的内容。正你看到的，导出后再导入(exported-imported)的镜像会丢失所有的历史，而保存后再加载（saveed-loaded）的镜像没有丢失历史和层(layer)。这意味着使用导出后再导入的方式，你将无法回滚到之前的层(layer)，同时，使用保存后再加载的方式持久化整个镜像，就可以做到层回滚（可以执行docker tag 来回滚之前的层） root@Ubuntu-13:~$ sudo docker images --tree ├─f502877df6a1 Virtual Size: 2.489 MB Tags: busybox-1-export:latest └─511136ea3c5a Virtual Size: 0 B └─bf747efa0e2f Virtual Size: 0 B └─48e5f45168b9 Virtual Size: 2.489 MB └─769b9341d937 Virtual Size: 2.489 MB └─227516d93162 Virtual Size: 2.489 MB Tags: busybox-1:latest ","date":"2015-08-25","objectID":"/posts/d3163da/:0:0","tags":["docker","export","save"],"title":"Docker的save和export命令的区别","uri":"/posts/d3163da/"},{"categories":["Web相关"],"content":"前提条件 内存：2G，硬盘空闲空间10G，安装完成后实际只占不到2G 支持winXP SP3;32位与64位win7浏览器支持IE6-8,IE9,firefox3 若以前安装过LoadRunner,则将其卸载。 下载介质 下载地址是，这个是我自己搜集的，也可以安装其他版本： LoadRunner11 链接：http://pan.baidu.com/s/1skGkzb3 密码：88uq LoadRunner12 链接: https://pan.baidu.com/s/1qXL4tFu 密码: cgrt 备注：压缩后大小有3G多，解压之后4G左右，iso文件。由于文件太大，需要放在NFS的盘中, FAT32最大只支持4GB的文件。 安装步骤 启动安装程序 运行setup.exe，点击“LoadRunner完整安装程序” 安装组件 安装LoadRunner11时，安装程序会自动检测系统所安装的组件情况，LoadRunner运行支持的组件，一般比较重要的是Visual C++ 2005 SP1和.Net Framework 3.5。因之前安装了一组件在计算机中，下图中只显示了2个必要的组件(lr安装包中含有这些组件)，如果是全新的系统一般会是5个，直接点击“下一步”，如下图： 安装欢迎界面 组件安装完成后进入LoadRunner主程序的安装界面，直接“下一步”： 许可协议 选择“我同意”，然后点击“下一步”： 个人信息 输入个人相关信息，选择“下一步”： 安装路径 选择LoadRunner安装路径，注意安装路径不要有中文，选择“下一步”： 安装及完成 安装后 安装完成后，系统会自动打开“LoadRunner License Information”窗口： 并提示你的License只有十天的使用期。 此时，可以启动LoadRunner了。 破解方法 把loadrunner相关程序全部退出； 解压文件: lr破解.zip 用LR8.0中的mlr5lprg.dll、lm70.dll覆盖LR9.5安装目录下“bin”文件夹中的对应文件；一般是C:\\Program Files\\Mercury\\LoadRunner\\bin. 清理注册表（不清理的话，在添加licence时，会提示“License security violation……”） 可以下载注册表清理器lr_Del_license（LR破解包内有）或者手动修改注册表，删除下面内容： [HKEY_LOCAL_MACHINE\\SOFTWARE\\Mercury Interactive\\LoadRunner\\License2] [HKEY_LOCAL_MACHINE\\SOFTWARE\\Mercury Interactive\\LoadRunner\\License2\\History]@=“AIBGEBFW-JVED-ZKEKEKEKEKEBDNQAF-KBRDN”=”” [HKEY_LOCAL_MACHINE\\SOFTWARE\\Mercury Interactive\\LoadRunner\\License2\\PermanentLicense]@=”AIBGEBFW-JVED-ZKEKEKEKEKEBDNQAF-KBRDN””last”=”AIBGEBFW-JVED-ZKEKEKEKEKEBDNQAF-KBRDN” [HKEY_LOCAL_MACHINE\\SOFTWARE\\Mercury Interactive\\LoadRunner\\License2\\TemporaryLicense]@=”AEBGEBFS-AKEKEKEKE-KAUCA” [HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\Interface\\{87B3ADD4-21EB-11d5-93EF-00105AA0FD2D}]@=”IControl” 添加下面的licence，即可使用： global-100: AEAMAUIK-YAFEKEKJJKEEA-BCJGI web-10000: AEABEXFR-YTIEKEKJJMFKEKEKWBRAUNQJU-KBYGB golba-1000：AEACFSJI-YASEKJJKEAHJD-BCLBR 提供一个超级license 最高支持6.5w个并发：AEACFSJI-YJKJKJJKEJIJD-BCLBR (备注：破解同8.1、9.5一样) 安装过程中遇到的问题 安装过程中，提示：少了Microsoft Visual c++2005 sp1运行时组件，安装时会提示命令行选项语法错误，键入“命令/?”可获取帮肋信息，无法正常安装； 解决方法： 进入loadrunner-11\\Additional Components\\IDE Add-Ins\\MS Visual Studio .NET 安装LRVS2005IDEAddInSetup.exe 再安装loadrunner 注意开启 ，在开始菜单下面的HP LoadRunner\\Advanced Settings\\LoadRunner Agent Process.如果不打开此服务会影响GUI Vusers、ASPGUI脚本回放。 安装时提示”the link file …. may be corrupted or has illegated link string”的错误信息或者提示Command Line Option Syntax error.Type Command/? 原因：LoadRunner的安装文件夹包含中文，LoadRunner的安装脚本无法识别路径，最终导致不断有这样的错误提示。 解决方法：把安装文件的目录名改为不要有中文，安装目录最好使用默认。 管理员权限安装 LoadRunner录制脚本经常遇到不能打开浏览器的情况，(当一台主机上安装多个浏览器时，)可以用下面的方法来解决。 解决办法：启动浏览器，打开Internet选项对话框，切换到高级标签，去掉“启用第三方浏览器扩展(需要重启动)”的勾选，然后再次运行VuGen即可; 提示：通常安装Firefox等浏览器后，都会勾选上面得选项，导致不能正常录制。因此建议运行LoadRunner得主机上保持一个干净的测试环境 录制时关闭防火墙，关闭360相关东西。 loadrunner在打开场景时，提示“试图执行系统不支持的操作” 原因：在安装时，360杀毒软件的防御提示全部设为阻止了。 解决方法：卸载LoadRunner，然后手动删除安装文件和注册表里面的信息，重启后安装，杀毒软件的防御提示全部设为允许，就OK了 重装系统后安装LR,提示setup has determined that a previous installation has not completed，重启无效 ; 解决方法： 进入注册表：运行/regedit; 进入路径：KEY_LOCAL_MACHINE/SYSTEM/Contrl/SessionManager; 在Session Manager右侧的主试图中，双击PendingRenameOperations，在弹出的窗口中，将临时文件删除。 重新运行LR安装文件即可。 当安装提示\"此计算机缺少 vc2005_sp1_with_atl_fix_redist\"，怎么办？ 解决方法：运行安装程序自带的vcredist_x86.exe（默认位置在 “安装包\\lrunner\\Chs\\prerequisites\\vc2005_sp1_redist”），让电脑先装基础环境后装LoadRunner 11即可。 ","date":"2015-08-20","objectID":"/posts/edb65560/:0:0","tags":["tools","loadrunner"],"title":"LoadRunner 11 安装及破解","uri":"/posts/edb65560/"},{"categories":["容器","Docker"],"content":"Docker 简介 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于 操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。 Docker 特性 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。 而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展 Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 对比传统虚拟机 特性 容器 虚拟机 部署难度 非常简单 相对复杂 启动 秒级 分钟级 存储 一般为MB 一般为GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 可移植性 轻量、灵活 笨重、与虚拟化技术耦合度高 下面的图片比较了 Docker 和传统虚拟化方式的不同之处。 传统虚拟化技术是虚拟一套硬件后，然后安装运行一个完整操作系统，在该系统上再运行所需应用进程，而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 Docker 基本概念 Docker 包括三个基本概念 镜像（Image） 容器（Container） 仓库（Repository） 理解了这三个概念，就理解了 Docker 的整个生命周期。 镜像（Image） 我们都知道，操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。 Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 容器（Container） 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。 仓库（Repository） 镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 \u003c仓库名\u003e:\u003c标签\u003e 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，16.04, 18.04。我们可以通过 ubuntu:16.04，或者 ubuntu:18.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。 ","date":"2015-08-13","objectID":"/posts/557f44df/:0:0","tags":["docker"],"title":"Docker简介概述","uri":"/posts/557f44df/"},{"categories":["Web相关","Apache"],"content":"当前WEB服务器中联接次数最多的ip地址 $ netstat -ntu |awk '{print $5}' |sort | uniq -c| sort -nr 查看日志中访问次数最多的前10个IP $ cat access.log |cut -d ' ' -f 1 |sort |uniq -c | sort -nr | awk '{print $0 }' | head -n 10 |less 查看日志中出现100次以上的IP $ cat access.log |cut -d ' ' -f 1 |sort |uniq -c | awk '{if ($1 \u003e 100) print $0}'｜sort -nr |less 查看最近访问量最高的文件 $ cat access.log |tail -10000|awk '{print $7}'|sort|uniq -c|sort -nr|less 查看日志中访问超过100次的页面 $ cat access.log | cut -d ' ' -f 7 | sort |uniq -c | awk '{if ($1 \u003e 100) print $0}' | less 统计某url，一天的访问次数 $ cat access.log|grep '12/Aug/2009'|grep '/images/index/e1.gif'|wc|awk '{print $1}' 前五天的访问次数最多的网页 $ cat access.log|awk '{print $7}'|uniq -c |sort -n -r|head -20 从日志里查看该ip在干嘛 $ cat access.log | grep 218.66.36.119| awk '{print $1″\\t”$7}' | sort | uniq -c | sort -nr | less 列出传输时间超过 30 秒的文件 $ cat access.log|awk '($NF \u003e 30){print $7}' |sort -n|uniq -c|sort -nr|head -20 列出最最耗时的页面(超过60秒的) $ cat access.log |awk '($NF \u003e 60 \u0026\u0026 $7~/\\.php/){print $7}' |sort -n|uniq -c|sort -nr|head -100 ","date":"2015-08-12","objectID":"/posts/e3d0f43e/:0:0","tags":["apache","log"],"title":"Apache访问日志分析","uri":"/posts/e3d0f43e/"},{"categories":["Web相关","Nginx"],"content":"域名重写 我们可以在同一个server中绑定域名www.example.com和example.com两个域名： server { listen 80; server_name example.com www.example.com; } 但是这样对我们的SEO非常不利，我们需要使用301（rewrite）将一个域名重定向到另一个，比如将example重定向到www.example.com。这里要依赖于正则表达式的分组（使用$1来引用分组）。 server { listen 80; server_name example.com www.example.com; if($host!= 'www.example.com'){ rewrite ^/(.*)$ http://www.example.com/$1 permanent; }} http重写到https 另一个需求是将两个域名的所有的http请求转发到https上，提高安全级别，同时实现二级域名转向一级域名。 server { listen 80; server_name www.debugo.com debugo.com; rewrite ^(.*)$ https://$host$1 permanent; } server { listen 443 ssl; ssl_certificate /etc/nginx/server.crt; ssl_certificate_key /etc/nginx/server.key; server_name www.debugo.com debugo.com; root /webrooot; index index.html index.htm; if ($host != 'debugo.com') { rewrite ^/(.*)$ https://debugo.com/$1 permanent; } #... } 静动态分离 我们通常有自己的动态语言服务器（例如Python wsgi，Node.JS），而静态文件我们又希望使用Nginx来管理，提供缓存等功能。就要使用到下面的配置： location ~ .*\\.(html|htm|gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ { root /web/build; } location / { proxy_pass http://54.3.6.34:8000; proxy_redirect off; proxy_set_header HOST $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; } } ","date":"2015-06-24","objectID":"/posts/bfc48fed/:0:0","tags":["nginx","tools"],"title":"Nginx重定向\u0026静动资源分离","uri":"/posts/bfc48fed/"},{"categories":["Linux/Unix"],"content":" 问题： 我的程序在其内部创建并执行了多个线程，我怎样才能在该程序创建线程后监控其中单个线程？我想要看到带有它们名称的单个线程详细情况（如，CPU/内存使用率）。 线程是现代操作系统上进行并行执行的一个流行的编程方面的抽象概念。当一个程序内有多个线程被叉分出用以执行多个流时，这些线程就会在它们之间共享特定的资源（如，内存地址空间、打开的文件），以使叉分开销最小化，并避免大量高成本的IPC（进程间通信）通道。这些功能让线程在并发执行时成为一个高效的机制。 在Linux中，程序中创建的线程（也称为轻量级进程，LWP）会具有和程序的PID相同的“线程组ID”。然后，各个线程会获得其自身的线程ID（TID）。对于Linux内核调度器而言，线程不过是恰好共享特定资源的标准的进程而已。经典的命令行工具，如ps或top，都可以用来显示线程级别的信息，只是默认情况下它们显示进程级别的信息。 这里提供了在Linux上显示某个进程的线程的几种方式。 方法一：PS 在ps命令中，“-T”选项可以开启线程查看。下面的命令列出了由进程号为的进程创建的所有线程。 $ ps -T -p \u003cpid\u003e “SID”栏表示线程ID，而“CMD”栏则显示了线程名称。 方法二： Top top命令可以实时显示各个线程情况。要在top输出中开启线程查看，请调用top命令的“-H”选项，该选项会列出所有Linux线程。在top运行时，你也可以通过按“H”键将线程查看模式切换为开或关。 $ top -H 要让top输出某个特定进程并检查该进程内运行的线程状况： $ top -H -p \u003cpid\u003e 方法三： Htop 一个对用户更加友好的方式是，通过htop查看单个进程的线程，它是一个基于ncurses的交互进程查看器。该程序允许你在树状视图中监控单个独立线程。 要在htop中启用线程查看，请开启htop，然后按来进入htop的设置菜单。选择“设置”栏下面的“显示选项”，然后开启“树状视图”和“显示自定义线程名”选项。按退出设置。 现在，你就会看到下面这样单个进程的线程视图。 ","date":"2015-06-19","objectID":"/posts/8c6e7157/:0:0","tags":["linux","进程"],"title":"Linux上如何查看某个进程的线程","uri":"/posts/8c6e7157/"},{"categories":["编程语言"],"content":"学习一门新的语言是一种冒险。我总是热衷于尝试新的东西——学习新的语法，了解不同的模式，乃至彻底改变思维方式。不幸的是，许多开发人员对此不以为然，甚至可能是深恶痛绝的——学习新语言，就得走出舒适区，花时间花精力来学习新的理念和方法。 这段日子，我每天都要用大约5种不同的语言来写不同的项目！ 我应该先学哪种语言？ 有关这方面的讨论真可谓数不胜数。很多刚进入编程社区的初学者，都会问这个问题，简直就是前赴后继。有些人建议先学不费力的，如Python和Ruby，也有的人认为应该先学例如C、C++和GO这类难一些的低层次的内容。我要说的是我们在选择新的语言之前，应该注意以下几个要点。 类型系统 从我的经验和先前的学习路径看，这是最重要的概念之一。我很庆幸我一开始学的是C，接着尝试了C++，一段时间之后，我又投入了Java的怀抱。然后是Scala，以及现在我开始玩Ruby。同时，我对Objective-C、Python、甚至是OCaml也有所涉及。哦，对了，最近我正在捣鼓Swift和CoffeeScript。 如果我一开始学的是JavaScript、Python或Ruby，那么后面去理解什么是类型和变量就会非常困难。理解静态和动态以及弱类型和强类型系统之间的区别，对于领悟语言的工作原理是至关重要的。我无法想象，如果我一开始不能掌控类型，那么后面涉及到的声明与定义，以及汇编与解释之间的差异，会是让人多么头大的一件事。 不过，也有很多开发人员希望能有立竿见影的效果：既想快速看到结果，又不愿意过多地了解细节。他们喜欢接轨新的应用程序。最好是不用动脑子的语言，碰到这样的他们最开心了。因为在他们眼中，掌握 integer、string和boolean是学习编程的超级大障碍。最好能够毋须分辨类、对象和方法，直接写代码： scala\u003e println(“Hello World!”) Hello World! \u003e\u003e\u003e print \"Hello World!\" Hello World! 2.2.1 :001 \u003e puts \"Hello World!\" Hello World! 不可否认这种途径能够给人信心，让人觉得自己学到了新的东西。 首先，请明确你属于哪种类型，摆正自己的位置。你想要探究隐藏起来的工作原理吗，喜欢深入研究本地执行吗？愿意去理解语言结构吗？又或者你只在乎能有快速的结果，不想了解虚拟机和编译工作，并且语言内部机制对你而言也一点都不重要？ 从自己的利益角度考虑 你可能需要处理哪些数据？你打算写复杂的业务系统还是相对简单的CRUD创业公司？请基于可能会让自己感兴趣的内容来确定工作领域。 所以，如果你确定你想要去企业工作，那么你可以试试Java或者.NET。如果你倾向于黑客并高度注重安全问题，那么不妨学习C/C ++或Bash。如果你梦想成为一名Web开发人员，那么先掌握PHP、JavaScript或Ruby吧。如果你想要编写一些机器、机器人、汽车或其他电子方面的程序——也行，先学C ++或Python吧。你喜欢捣鼓移动设备？那么Java、Swift或C＃就应该是你的首选。如果你喜欢数学和算法，那么Lua、Erlang或R就很适合你。等等等等，不胜枚举。总之——一切取决于你的目的和爱好。 语言内部机制 你有组织化的堆栈内存吗？你在程序中传递变量时使用引用类型还是只使用值类型？你是否利用指针和析构函数来控制对象的生命周期？你是自行清理存储器还是使用相关的垃圾收集器？你是否计算和跟踪引用类型和子类？ 这些都是我们平时不会关心的问题。但是有时候，它们却是一些你不得不处理的概念，所以理解内部机制很重要。虽然现在你会觉得这些概念很复杂，理解起来很难，因为终有一天，你会庆幸自己现在的选择，有道是，书到用时方恨少，不要到用的时候追悔莫及。 我应该学习哪些语言？ 社区——StackOverflow、Reddit 下面是一些Reddit上面有关于通用编程的内容： http://www.reddit.com/r/programmers http://www.reddit.com/r/cscareerquestions/ http://www.reddit.com/r/learnprogramming/ http://www.reddit.com/r/programming 你也点击 http://stackoverflow.com/tags 或 http://www.reddit.com/subreddits 在特定的语言社区中寻求帮助。许多乐于助人的高手就在那里等你。 函数库 函数库之所以重要是因为它能让你有效利用现有资源，而不必再“重新发明轮子”。我们通常需要解决特定问题，实现业务规则，处理重要进程，从数组中找出所需元素，利用给定字符串，过滤特定集合等等。最好语言本身或者第三方函数库能够提供一些可以加快开发进程的实用程序、辅助工具和数据结构。 下面是一些不同语言的社区函数库代码仓库： iOS：https://cocoapods.org/ Android：https://android-arsenal.com/ Java、Scala、Groovy：https://search.maven.org/ Haskell：https://hackage.haskell.org/packages/ GO：http://golang.org/pkg/ Ruby：https://rubygems.org/ Python：https://pypi.python.org/pypi .NET：https://www.nuget.org/packages JavaScript：https://www.npmjs.com/ 保持对第三方支持可扩展性、开放性和易于集成等方面的审查。 从创造者/维护人员那儿获得文档和支持 你阅读文档吗？文档是不是易于理解的，全面的，最新的？更新频率如何？有多少维护人员，是否也在社区中？从文档中你能提取多少信息？你能否轻松驾驭不同的部分？ 这是一个非常有效的观察报告。只要有创造者提供有助于学习和理解语言的文档，其他的其实无所谓。例如，Ruby就有不少提供文档的网站，如：https://www.omniref.com/，http://ruby-doc.org/。 Scala也有相当不错的API说明书http://www.scala-lang.org/api/current/。 语言的创造者对待社区的态度也很重要。他能否像Ruby创始人Matz一样愿意接受和倾听反馈？他是否像Scala之父Martin Odersky一样有着纯粹的经营方针？又或者他是否会像Clojure的发明者一样鼓励社区发展？ 资源和实例——博客、GitHub代码仓库 下面是一些可作为起步指导的好例子： http://docs.scala-lang.org/overviews/ https://www.ruby-lang.org/en/documentation/ https://developer.apple.com/library/ios/documentation/Swift/Conceptual/-Swift_Programming_Language/index.html http://arcturo.github.io/library/coffeescript/,http://autotelicum.github.io/Smooth-CoffeeScript/ 至于网上教程，下面这些是很不错的门户网站，如： https://www.codeschool.com/ http://www.codecademy.com/ http://www.pluralsight.com/ http://teamtreehouse.com/ http://tutsplus.com/ http://www.lynda.com/ https://www.udemy.com/ 不妨去看一看。 资金 没错，前面我们谈论了思想、激情，以及一些抽象的概念，但是最后所有这一切都归结到资金，也就是金钱。在选择语言之前最好先搞清楚哪种薪酬/需求相对比较高。当然，你也可以纯粹是因为好玩而选择它。新事物总在不断地出现和发展，虽然这可以拓宽我们的视野，但学一些有用的东西还是非常重要的。在这种情况下你有以下两种解决方案： 学习当前市场上最流行/需求量最大的语言/技术/框架。这能确保你不但能找到工作，还能获得优渥的报酬。 按照自己的观点学习。这可能有点难以想象。因为谁也不能打包票说下一个流行的就一定是这种编程语言。试想一下，10年前你要是说Ruby会成为当前社会的宠儿，谁会相信。还有Scala和GO，没人知道之后，比如说，5年以后它们会发生什么变化。如果你现在选择了它们——那么，要么你将成为高薪专家，因为以后会变得非常普及；要么你只是掌握了一种没用的，被淘汰的语言。 点击这里查看市场分析：https://gooroo.io/analytics。 我要不要一次学习多种编程语言？ 刚开始——不要这么做。从长远来看——是的，你应该学习多种编程语言。 当你刚踏上编程之旅时，你应该只专注于一种语言。你需要掌握所有的概念，全神贯注于学习某个特定区域。 当你已经是一个有一定经验的程序员，那情况就有所不同了。由于你已经知道内部机制和程序的工作原理，这时你需要做的就是学习新的语法和新的范式，因为很多概念在不同语言里面都是相通的。 万事开头难，一旦正确起步之后，就会像滚雪球一样越滚越顺。 总结 那么归根究底我们为什么要学习新的语言呢？因为没有哪种工具是适用于所有目标的。而我们有","date":"2015-06-19","objectID":"/posts/fdca3c9c/:0:0","tags":["编程","程序员"],"title":"如何成为一个通晓多种编程语言的程序员","uri":"/posts/fdca3c9c/"},{"categories":["Web相关","Nginx"],"content":"Nginx中upstream有以下几种方式： 轮询(weight=1) 默认选项，当weight不指定时，各服务器weight相同， 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 upstream bakend { server 192.168.1.10; server 192.168.1.11; } weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 如果后端服务器down掉，能自动剔除。 比如下面配置，则1.11服务器的访问量为1.10服务器的两倍。 upstream bakend { server 192.168.1.10 weight=1; server 192.168.1.11 weight=2; } ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session不能跨服务器的问题。 如果后端服务器down掉，要手工down掉。 upstream resinserver{ ip_hash; server 192.168.1.10:8080; server 192.168.1.11:8080; } fair（第三方插件） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream resinserver{ server 192.168.1.10:8080; server 192.168.1.11:8080; fair; } url_hash（第三方插件） 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存服务器时比较有效。 在upstream中加入hash语句，hash_method是使用的hash算法 upstream resinserver{ server 192.168.1.10:8080; server 192.168.1.11:8080; hash $request_uri; hash_method crc32; } 设备的状态有: down 表示单前的server暂时不参与负载 weight 权重,默认为1。 weight越大，负载的权重就越大。 max_fails 允许请求失败的次数默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误 fail_timeout max_fails次失败后，暂停的时间。 backup 备用服务器, 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 ","date":"2015-06-14","objectID":"/posts/1d31b1f3/:0:0","tags":["nginx"],"title":"Nginx中的upstream轮询机制介绍","uri":"/posts/1d31b1f3/"},{"categories":["编程语言","Python"],"content":"APScheduler是一个Python定时任务框架，使用起来十分方便。提供了基于日期、固定时间间隔以及crontab类型的任务，并且可以持久化任务、并以daemon方式运行应用。目前最新版本为3.0.x。 在APScheduler中有四个组件： **触发器(trigger)**包含调度逻辑，每一个作业有它自己的触发器，用于决定接下来哪一个作业会运行。除了他们自己初始配置意外，触发器完全是无状态的。 **作业存储(job store)**存储被调度的作业，默认的作业存储是简单地把作业保存在内存中，其他的作业存储是将作业保存在数据库中。一个作业的数据讲在保存在持久化作业存储时被序列化，并在加载时被反序列化。调度器不能分享同一个作业存储。 **执行器(executor)**处理作业的运行，他们通常通过在作业中提交制定的可调用对象到一个线程或者进城池来进行。当作业完成时，执行器将会通知调度器。 **调度器(scheduler)**是其他的组成部分。你通常在应用只有一个调度器，应用的开发者通常不会直接处理作业存储、调度器和触发器，相反，调度器提供了处理这些的合适的接口。配置作业存储和执行器可以在调度器中完成，例如添加、修改和移除作业。 你需要选择合适的调度器，这取决于你的应用环境和你使用APScheduler的目的。通常最常用的两个： BlockingScheduler: 当调度器是你应用中唯一要运行的东西时使用。 BackgroundScheduler: 当你不运行任何其他框架时使用，并希望调度器在你应用的后台执行。 安装APScheduler非常简单： pip install apscheduler 选择合适的作业存储，你需要决定是否需要作业持久化。如果你总是在应用开始时重建job，你可以直接使用默认的作业存储（MemoryJobStore).但是如果你需要将你的作业持久化，以避免应用崩溃和调度器重启时，你可以根据你的应用环境来选择具体的作业存储。例如：使用Mongo或者SQLAlchemyJobStore （用于支持大多数RDBMS） 然而，调度器的选择通常是为你如果你使用上面的框架之一。然而，默认的ThreadPoolExecutor 通常用于大多数用途。如果你的工作负载中有较大的CPU密集型操作，你可以考虑用ProcessPoolExecutor来使用更多的CPU核。你也可以在同一时间使用两者，将进程池调度器作为第二执行器。 配置调度器 APScheduler提供了许多不同的方式来配置调度器，你可以使用一个配置字典或者作为参数关键字的方式传入。你也可以先创建调度器，再配置和添加作业，这样你可以在不同的环境中得到更大的灵活性。 下面是一个简单使用BlockingScheduler，并使用默认内存存储和默认执行器。(默认选项分别是MemoryJobStore和ThreadPoolExecutor，其中线程池的最大线程数为10)。配置完成后使用start()方法来启动。 from apscheduler.schedulers.blocking import BlockingScheduler def my_job(): print 'hello world' sched = BlockingScheduler() sched.add_job(my_job, 'interval', seconds=5) sched.start() 在运行程序5秒后，将会输出第一个Hello world。 下面进行一个更复杂的配置，使用两个作业存储和两个调度器。在这个配置中，作业将使用mongo作业存储，信息写入到MongoDB中。 from pymongo import MongoClient from apscheduler.schedulers.blocking import BlockingScheduler from apscheduler.jobstores.mongodb import MongoDBJobStore from apscheduler.jobstores.memory import MemoryJobStore from apscheduler.executors.pool import ThreadPoolExecutor, ProcessPoolExecutor def my_job(): print 'hello world' host = '127.0.0.1' port = 27017 client = MongoClient(host, port) jobstores = { 'mongo': MongoDBJobStore(collection='job', database='test', client=client), 'default': MemoryJobStore() } executors = { 'default': ThreadPoolExecutor(10), 'processpool': ProcessPoolExecutor(3) } job_defaults = { 'coalesce': False, 'max_instances': 3 } scheduler = BlockingScheduler(jobstores=jobstores, executors=executors, job_defaults=job_defaults) scheduler.add_job(my_job, 'interval', seconds=5) try: scheduler.start() except SystemExit: client.close() 查询MongoDB可以看到作业的运行情况如下： { \"_id\" : \"55ca54ee4bb744f8a5ab08cc4319bc24\", \"next_run_time\" : 1434017278.797, \"job_state\" : new BinData(0, \"gAJ9cQEoVQRhcmdzcQIpVQhleGVjdXRvcnEDVQdkZWZhdWx0cQRVDW1heF9pbnN0YW5jZXNxBUsDVQRmdW5jcQZVD19fbWFpbl9fOm15X2pvYnEHVQJpZHEIVSA1NWNhNTRlZTRiYjc0NGY4YTVhYjA4Y2M0MzE5YmMyNHEJVQ1uZXh0X3J1bl90aW1lcQpjZGF0ZXRpbWUKZGF0ZXRpbWUKcQtVCgffBgsSBzoMKUhjcHl0egpfcApxDChVDUFzaWEvU2hhbmdoYWlxDU2AcEsAVQNDU1RxDnRScQ+GUnEQVQRuYW1lcRFVBm15X2pvYnESVRJtaXNmaXJlX2dyYWNlX3RpbWVxE0sBVQd0cmlnZ2VycRRjYXBzY2hlZHVsZXIudHJpZ2dlcnMuaW50ZXJ2YWwKSW50ZXJ2YWxUcmlnZ2VyCnEVKYFxFn1xF1UPaW50ZXJ2YWxfbGVuZ3RocRhHQBQAAAAAAABzfXEZKFUIdGltZXpvbmVxGmgMKGgNTehxSwBVA0xNVHEbdFJxHFUIaW50ZXJ2YWxxHWNkYXRldGltZQp0aW1lZGVsdGEKcR5LAEsFSwCHUnEfVQpzdGFydF9kYXRlcSBoC1UKB98GCxIHIQwpSGgPhlJxIVUIZW5kX2RhdGVxIk51hmJVCGNvYWxlc2NlcSOJVQd2ZXJzaW9ucSRLAVUGa3dhcmdzcSV9cSZ1Lg==\") } 操作作业 添加作业 上面是通过add_job()来添加作业，另外还有一种方式是通过scheduled_job()修饰器来修饰函数 @sched.scheduled_job('cron', id='my_job_id', day='last sun') def some_decorated_task(): print(\"I am printed at 00:00:00 on the last Sunday of every month!\") 移除作业 job = scheduler.add_job(myfunc, 'interval', minutes=2) job.remove() Same, using an explicit job ID: scheduler.add_job(myfunc, 'interval', minutes=2, id='my_job_id') scheduler.remove_job('my_job_id') 暂停和恢复作业 暂停作业: – apscheduler.job.Job.pause() – apscheduler.schedulers.base.BaseScheduler.pause_job() 恢复作业: – apscheduler.job.Job.resume() – apscheduler.schedulers.base.BaseScheduler.resume_job() 获得job列表 获得调度作业的列表，可以使用get_jobs()来完成，它会返回所有的job实例。或者使用print_jobs()来输出所有格式化的作业列表。 修改作业 def some_decorated_task(): print(\"I am printed at ","date":"2015-06-11","objectID":"/posts/961db27e/:0:0","tags":["python","APScheduler"],"title":"Python任务调度模块 – APScheduler","uri":"/posts/961db27e/"},{"categories":["Linux/Unix"],"content":"源服务器名称可能不太准确，意思是创建内网自己的私服，这样只要有Ubuntu通过该私服下载安装过软件，私服都会缓存，下一个Ubuntu的请求就直接从缓存中获取。 最近Ubuntu源服务器太慢了，北京的网络也够烂的。逼不得已！ 首先安装apt-cacher apt-get install apt-cacher 装的过程中选择Daemon方式。 装完后，/etc/default/apt-cacher 文件内容应该如下： AUTOSTART=1 所以服务应该已经启动了。 到/etc/apt-cacher/apt-cacher.conf文件中修改一行配置，允许任何客户端访问： allowed_hosts = * 重启服务 service apt-cacher restart 然后打开网页：http://your_ip:3142/apt-cacher 看到页面就说明服务器正常启动了。 在/etc/hosts文件中添加一行，可以帮助找到chrome依赖的dl.google.com 203.208.45.206 dl.google.com 在客户端的ubuntu机器上，创建文件 /etc/apt/apt.conf文件或者/etc/apt/apt.conf.d/01proxy文件 内容如下： Acquire::http::Proxy \"http://your_server:3142\"; 然后运行apt-get update, 为了确认真的起作用。可以查看apt-cacher的日志，到服务器上查看目录下的日志文件 /var/log/apt-cache,缓存存放地址 /var/cahe/apt-cacher/ ","date":"2015-05-18","objectID":"/posts/f67f52f9/:0:0","tags":["ubuntu","apt-cacher"],"title":"架设Ubuntu apt-cacher服务","uri":"/posts/f67f52f9/"},{"categories":["编程语言","Python"],"content":"cx_Freeze是一个打包Python应用的工具，通过cx_Freeze，可以制作Windows平台、MacOS平台、以及Linux平台的二进制可执行程序，使得Python应用能够在没有安装Python环境的机器上运行。 cx_Freeze的安装 同很多Python的第三方库类似，cx_Freeze也可以通过如下命令安装： pip install cx_Freeze 或者从官网下载安装包，解压后，切换目录至解压后的根目录，运行命令即可 python setup.py install 注意：在Windows平台上安装cx_Freeze时，也可以根据官网提供的链接，从SourceForge上下载二进制安装包直接安装，但一定要注意Python的版本问题，否则，打包的应用程序可能会因为Python.dll的版本问题而无法正常运行。 cx_Freeze的使用(Windows平台) 典型的setup脚本的写法 #! /usr/bin/env python # -*- coding: utf-8 -*- from cx_Freeze import setup, Executable base = None # base = 'Console' # base = 'ConsoleKeepPath' # base = 'Win32GUI' # base = 'Win32Service' executables = [ Executable('main.py', base = base) ] setup(name = 'main app', version = '1.0', description = 'main app', executables = executables ) 在Windows平台上，base的可选值有： None 普通的Python程序。也可以不指定，在Executable中忽略base参数即可。 Console Console应用程序（控制台应用程序）。 ConsoleKeepPath 保持相对路径的Console应用程序。 Win32GUI GUI应用程序。基于tkinter、wxPython、PyQt的Python GUI应用程序需要将base参数的值设为’Win32GUI’。 Win32Service Windows服务程序。 构建命令选项 构建时，只需要运行如下命令即可： python setup.py option 在Windows平台上，option 有以下几种可选值： build cx_Freeze的标准构建命令。 build_exe 构建一系列的可执行程序。 bdist_msi 构建Windows平台上的msi安装包。 注意：在Windows平台上，存放代码路径一定不要有中文，否则，在执行python setup.py bdist_msi时可能会遇到FCI Error。 自定义图标 通过 Executable 的 icon 参数可以指定应用程序的图标，默认为’Tcl/Tk’的图标。 如下例： executables = [ Executable('main.py', base = base, icon = 'main.ico') ] 程序资源文件 对于应用程序用到的图片以及其他素材, 特别是GUI程序中用到图片等资源文件，可以在成功构建可执行程序后手动拷贝到可执行程序的目录，保持相对路径不变即可。也可以通过修改构建文件中的include_files参数，直接打包。如下例： build_exe_options = { 'include_files' = ['...', '...'], ... } setup( ... options = {'build_exe': build_exe_options} 复杂应用程序的打包 通过Executable的includes, excludes, 以及 packages 三个选项可以有效地控制应用程序包含和排除的模块以及包依赖关系。 也可以通过设置setup函数的options选项来解决依赖问题。如下例： build_exe_options = { 'packages': ['os', 'sys'], 'includes': ['tkinter'], 'excludes': ['django'], ... } setup( ... options = {'build_exe': build_exe_options} ) 其他平台 在其他平台上，有如下构建选项可以构建对应平台的可执行文件： bdist_rpm 构建rpm安装包。 bdist_mac 构建Mac OS系统的程序安装包。 bdist_dmg 构建Mac OS系统的程序安装包。 说明 本文所给代码均在Python34 for Windows, cx_Freeze release 4.3.4 上运行通过。 参考 cx_Freeze Documentation ","date":"2015-05-17","objectID":"/posts/550b75c7/:0:0","tags":["cx_freeze","python"],"title":"cx_Freeze打包Python应用程序","uri":"/posts/550b75c7/"},{"categories":["虚拟化","OpenStack"],"content":"安装完 OpenStack Nova 以后过段时间就很容易忘记自己装的是哪个版本，OpenStack 开发进度很快，遇到问题到 mailing list 寻求帮助的时候最好带上 Nova 的版本号。如何知道自己安装的是哪个版本的 OpenStack Nova 呢？ 旧版本的 OpenStack Nova 提供了 version 的接口，不过只是针对开发人员，命令行工具没有面向系统管理员的接口，所以只能通过 python 调取 nava API 来获得version 信息： # nova-manage shell python Python 2.7.1+ (r271:86832, Apr 11 2011, 18:13:53) [GCC 4.5.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. (InteractiveConsole) \u003e\u003e\u003e from nova import version \u003e\u003e\u003e version.version_string() '2011.2' \u003e\u003e\u003e version.version_string_with_vcs() u'2011.2-workspace:tarmac-20110415024701-a9bdb77vaatk99lh' \u003e\u003e\u003e 新版本的 OpenStack Nova 提供了简单的管理员接口，不再需要通过 API 调用了： # nova-manage version list 2011.3-dev (2011.3-workspace:tarmac-20110428165803-elcz2wp2syfzvxm8) ","date":"2015-05-15","objectID":"/posts/a1022384/:0:0","tags":["openstack","nova"],"title":"如何知道 OpenStack Nova 的安装版本号？","uri":"/posts/a1022384/"},{"categories":["渗透测试","Kali Linux"],"content":"推荐的更新源 在安装完Kali后，需要对软件及系统进行更新，选择更新源是是十分重要的，虽然网上存在各种更新源，但是如果是一个新手的话，建议只选择官方的更新源，可以避免学习过程中遇到一些不必要的麻烦，而且目前官方源更新下载的速度也是很快的。 官方源： deb http://http.kali.org/kali kali-rolling main non-free contrib 中科大源： deb http://mirrors.ustc.edu.cn/kali kali-rolling main non-free contrib 添加更新源 更新源路径： /etc/apt/sources.list 往 sources. list 中添加官方源，保存。 常用更新命令 apt update //检测可更新的软件 apt upgrade //自动更新并安装软件 apt dist-upgrade //检测并进行系统升级 常用清理命令 apt autoremove //卸载过期的软件包 apt autosudo //清理无用的软件包 apt autoclean //清理缓存 apt clean //强制清理缓存 需要注意的问题 在下载过程中如果出现Hash检验值不符不会软件是不会安装的 可能会出现 签名无效，GPG错误 的提示 执行命令：apt-key adv --keyserver hkp://keys.gnupg.net --recv-keys 7D8D0BF6 然后就可以正常更新了。 ","date":"2015-04-24","objectID":"/posts/5dbca548/:0:0","tags":["linux","kali"],"title":"Kali Linux的更新及清理","uri":"/posts/5dbca548/"},{"categories":["Linux/Unix"],"content":"我们经常需要到检查家里与办公室之间的网络是否连通，那么我们要怎么做呢？打开网站Speedtest.net然后开始测试。网站是通过加载浏览器中的JavaScript脚本然后选择最佳的服务器测速然后用Flash产生图形化的结果。 那么远程服务器呢？要知道大多数远程服务器是没有浏览器可以打开web页面的。用浏览器打开网页测速的瓶颈就在此，你不能按计划的对服务器进行定期的常规测试。这时需要到一个名为Speedtest-cli的软件来打破这个瓶颈，它能让你通过命令行来测试互联网连接的速度。 Speedtest-cli是什么 此程序是基于Python开发的脚本程序，利用了speedtest.net的服务来测量出上下行的宽带。Speedtest-cli能根据机房离测速服务器的物理距离来列出测速服务器，或者针对某一服务器进行测速，同时还能为你生成一个URL以便你分享你的测速结果。 要在Linux上安装最新版本的speedtest-cli，你必须安装2.4-3.4或者更高版本的Python。 在Linux上安装speedtest-cli 有两种方法可以安装speedtest-cli。第一种方法需要用到python-pip包管理器，第二种方法需要安装Python脚本，生成安装文件然后运行，这里我们分别介绍两种方法： 使用pythin-pip安装speedtest-cli 首先你需要安装python-pip包管理器，之后你就可以用pip命令来安装speedtest-cli $ sudo apt-get install python-pip $ sudo pip install speedtest-cli 如果要把speedtest-cli升级至最新版本，你需要输入以下命令 $ sudo pip install speedtest-cli --upgrade 通过Pyhton脚本来安装speedtest-cli 首先要用wget命令从github上下来Python脚本，然后解压提取下载的文件（master.zip) $ wget https://github.com/sivel/speedtest-cli/archive/master.zip $ unzip master.zip 提取出文件后，进入提取出的目录speedtest-cli-master然后使脚本可以执行。 $ cd speedtest-cli-master/ $ chmod 755 speedtest_cli.py 下一步，把可执行的脚本移动到/usr/bin文件夹，这样你就不用每次都输入完整的脚本路径了。 $ sudo mv speedtest_cli.py /usr/bin/ 用speedtest-cli测试互联网连通速度 要测试你的下载与上传速度，只需要运行speedtest-cli命令，不需要带参数。 $ speedtest_cli.py 在Linux下测试上传下载速度 测试上传下载的速度（以字节计算） $ speedtest_cli.py --bytes 测试bytes的速度 工具提供一个链接来下载由你的宽带测试结果生成的图片，你可以分享给你的家人朋友。 分享测速结果 下面的图片就是你通过以上的命令行测速而生成的图片 测速结果 如果你仅仅需要Ping，上传，下载的结果，就运行以下命令： $ speedtest_cli.py --simple 测试Ping，上传，下载的速度 列出speedtest.net所有的服务器距离你的物理距离，单位是千米（km） $ speedtest_cli.py --list 列出Speedtest.net的服务器 当获得一个非常长的服务器列表之后，怎么列出我想要的某个服务器？如果我要在speedtest.net服务器列表中找出位于Mumbai（印度）的服务器呢？ $ speedtest_cli.py --list | grep -i Mumbai 列出最近的服务器 对指定的服务器进行测速。我们使用上面例子5和例子6中获取的服务器ID: $ speedtest_cli.py --server [server ID] $ speedtest_cli.py --server [5060] ## 这里使用服务器ID为5060作为例子 对指定的服务器进行测速 输出speedtest-cli的版本信息和帮助文档 $ speedtest_cli.py --version 输出版本号 $ speedtest_cli.py --help 输出帮助文档 提醒 报告中的延迟并不是确切的结果，不应该过于依赖它；这个数值可以当作相对延迟，这对你选择某一测试服务器来说是可靠的。同时，CPU和内存的容量会影响结果的准确度。 结论 系统管理员和开发者应该必备这个简单的脚本工具，这个轻量级的工具功能齐全，真是太赞了。我不喜欢Speedtest.net的原因是它使用来flash，相反speedtest-cli刚好戳中了我的痛点。 speedtest_cli是一个第三方工具，也不能自动地记录下宽带速度。Speedtest.net拥有上百万的用户，你可以自己配制一个小型的测速服务器。 ","date":"2015-03-19","objectID":"/posts/d388be37/:0:0","tags":["linux","speedtest-cli"],"title":"用命令行工具 speedtest-cli 来测试你的网速","uri":"/posts/d388be37/"},{"categories":["编程语言","Python"],"content":"在许多编程语言中都包含有格式化字符串的功能，比如C和Fortran语言中的格式化输入输出。Python中内置有对字符串进行格式化的操作%。 模板 格式化字符串时，Python使用一个字符串作为模板 。模板中有格式符，这些格式符为真实值预留位置，并说明真实数值应该呈现的格式。Python用一个tuple将多个值传递给模板，每个值对应一个格式符。 比如下面的例子： print(\"I'm %s. I'm %d year old\" % ('Vamei', 99)) 上面的例子中，“I’m %s. I’m %d year old” 为我们的模板。 %s为第一个格式符，表示一个字符串。 %d为第二个格式符，表示一个整数。 (‘Vamei’, 99)的两个元素’Vamei’和99为替换%s和%d的真实值。 在模板和tuple之间，有一个%号分隔，它代表了格式化操作。 整个”I’m %s. I’m %d year old” % (‘Vamei’, 99) 实际上构成一个字符串表达式。我们可以像一个正常的字符串那样，将它赋值给某个变量。比如: a = \"I'm %s. I'm %d year old\" % ('Vamei', 99) print(a) 我们还可以用词典来传递真实值。如下： print(\"I'm %(name)s. I'm %(age)d year old\" % {'name':'Vamei', 'age':99}) 可以看到，我们对两个格式符进行了命名。命名使用()括起来。每个命名对应词典的一个key。 格式符 格式符为真实值预留位置，并控制显示的格式。格式符可以包含有一个类型码，用以控制显示的类型，如下: 格式符 描述 %s 字符串 (采用str()的显示) %r 字符串 (采用repr()的显示) %c 单个字符 %b 二进制整数 %d 十进制整数 %i 十进制整数 %o 八进制整数 %x 十六进制整数 %e 指数 (基底写为e) %E 指数 (基底写为E) %f 浮点数 %F 浮点数，与上相同 %g 指数(e)或浮点数 (根据显示长度) %G 指数(E)或浮点数 (根据显示长度) %% 字符”%” 可以用如下的方式，对格式进行进一步的控制： %[(name)][flags][width].[precision]typecode (name)为命名 flags可以有+,-,’ ‘或0。+表示右对齐。-表示左对齐。’ ‘为一个空格，表示在正数的左侧填充一个空格，从而与负数对齐。0表示使用0填充。 width表示显示宽度 precision表示小数点后精度 比如： print(\"%+10x\" % 10) print(\"%04d\" % 5) print(\"%6.3f\" % 2.3) 上面的width, precision为两个整数。我们可以利用*，来动态代入这两个量。比如： print(\"%.*f\" % (4, 1.2)) Python实际上用4来替换*。所以实际的模板为”%.4f”。 总结 Python中内置的%操作符可用于格式化字符串操作，控制字符串的呈现格式。Python中还有其他的格式化字符串的方式，但%操作符的使用是最方便的。 ","date":"2015-01-31","objectID":"/posts/7ebc6f83/:0:0","tags":["python"],"title":"Python 格式化字符串 (%操作符)","uri":"/posts/7ebc6f83/"},{"categories":["Linux/Unix"],"content":"在我们进行远程文件操作的时候，我们经常会出现文件服务出现卸载掉哦情况。 umount /mnt/ umount: /mnt/: device is busy. (In some cases useful info about processes that use the device is found by lsof(8) or fuser(1)) 解决方法: 查找使用这个文件的进程和命令，具体的操作代码 [root@localhost ~]# lsof |grep /mnt/ lsof: WARNING: can't stat() cifs file system /mnt/ Output information may be incomplete. bash 18841 root cwd unknown /mnt/TDDOWNLOAD/软件 (stat: No such device) 然后执行ps命令可以查找执行此进程的命令 [root@localhost ~]# ps -ef|grep 18841 root 18841 18839 0 Nov29 pts/2 00:00:00 /bin/bash -l root 29496 25604 0 16:26 pts/0 00:00:00 grep 18841 强行结束无关进程 [root@localhost ~]# kill -9 18841 然后卸载相关挂载 [root@localhost ~]# umount /mnt/net1 然后可以再通过mount命令进行查看。 ","date":"2015-01-31","objectID":"/posts/d4af459a/:0:0","tags":["umount","linux"],"title":"解决Linux下取消挂载提示:device is busy","uri":"/posts/d4af459a/"},{"categories":["Linux/Unix"],"content":"今天给Centos通过rpm -Uvh装了个epel的扩展后，执行yum list就开始报错： Error: Cannot retrieve metalink for repository: epel. Please verify its path and try again 在网上查了查，解决办法是编辑/etc/yum.repos.d/epel.repo，把基础的恢复，镜像的地址注释掉 #baseurl mirrorlist 改成 baseurl #mirrorlist 注意： 安装epel时区分i386 \\ x86_64，对应安装软件包，别忘了检查操作系统内核版本,如果装错包了也会报错！ 哎呀，忘记把报错信息站出来了。下次把报错信息补上。 ","date":"2015-01-27","objectID":"/posts/d3fa1f95/:0:0","tags":["epel","yum","Cobbler"],"title":"运行yum报错Error: Cannot retrieve metalink for repository: epel","uri":"/posts/d3fa1f95/"},{"categories":["Windows","Office"],"content":" 先卸载原有office，再安装office2010.还不行使用下面方法是一下： 使用组合键 Win+R 打开“运行”对话框，输入 regedit 并回车（可能需要管理员权限） 找到这个键值 HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Installer\\UserData 右击“UserData” 选择“权限(P)…” 点击“高级(V)”按钮 选定“Administrators……”，勾选“替换子容器和对象的所有者(R)”，点击“应用(A)”，将“当前所有者(C)：”更改为“Administrators……” “权限项目(T)：”选定“Administrators……”，勾选“使用可从此对象继承的权限替换所有子对象权限(P)”，点击“确定”按钮 ","date":"2015-01-14","objectID":"/posts/d14dfb/:0:0","tags":["office",1042],"title":"解决Office 2010安装错误:1402","uri":"/posts/d14dfb/"},{"categories":["DevOps","Ansible"],"content":"前言 AnsibleWorks成立于2012年，由自动化工具Cobbler及Func的开发者Michael DeHaan创建。其Ansible平台是一个开源的配置及计算机管理平台。可实现多节点的软件部署，执行特定任务并进行配置管理。 Ansible 跟其他IT自动化技术的区别在于其关注点并非配置管理、应用部署或IT流程工作流，而是提供一个统一的界面来协调所有的IT自动化功能，因此 Ansible的系统更加易用，部署更快。受管理的节点无需安装额外的远程控制软件，由平台通过SSH（Secure SHell）对其进行管理，因此十分方便。其模块支持JSON等标准输出格式，可采用任何编程语言重写。 Ansible可以让用户避免编写脚本或代码来管理应用，同时还能搭建工作流实现IT任务的自动化执行。IT自动化可以降低技术门槛及对传统IT的依赖，从而加快项目的交付速度。 Ansible有如下优点： 轻量级，他不需要去客户端安装agent，更新时，只需要在操作机上进行一次更新即可 批量任务执行可以写成脚本，而且不用分发到远程就可以执行 使用python编写的，维护更简单 支持sudo 安装Ansible 创建ansible用户 [root@node1 ~]# useradd ansible [root@node1 ~]# passwd ansible 更改用户 ansible 的密码 。 新的 密码： 重新输入新的 密码： passwd： 所有的身份验证令牌已经成功更新。 允许执行sudo [root@node1 ~]# vi /etc/sudoers # Defaults requiretty //表示不需要控制终端 ansible ALL=(ALL) NOPASSWD:ALL 安装ansible [root@node1 ~]# yum install PyYAML.x86_64 python-paramiko.noarch python-jinja2.x86_64 python-devel -y [root@node1 ~]# wget https://pypi.python.org/packages/source/s/setuptools/setuptools-7.0.tar.gz [root@node1 ~]# tar zxvf setuptools-7.0.tar.gz [root@node1 ~]# cd setuptools-7.0 [root@node1 setuptools-7.0]# python setup.py install [root@node1 setuptools-7.0]# cd .. [root@node1 ~]# wget https://pypi.python.org/packages/source/a/ansible/ansible-1.7.2.tar.gz [root@node1 ~]# tar zxvf ansible-1.7.2.tar.gz [root@node1 ~]# cd ansible-1.7.2 [root@node1 ansible-1.7.2]# python setup.py build [root@node1 ansible-1.7.2]# python setup.py install [root@node1 ansible-1.7.2]# mkdir /etc/ansible [root@node1 ansible-1.7.2]# cp examples/ansible.cfg /etc/ansible/ [root@node1 ansible-1.7.2]# cp examples/hosts /etc/ansible/ 修改配置文件 [root@node1 ansible-1.7.2]# vi /etc/ansible/ansible.cfg hostfile = /etc/ansible/hosts library = /usr/share/ansible remote_tmp = $HOME/.ansible/tmp pattern = * forks = 5 poll_interval = 15 sudo_user = ansible #ask_sudo_pass = True #ask_pass = True transport = smart remote_port = 22 module_lang = C [root@node1 ansible-1.7.2]# vi /etc/ansible/hosts #server [localhost] 127.0.0.1 #client [client] 172.16.0.112 ssh互信 [root@node1 ansible-1.7.2]# su - ansible [ansible@node1 ~]$ [ansible@node1 ~]$ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/ansible/.ssh/id_rsa): Created directory '/home/ansible/.ssh'. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/ansible/.ssh/id_rsa. Your public key has been saved in /home/ansible/.ssh/id_rsa.pub. The key fingerprint is: dc:c9:ac:d8:46:81:37:72:08:f3:77:06:98:33:cb:5f ansible@node1 The key's randomart image is: +--[ RSA 2048]----+ | o o. | | +=o . | | .=+* o | | o* OE. | | .S.= | | +.. | | . + | | . | | | +-----------------+ [ansible@node1 ~]$ [ansible@node1 ~]$ ssh-keygen -t dsa Generating public/private dsa key pair. Enter file in which to save the key (/home/ansible/.ssh/id_dsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/ansible/.ssh/id_dsa. Your public key has been saved in /home/ansible/.ssh/id_dsa.pub. The key fingerprint is: b3:a6:94:bf:5c:21:a3:c5:8b:74:b8:a5:8c:62:34:d2 ansible@node1 The key's randomart image is: +--[ DSA 1024]----+ | | | | | | | . o | |. E o S . | | o . + X * . | | o . O + . | | . . . = . | | . +. | +-----------------+ [ansible@node1 ~]$ [ansible@node1 ~]$ cd .ssh/ [ansible@node1 .ssh]$ cat *.pub \u003e authorized_keys [ansible@node1 .ssh]$ chmod -R 700 . #测试本机互信 [ansible@node1 .ssh]$ ssh 127.0.0.1 The authenticity of host '127.0.0.1 (127.0.0.1)' can't be established. RSA key fingerprint is fa:73:59:f5:08:95:b2:2e:7f:3e:52:91:8a:e6:47:1f. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added '127.0.0.1' (RSA) to the list of known hosts. [ansible@node1 ~]$ exit logout Connection to 127.0.0.1 closed. 远程ssh互信配置测试 [ansible@node1 .ssh]$ scp authorized_keys ansible@172.16.0.112: The authenticity of host '172.16.0.112 (172.16.0.112)' can't be established. RSA key fingerprint is fa:73:59:f5:08:95:b2:2e:7f:3e:52:91:8","date":"2014-11-22","objectID":"/posts/7b524d8e/:0:0","tags":["devops","ansible"],"title":"Ansible安装及使用","uri":"/posts/7b524d8e/"},{"categories":["虚拟化","VMWare"],"content":"在电脑里装了VMware后，再要装xampp，十有八九就会出现这个问题： 10:21:18 [Apache] Problem detected! 10:21:18 [Apache] Port 443 in use by \"\"d:\\Program Files (x86)\\VM\\vmware-hostd.exe\" -u \"C:\\ProgramData\\VMware\\hostd\\config.xml\"\" with PID 2764! 10:21:18 [Apache] Apache WILL NOT start without the configured ports free! 10:21:18 [Apache] You need to uninstall/disable/reconfigure the blocking application 10:21:18 [Apache] or reconfigure Apache and the Control Panel to listen on a different port 这个问题是处在VMware上，VMware将443端口占用了，而apache也需要443端口。所以，想要开启apache的服务，必须要将VMware端口改变。 操作如下： 打开菜单 编辑→参数（Edit–\u003e Preferences），如下图： 选择 共享虚拟机（Shared VMs），点击禁用共享。这里的HTTPS端口是443，正是apache需要的。 为了方便vmware的使用,我们把443修改成任意一个空闲端口即可，如下图： 接下来启用共享，在开启apache，是不是问题就解决了呢？ ","date":"2014-11-14","objectID":"/posts/3123c592/:0:0","tags":[443,"vmware","xampp"],"title":"XAMPP 和 VMWare 的端口443冲突的解决","uri":"/posts/3123c592/"},{"categories":["Linux/Unix","LVM"],"content":"逻辑卷管理LVM是一个多才多艺的硬盘系统工具。无论在Linux或者其他类似的系统，都是非常的好用。传统分区使用固定大小分区，重新调整大小十分麻烦。但是，LVM可以创建和管理“逻辑”卷，而不是直接使用物理硬盘。可以让管理员弹性的管理逻辑卷的扩大缩小，操作简单，而不损坏已存储的数据。可以随意将新的硬盘添加到LVM，以直接扩展已经存在的逻辑卷。LVM并不需要重启就可以让内核知道分区的存在。 LVM使用分层结构，如下图所示。 图中顶部，首先是实际的物理磁盘及其划分的分区和其上的物理卷（PV）。一个或多个物理卷可以用来创建卷组（VG）。然后基于卷组可以创建逻辑卷（LV)。只要在卷组中有可用空间，就可以随心所欲的创建逻辑卷。文件系统就是在逻辑卷上创建的，然后可以在操作系统挂载和访问。 LVM测试说明 本文将介绍怎么在linux中创建和管理LVM卷。我们将会分成两个部分。第一个部分，我们首先要在一个硬盘上创建多个逻辑卷，然后将它们挂载在/lvm-mount目录。然后我们将要对创建好的卷调整大小。而第二部分，我们将会从另外一块硬盘增加额外的卷到LVM中。 准备磁盘分区 通过使用fdisk，创建磁盘分区。我们需要创建3个1G分区，注意，并不要求分区的大小一致。同样，分区需要使用‘8e’类型来使他们可用于LVM。 # fdisk /dev/sdb Command (m for help): n ## 新建 Command action e extended p primary partition (1-4) p ## 主分区 Partition number (1-4): 1 ## 分区号 First cylinder (1-1044, default 1): ## 回车用默认的1 Last cylinder, +cylinders or +size{K,M,G} (1-1044, default 1044): +1G ## 大小 Command (m for help): t ## 改变类型 Selected partition 1 Hex code (type L to list codes): 8e ## LVM 的分区代码 Changed system type of partition 1 to 8e (Linux LVM) 重复上面的操作来创建其他两个分区。分区创建完成后，我们应该有类似如下的输出： # fdisk -l Device Boot Start End Blocks Id System /dev/sdb1 1 132 1060258+ 8e Linux LVM /dev/sdb2 133 264 1060290 8e Linux LVM /dev/sdb3 265 396 1060290 8e Linux LVM 准备物理卷(PV) 刚创建的分区是用来储存物理卷的。LVM可以使用不同大小的物理卷。 # pvcreate /dev/sdb1 # pvcreate /dev/sdb2 # pvcreate /dev/sdb3 使用下列命令检查物理卷的创建情况。下面截取部分输出。\"/dev/sdb2\"是一个新的\"1.01 GiB\"物理卷。 # pvdisplay --- NEW Physical volume --- PV Name /dev/sdb2 VG Name PV Size 1.01 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID jszvzz-ENA2-g5Pd-irhV-T9wi-ZfA3-0xo092 使用下列命令可以删除物理卷。 # pvremove /dev/sdb1 准备卷组(VG) 下列命令用来创建名为’volume-group1’的卷组，使用/dev/sdb1, /dev/sdb2 和 /dev/sdb3创建。 # vgcreate volume-group1 /dev/sdb1 /dev/sdb2 /dev/sdb3 使用下列命令可以来验证卷组。 # vgdisplay --- Volume group --- VG Name volume-group1 System ID Format lvm2 Metadata Areas 3 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 3 Act PV 3 VG Size 3.02 GiB PE Size 4.00 MiB Total PE 774 Alloc PE / Size 0 / 0 Free PE / Size 774 / 3.02 GiB VG UUID bwd2pS-fkAz-lGVZ-qc7C-TaKv-fFUC-IzGNBK 从输出中，我们可以看见卷组的使用量/总量。物理卷给卷组提供空间。只要在这个卷组中还有可用空间，我们就可以随意创建逻辑卷。 使用下列命令删除卷组。 # vgremove volume-group1 创建逻辑卷(LV) 下列命令创建一个名为'1v1’、大小为100MB的逻辑卷。我们使用小分区减少执行时间。这个逻辑卷使用之前创建的卷组的空间。 # lvcreate -L 100M -n lv1 volume-group1 逻辑卷可使用lvdisplay命令查看。 # lvdisplay --- Logical volume --- LV Name /dev/volume-group1/lv1 VG Name volume-group1 LV UUID YNQ1aa-QVt1-hEj6-ArJX-I1Q4-y1h1-OFEtlW LV Write Access read/write LV Status available # open 0 LV Size 100.00 MiB Current LE 25 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:2 现在逻辑卷已经准备好了，我们可以格式化和挂载逻辑卷，就像其它ext2/3/4分区一样！ # mkfs.ext4 /dev/volume-group1/lv1 # mkdir /lvm-mount # mount /dev/volume-group1/lv1 /lvm-mount/ 一旦逻辑卷挂载，我们就可以到挂载点 /lvm-mount/ 上读写了。要创建和挂载其它的逻辑卷，我们重复这个过程。 最后，使用lvremove我们可以删除逻辑卷。 # umount /lvm-mount/ # lvremove /dev/volume-group1/lv1 扩展一个LVM卷 调整逻辑卷大小的功能是LVM最有用的功能。这个部分会讨论我们怎么样扩展一个存在的逻辑卷。下面，我们将会扩展先前创建的逻辑卷‘lv1’扩大到200MB。 注意，调整逻辑卷大小之后，也需要对文件系统调整大小进行匹配。这个额外的步骤各不相同，取决于创建文件系统的类型。在本文中，我们使用’lv1’创建了ext4类型的文件系统，所以这里的操作是针对ext4文件系统的。（ext2/3文件系统也类同）。命令的执行顺序是很重要的。 首先，我们卸载掉lv1卷 # umount /lvm-mount/ 然后，设置卷的大小为200M # lvresize -L 200M /dev/volume-group1/lv1 接下来，检查磁盘错误 # e2fsck -f /dev/volume-group1/lv1 运行以下命令扩展文件系统以后，ext4信息就更新了。 # resize2fs /dev/volume-group1/lv1 现在，这个逻辑卷应该已经扩展到200MB了。我们检查LV的状态来验证。 # lvdisplay --- Logical volume --- LV Name /dev/volume-group1/lv1 VG Name volume-group1 LV UUID 9RtmMY-0RIZ-Dq40-ySjU-vmrj-f1es-7rXBwa LV Write Access read/write LV Status available # open 0 LV Size 200.00 MiB Current LE 50 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:2 现在，这个逻辑卷可以再次挂载，同样这个方法也可用于其他分区。 缩减一个LVM卷 这章节介绍缩减LVM卷大小的方法。命令的顺序同样重要。并且，下列命令对ext2/3/4文件系统同样有效。 注意减少逻辑卷的大小值若小于储存的数据大小，存储在后面的数据会丢失。 首先，卸载掉卷。 # umount /dev/volume-group1/lv1 然后，检测磁盘错误。 # e2fsck -f /dev/volume-group1/lv1 接下来缩小文件系统，更新ext4信息。 # resize2fs /dev/volume-group1/lv1 100M 完成以后，减少逻辑卷大小 # lvresize -L 100M /dev/volume-gro","date":"2014-06-18","objectID":"/posts/50158b3/:0:0","tags":["LVM","分区","磁盘"],"title":"Linux LVM简明教程","uri":"/posts/50158b3/"},{"categories":["Linux/Unix"],"content":"Linux是一种自由和开放源代码的类UNIX操作系统.该操作系统的内核由林纳斯·托瓦兹在1991年10月5日首次发布。在加上用户空间的应用程序之后，成为Linux操作系统。Linux也是自由软件和开放源代码软件发展中最著名的例子。只要遵循GNU通用公共许可证，任何个人和机构都可以自由地使用Linux的所有底层源代码，也可以自由地修改和再发布。大多数Linux系统还包括像提供GUI的X Window之类的程序。除了一部分专家之外，大多数人都是直接使用Linux发行版，而不是自己选择每一样组件或自行设置。 Linux诞生 1991年，在赫尔辛基，Linus Torvalds开始那个后面成为了Linux内核的项目。最初它只是一个Torvalds用来访问大学里的大型的Unix服务器的虚拟终端。他专门写了一个用于他当时正在用的硬件的，与操作系统无关的程序，因为他要用他那用80386处理器的新PC机的功能。开发是在Minix上，用至今仍为首选的编译器——GCC——来完成的。 2002年的Linus Torvalds 1996年，Torvalds为Linux选定了企鹅作为它的吉祥物。Larry Ewing提供了吉祥物的初稿。现在正在使用的著名的吉祥物就是基于这份初稿的。James Hughes根据“Torvalds’s Unix”为它取了名字Tux。 Tux吉祥物 一些相关术语 FSF：Free Software Foundation自由软件基金会。 GPL：General Public License通用公共许可。是广泛使用的免费软件许可证，可以保证终端用户得自由运行，学习，共享和修改软件。GPL提供的Copyleft对于基于Linux的系统的成功至关重要，给予向内核贡献的程序员保证他们的工作将有益于整个世界并保持自由，而不至于被不提供回馈给社区的不肖软件公司所剥削。通俗地讲，就是软件行业的共产主义运动章程，目的保持开源软件最大自由。 BSD：Berkeley Software Distribution伯克利软件套件 GNU：GNU’s Not Unix! GNU操作系统起源于GNU计划，由理查·斯托曼在MIT人工智能实验室发起，希望发展出一套完整的开放源代码操作系统来取代Unix，计划中的操作系统，名为GNU。 ASF：Apache Software Foundation Apache软件基金会 Linux发行版 基于Dpkg (Debian系) Debian GNU / Linux是一种强调使用自由软件的发行版。它支持多种硬件平台。Debian及其派生发行版使用deb软件包格式，并使用dpkg及其前端作为包管理器。 商业发行版 Ubuntu，一个非常流行的桌面发行版，由Canonical维护。 社区发行版 Debian，一个强烈信奉自由软件，并由志愿者维护的系统。 Kubuntu, 使用KDE桌面的Ubuntu。 Linux Mint，从Ubuntu派生并与Ubuntu兼容的系统。 Knoppix，第一个Live CD发行版，可以从可移动介质运行，Debian的派生版。 OpenGEU，Ubuntu的派生版。 Elementary OS：基于Ubuntu，接口酷似Mac OS X。 gOS和其他上网本用的系统。 基于RPM (Red Hat系) Red Hat Linux和SUSE Linux是最早使用RPM格式软件包的发行版，如今RPM格式已广泛运用于众多的发行版。这两种发行版后来都分为商业版本和社区支持版本。Red Hat Linux的社区支持版本现称为Fedora，商业版本则称为Red Hat Enterprise Linux。 商业发行版 Red Hat Enterprise Linux，Fedora的商业版，由Red Hat维护和提供技术支持。 Mandriva，最初为Red Hat的派生版，现在由法国一个同名的公司维护。 openSUSE，最初由Slackware分离出来，现在由Novell维护。 社区发行版 Fedora，是Red Hat的社区版，会经常引入新特性进行测试。 PCLinuxOS，Mandriva的派生版本，由社区维护的非常流行的发行版。 CentOS，从Red Hat发展而来的发行版，由志愿者维护，旨在提供开源的，并与Red Hat 100%兼容的系统。 基于其他包格式 ArchLinux，一个基于KISS（Keep It Simple and Stupid）的滚动更新的操作系统。 Chakra，一个从ArchLinux派生出来，只使用KDE桌面的半滚动更新发行版。 Gentoo，一个面向高级用户的发行版，所有软件的源代码需要自行编译。 Slackware，最早的发行版之一，1993年创建，由Patrick J. Volkerding维护。 在DistroWatch网站可以看到很多发行版的排名和信息。 Linux包管理 最受欢迎的四个linux发行版的软件包管理方式。 Debian（包括 Ubuntu, Linux Mint, elementary OS, Zorin OS 和其他Debian衍生版本） OpenSUSE Fedora（包括 Red Hat Enterprise Linux, CentOS, Scientific Linux 和 基于Fedora的发行版） Mageia 和 OpenMandriva 在基于Fedora的发行版中，yum包管理器在2015年的某个时间点被替换为dnf（从Fedora 22开始），但目前看来大部分dnf软件包管理命令与yum命令保持一致（例外情况是“localinstall”，它尚未在dnf中实现，和“update”，这已被弃用，以支持“upgrade”）。 Ubuntu的当前版本使用apt来操作deb包。但是，Ubuntu的实验版本使用新的snap包管理器。 参考：https://distrowatch.com/dwres.php?resource=package-management 任务 apt (deb) Debian, Ubuntu zypp (rpm) openSUSE yum/dnf (rpm) Fedora, CentOS urpmi (rpm) Mandriva, Mageia 管理软件 从软件包存储库安装新软件 apt-get install pkg zypper install pkg yum install pkg urpmi pkg 从软件包文件安装新软件 dpkg -i pkg zypper install pkg yum localinstall pkg urpmi pkg 更新现有软件 apt-get install pkg zypper update -t package pkg yum update pkg urpmi pkg 删除不需要的软件 apt-get remove pkg zypper remove pkg yum erase pkg urpme pkg 更新系统 更新软件包列表 apt-get updateaptitude update zypper refresh yum check-update urpmi.update -a 更新系统 apt-get upgradeaptitude safe-upgrade zypper update yum update urpmi –auto-select 搜索软件包 按包名搜索 apt-cache search pkg zypper search pkg yum list pkg urpmq pkg 按模式搜索 apt-cache search pattern zypper search -t pattern pattern yum search pattern urpmq –fuzzy pkg 按文件名搜索 apt-file search path zypper wp file yum provides file urpmf file 列出已安装的包 dpkg -l zypper search -is rpm -qa rpm -qa 配置对软件存储库的访问 列出存储库 cat /etc/apt/sources.list zypper repos yum repolist urpmq –list-media 添加存储库 (edit /etc/apt/sources.list) zypper addrepo path name (add repo to /etc/yum.repos.d/) urpmi.addmedia name path 移除存储库 (edit /etc/apt/sources.list) zypper removerepo name (remove repo from /etc/yum.repos.d/) urpmi.removemedia media Linux发展时间线 如果想要看到更详细的Linux发展版本及发展分支。可以访问 http://futurist.se/gldt ","date":"2014-04-27","objectID":"/posts/735e3e61/:0:0","tags":["linux"],"title":"Linux发行版与区别","uri":"/posts/735e3e61/"},{"categories":["Linux/Unix"],"content":"进程是操作系统上非常重要的概念，所有系统上面跑的数据都会以进程的类型存在。在 Linux 系统当中：触发任何一个事件时，系统都会将它定义成为一个进程，并且给予这个进程一个 ID，称为 PID，同时根据触发这个进程的用户，给予这个 PID 一组有效的权限设置。 进程是什么样的 程序运行起来后，我们看不到也摸不着。因此 Linux 为我们提供了一系列方便的命名来查看正在运行的进程。首先是 ps 命令，比如 ps -l命令能查看当前 bash 下的相关进程全部信息。如下： $ ps -l F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 0 S 1000 2552 2538 0 80 0 - 1945 wait pts/0 00:00:00 bash 0 S 1000 9352 2552 0 80 0 - 1926 wait pts/0 00:00:00 bash 0 R 1000 9478 9352 0 80 0 - 1598 - pts/0 00:00:00 ps 另外，我们还可以用 pstree 命令来显示整棵进程树。 可以看到这里 init 进程是所有进程的根节点，使用ps命令还能看到 init 的 PID 为 1 。当Linux启动的时候，init 是系统创建的第一个进程，这一进程会一直存在，直到我们关闭计算机。所有其他的进程都是由 init 进程衍生出来的。 父进程 \u0026 子进程 上面提到所谓的“衍生出来的进程”正是 Linux 的父子进程的概念。当我们登录系统后，会取得一个 bash shell，然后我们利用这个 bash 提供的接口去执行另一个命令，例如 bash 或者 ps 等。那些另外执行的命令也会被触发成为 PID，那个后来执行的命令产生的 PID 就是“子进程”，而原本的 bash 环境下，就称为“父进程”了。 老进程成为新进程的父进程（parent process），而相应的，新进程就是老的进程的子进程（child process）。一个进程除了有一个PID之外，还会有一个PPID（parent PID）来存储的父进程 PID。如果我们循着 PPID 不断向上追溯的话，总会发现其源头是 init 进程。所以说，所有的进程也构成一个以 init 为根的树状结构。 我们使用 ps -o 命令来看一看现有的进程。 $ ps -o pid,ppid,comm PID PPID COMMAND 2552 2538 bash 9352 2552 bash 9625 9352 ps 我所做的操作是在原来的 bash shell 中执行了 bash 命令，然后又执行了 ps 命令。我们可以看到，第二个进程 bash 是第一个进程 bash 的子进程，而第三个进程ps是第二个进程的子进程。 fork \u0026 exec 当计算机开机的时候，内核（kernel）只建立了一个 init 进程。Linux kernel 并不提供直接建立新进程的系统调用。剩下的所有进程都是 init 进程通过 fork 机制建立的。新的进程要通过老的进程复制自身得到，这就是 fork。fork 是一个系统调用。进程存活于内存中。每个进程都在内存中分配有属于自己的一片空间 (内存空间，包含栈、堆、全局静态区、文本常量区、程序代码区)。当一个程序调用 fork 的时候，实际上就是将上面的内存空间，又复制出来一个，构成一个新的进程，并在内核中为该进程创建新的附加信息 (比如新的 PID，而 PPID 为原进程的 PID)。此后，两个进程分别地继续运行下去。新的进程和原有进程有相同的运行状态(相同的变量值，相同的指令…)。我们只能通过进程的附加信息来区分两者。 程序调用 exec 的时候，进程清空自身的内存空间，并根据新的程序文件重建程序代码、文本常量、全局静态、堆和栈(此时堆和栈大小都为 0)，并开始运行。 工作管理 这个工作管理（job control）是用在 bash 环境下的，也就是说，当我们登录系统取得 bash shell 之后，在单一终端机下可以同时进行多个工作的行为管理。 假如我们只有一个终端，因此在可以出现提示符让你操作的环境就成为前台（foreground），至于其他工作就可以放在后台（background）去暂停或运行。 工作管理的意义在于将多个工作囊括在一个终端，并取其中的一个工作作为前台，来直接接收该终端的输入输出以及终端信号。 其他工作在后台运行。 直接将命令丢到后台执行：\u0026 $ping localhost \u003e log \u0026 此时终端显示: [1] 9800 括号中的 1 表示工作号，而 9800 为 PID 将目前的工作丢到后台中“暂停”： [ctrl]+z $vim ~/.bashrc 在vim的普通模式下，按下[ctrl]+z的组合键 [2]+ 已停止 vim ~/.bashrc 查看目前的后台工作状态：jobs 其各个参数的含义如下 -l ：同时列出PID的号码 -r：仅列出正在后台run的工作 -s：仅列出在后台stop的工作 例如我们执行 $ jobs -l [1]- 9800 运行中 ping localhost \u003e log \u0026 [2]+ 9905 停止 vim ~/.bashrc 能看到目前有多少个工作在后台中，并且能看到这些工作的 PID。紧跟在 job number 后面的 + 代表最近放到后台的工作，- 代表最近最后第二个放到后台的工作，直接执行fg的话会先取+的 将后台工作拿到前台来处理：fg %jobnumber $cat \u003e log \u0026 $fg %1 当我们运行第一个命令后，由于工作在后台，我们无法对命令进行输入，直到我们将工作带入前台，才能向 cat 命令输入。在输入完成后，按下 CTRL+D 来通知 shell 输入结束。 让工作在后台下的状态变成运行中：bg %jobnumber 管理后台工作中的工作：kill 信号可以通过 kill 传递给进程，信号值以下三个比较重要。 -1 重新加载 （SIGHUP） -9 立刻删除 （SIGKILL） -15 正常终止（SIGTERM） 可以使用 $kill -SIGTERM 9800 或者 $kill -15 %1 的方式来发送给工作。上面的两个命令，一个是发送给信号给 PID 9800 ，一个是发送信号值给工作号1，两者等价。 监控进程的变化：top top 是一个很不错的程序查看工具，但不同于 ps 的静态结果输出，top 可以持续监测整个系统的进程工作状态，而且功能非常丰富，可以在 top 中输入?查看更多功能按键。常用的有 P 以CPU使用资源排序，M以物理内存使用排序。 常用的参数有-d可以修改进程界面更新的秒数，-p可以指定某些个 PID 来进行查看监测。 参考资料 鸟哥的Linux私房菜.基础学习篇 ","date":"2014-04-25","objectID":"/posts/77a6d209/:0:0","tags":["linux","进程"],"title":"Linux基础：进程管理","uri":"/posts/77a6d209/"},{"categories":["Linux/Unix"],"content":"在 Linux 下，所有的文件与目录都是由根目录（/）开始的。然后再一个一个分支下来，形成一棵繁杂的树。因此我们也称这种目录配置方式为“目录树”。那目录树与文件系统有什么关系，目录树是怎么实现的呢？ 目录 在 Linux 系统中，目录也是一种文件。我们可以使用 $ls -li来查看一个目录的属性。 $ls -li /home/user01 141494 drwxr-xr-x 18 user01 user01 4096 12月 2 2013 hadoop-1.1.1 1715845 drwxrwxr-x 2 user01 user01 4096 7月 12 09:07 input 1718481 -rw-rw-r-- 1 user01 user01 0 7月 12 16:11 test.txt 1718478 -rw-r--r-- 1 root root 1780292 6月 16 19:04 etc.jar.bz2 …… 其中-i参数是显示文件的 inode 号。可以看到第一列就是目录/文件的 inode 号。因此 ext 文件系统对于目录也会像对待文件一样分配其 inode 块和 block 块。只不过，在目录中 inode 块记录的是该目录的相关权限与属性以及分配到的 block 块号码，而 block 则记录的是这个目录下的/文件名/与该文件名占用的 inode 号码数据。 没错，在 Linux 中文件的 inode 中是不记录文件名的，文件名是记录在目录的 block 中。因此在新增/删除/重命名文件的时候，与目录的w权限有关。另一个直观的感受就是，你可以对正在使用的文件改名，换目录，甚至放到废纸篓，都不会影响当前文件的使用，这在 Windows 里是无法想象的。比如你打开个 Word 文件，然后对其进行重命名操作，Windows 会告诉你先给我关闭文件！ 当我们读取一个文件时，实际上是在目录中找到了这个文件的 inode 编号，然后根据 inode 中的 block 指针，把各个 block 数据块组合起来，放入内存供进一步的处理。当我们写入一个文件时，是分配一个空白inode给该文件，将其inode编号记入该文件所属的目录，然后选取空白的数据块，让inode的指针指像这些数据块，并放入内存中的数据。 硬链接与软链接 当文件出现在一个目录文件中时，我们就把文件接入到文件系统中（在目录中写入该文件的文件名和 inode 号），我们称建立一个到文件的硬链接（hard link）。一个文件允许出现在多个目录中，这样，它就有多个硬链接。当硬链接的数目（link count）降为0时，文件会被 Linux 删除。所以很多时候，unlink 与 remove 在 Linux 操作系统中是一个意思。引入硬链接的目的是为了“安全”，如果你将任何一个“文件名”删除，其实 inode 与 block 都还是存在的。此时可以通过另一个“文件名”来读取到正确的文件数据。此外，不论你使用哪个“文件名”来编辑，最终的结果都会写入到相同的 inode 与 block 中，因此均能进行数据的修改。 至于软链接（soft link），其实就是 Windows 上的快捷方式。基本上，软链接就是在创建一个新的独立的文件，而这个文件会让数据的读取指向它连接的那个文件的文件名。由于只是利用文件来作为指向的操作，所以，当源文件被删除后，软链接的文件会打不开。由于软链接（soft link）的广泛使用不会影响 link count，而且可以跨越文件系统，现在较少手动建立硬连接。 创建硬链接与软链接使用 ln 命令即可。 $ln [-s] 源文件 目标文件 -s : 如果不加任何参数就是硬链接，加上 -s 就是软链接 ~$ln -s /etc/crontab . ~$ln /etc/crontab crontab2 ~$ ll -i /etc/crontab ~/crontab ~/crontab2 1310870 -rw-r--r-- 2 root root 722 6月 15 2012 /etc/crontab 1310870 -rw-r--r-- 2 root root 722 6月 15 2012 /home/user01/crontab2 1718696 lrwxrwxrwx 1 user01 user01 12 7月 12 16:42 /home/user01/crontab -\u003e /etc/crontab 可以看到硬链接文件的 inode 是同一个，并且连接数变成了 2。而软链接是一个新的文件，拥有自己的 inode 号。 文件系统管理命令 $df 列出文件系统的整体磁盘使用量 -h 以人们容易阅读的 GB MB KB 等格式自行显示 -i 不使用硬盘容量，而以 inode 的数量显示 $du file/dir 评估目录所占容量 -h 以人们容易阅读的 GB MB KB 等格式自行显示 -s 仅显示总计，不列出每个子目录的占用容量 -m 以 M 为单位 例如： $ df -h 文件系统 容量 已用 可用 已用% 挂载点 /dev/sda1 29G 4.2G 23G 16% / udev 1001M 4.0K 1001M 1% /dev tmpfs 404M 792K 403M 1% /run none 5.0M 0 5.0M 0% /run/lock none 1009M 152K 1009M 1% /run/shm none 100M 28K 100M 1% /run/user $ du -sh /home/user01/ 1.1G /home/user01/ 总结 主要概括性总结了目录文件的构成，以及与普通文件之间的关系。讲解了硬链接和软链接，以及 df du 命令。 Linux 是一个文件王国，一切都以文件的形式存在。了解 Linux 的文件系统，是深入了解操作系 Linux 原理的重要一步。 参考资料 鸟哥的Linux私房菜.基础学习篇 ","date":"2014-04-20","objectID":"/posts/5cd91fbc/:0:0","tags":["linux","文件"],"title":"Linux基础：文件管理","uri":"/posts/5cd91fbc/"},{"categories":["Linux/Unix"],"content":"我们知道不同的操作系统所使用的文件系统是不一样的。举例来说，Windows 98 以前所使用的是文件系统是 FAT，Windows 2000 以后的版本有所谓的 NTFS 文件系统。至于 Linux 的正规文件系统则为 Ext2（Linux second extended file system，Ext2fs）。之后又出现了改进版的 Ext3 和 Ext4 ，总体上变化不大。 文件系统的对比 我们经常听说 Windows 需要磁盘碎片整理，而 Linux 却不需要。这是为什么呢？ 我们可以先看看 Ext2 文件系统的数据访问方式，如下图所示。 假设一个文件的属性和权限信息是存放在 3 号的 inode 上，而文件的实际数据是存放在 1、4、6、11 这四个 block 中，那么当操作系统要访问该文件时，就能据此来排列磁盘的阅读顺序，可以扫描一次就将 4 个 block 内容读出来。这种访问方式称为索引式文件系统（indexed allocation）。而且 ext 在每两个文件之间都留有相当巨大的空闲空间。当文件被修改、体积增加时，它们通常有足够的空间来扩展。因此在一定程度上保证了 block 的访问范围不会跨度很大，减小了磁头的移动距离。 那 Windows 的文件系统是怎样的呢？ 我们以 FAT 为例说明。 在往 FAT 文件系统中存入一个文件时，系统会尽量存放在靠近磁盘开始的地方。当你存入第二个文件时，它会紧挨着第一个文件。当进行频繁的删除修改后，block 就会分散的特别厉害。FAT 文件系统没有 inode 的存在，所以不能一下子将文件的所有 block 在一开始就读取出来。每个 block 号码都记录在前一个 block 当中，形成一个 block 链。当我们需要读取文件的时候，就必须一个一个地将 block 读出，例如上图的读出顺序为 1、6、3、12 。这就会导致磁头无法在磁盘转一圈就获得所有数据，有时候需要来回转好几圈才能读取到这个文件，导致文件读取性能极差。这就是 Windows 经常需要碎片整理的原因——使离散的数据汇合在一起 而 NTFS 文件系统虽然智能了一点，在文件周围分配了一些“缓冲”的空间，但经过一段时间的使用后， NTFS 文件系统还是会形成碎片。由于 ext 是索引式文件系统，所以基本上不太需要经常进行磁盘碎片整理。 ext2/ext3 文件系统 我们知道文件数据除了文件的实际内容外，通常还包括非常多的属性，例如 Linux 中的文件权限（rwx）和文件属性（拥有者、用户组、时间、大小等）。ext 文件系统将这两部分存放在不同的块，权限和属性存放在 inode 中，至于文件的实际数据则存放在 block 块中。另外还有一个超级块（super block）会记录整个文件系统的整体系统。每个 inode 和 block 都有自己的编号。 ext 文件系统在格式化的时候基本上是区分为多个块组（block group）的，每个块组都有独立的 inode/block/super block 系统。其整体展示图如下所示： 其中各个块的含义如下： super block：记录此文件系统的整体系统，包括 inode 和 block 的总量、使用量、剩余量，以及文件系统类型等。 file system description：文件系统描述说明。描述每个 block group 的开始与结束的 block 号码。 block bitmap：块对照表。用来快速寻找可用的 block 块。 inode bitmap：inode对照表。用来快速寻找可用的 inode 块。 inode table：存放 inode 块的地方。它们是文件系统的关键。记录了文件的属性，一个文件占用一个 inode，同时包含多个指针，指向了属于该文件的各个 data block 块 data block：真正存放数据的地方。文件太大会占用多个 block 。 ##总结 本节主要讲述了 ext2/ext3 与其他文件系统的区别，以及不用磁盘碎片整理的原理。然后对 ext 文件系统的体系结构进行了剖析，说明了各个数据块的意义。重点是了解 inode 和 block 在 Linux 中所扮演的不同角色以及重要意义。 Linux 是一个文件王国，一切都以文件的形式存在。了解Linux的文件系统，是深入了解操作系Linux原理的重要一步。 参考资料 鸟哥的Linux私房菜.基础学习篇 ","date":"2014-04-16","objectID":"/posts/e916aedd/:0:0","tags":["linux","文件"],"title":"Linux基础：文件系统","uri":"/posts/e916aedd/"},{"categories":["Linux/Unix"],"content":"用户与用户组 Linux 是一个多用户、多任务的系统，常常有多人同时使用一台机工作，为了保护每个人的隐私权，“文件所有者”的角色就显得相当重要了。 当Linux用户登录系统之后，就会携带一个用户身份（User ID，UID）和一个用户组身份（Group ID，GID），相当于自己的名片。当需要访问文件或程序时，刷一下名片就能知道是否能读、写、执行了。 一般来说，Linux的用户信息保存在/etc/passwd中，组信息保存在/etc/group中，文件的每一行代表一个用户/组。早期的Linux将密码以明文的形式保存在/etc/passwd中，而现在则多以暗码(也就是加密之后的形式)的形式保存在/etc/shadow中。将密码存储在/etc/shadow中提高了密码的安全性，因为/etc/passwd允许所有人查看，而/etc/shadow只允许root用户查看。 文件属性 要了解Linux的权限控制就必须学习Linux的文件权限和属性。可以用ls命令查询文件信息（$ls -l），得到如下结果： $ ls -l ~/input 总用量 36 drwxrwxr-x 2 user01 user01 4096 7月 10 21:45 ./ drwxr-xr-x 30 user01 user01 4096 7月 12 08:58 ../ -rw-rw-r-- 1 user01 user01 46 6月 16 20:31 a.txt lrwxrwxrwx 1 user01 user01 4 6月 16 16:03 b.txt -\u003e a.txt [ 权限 ][连接数][拥有者][用户组][文件容量][ 修改日期 ] [文件名] 我们以 a.txt 文件为例介绍各个部分的含义： 第一列代表文件权限。它由十个字符组成。首先介绍第一个字符的-，它表示文件类型，说明 a.txt 是常规文件(如果是目录文件则应显示 d，如果是 l 则是软链接文件)。随后有九个字符，为rw-rw-r–，它们用于表示文件权限。这九个字符分为三组，rw-,rw-, r–，分别对应拥有者(owner)，所属用户组(owner group)和所有其他人(other)。回顾 Linux 的启动流程，登录后，我们会有一个用户身份和一个组身份, 相当于我的身份证。第一组表示，如果我的身份证上的用户身份证明我是该文件的拥有者，那么我就可以对该文件有读取(r)，写入(w)该文件的权限，但不拥有执行(x)该文件的权限。如果不拥有某项权限，会在对应的位置上出现减号(-)。第二组表示，如果我的名片上的组身份证明我所在的组是该文件的所属用户组的一员，那么我有从该文件读入和写入的权限。第三组表示，如果我的名片显示我既不是拥有者，也不是拥有组的一员，那么我只有读入的权限。当我想要进行一个读取操作时，Linux会先看我是否是拥有者。 第二列代表有多少文件名连接到此节点（i-node）。每个文件都将它的权限和属性记录到文件系统的 inode 中，不过文件名却是存放在目录文件中的。因此会有多个文件名连接到一个 inode 的情况，这就是硬链接，而该列就是指的硬链接数。 第三列表示这个文件（或目录）的拥有者。 第四列表示这个文件（或目录）的所属用户组。 第五列表示这个文件的大小，单位为字节（byte）。其中软链接文件（上面的 b.txt 文件）的大小正好是目标文件的字符数。至于目录也是一种文件，有趣的是大部分目录所占的大小都是 1K、2K、4K 的倍数。 第六列表示文件的最近修改时间。其实文件属性中还包括创建时间和最近读取时间，只是并未显示出来。 第七列为该文件的文件名。 改变文件属性和权限 我们已经知道文件权限对于一个系统的重要性了，但如何对文件的属性和权限进行修改呢？这里主要用到三个命令：chgrp、chown、chmod，分别对应修改用户组、拥有者和文件权限。 改变所属用户组：chgrp $ chgrp 组名 文件或目录 $ chgrp users a.txt 改变文件所有者：chown $ chown 账号名称 文件或目录 $ chown 账号名称:组名 文件或目录 $ chown root:root a.txt 改变文件权限：chmod Linux中的每种身份（own、group、other）拥有一个权限三元组（rwx）。每一个权限组可以用一个三位的二进制来表示，拥有对应权限的则在相应位上置1。例如-rw-rw-r–即代表 664 的意思。如果我们想将该文件改成-rwxrwx—的权限，就将其权限分数改成 770 即可。 $ chmod 770 a.txt $ ls -l a.txt -rwxrwx--- 1 root root 46 6月 16 20:31 a.txt 默认权限umask 当我们创建文件的时候，比如使用touch，它会尝试将新建文件创建为权限666，也就是 rw-rw-rw-。但操作系统要参照权限 mask 来看是否真正将文件创建为666。权限 mask 表示操作系统不允许设置的权限位，比如说037(——wxrwx)的权限 mask 意味着不允许设置设置 group 的 wx 位和 other 的 rwx 位。如果是这个权限 mask 的话，最终的文件权限是 rw-r——- ( group 的 w 位和 other 的 rw 位被 mask )。 我们可以通过 $umask 022 的方式改变权限mask。仅输入umask是查询默认 mask 的意思。 总结 Linux 中的权限管理非常复杂，尤其是涉及进程的时候，有时会有权限的切换。这部分待到以后再说。不过Linux的权限管理都是基于文件的属性和权限的，因此学习了解 Linux 的文件系统非常重要。 参考资料 鸟哥的Linux私房菜.基础学习篇 ","date":"2014-04-05","objectID":"/posts/4119ba0a/:0:0","tags":["linux","权限"],"title":"Linux基础：权限与文件","uri":"/posts/4119ba0a/"},{"categories":["Linux/Unix"],"content":"计算机的启动是一个非常复杂的过程，从打开电源到桌面的显示，需要经过一系列不可或缺的过程，了解这些过程有助于我们更好地理解操作系统，也有助于我们修复系统可能出现的问题。 启动流程一览 我们先给出 Linux 启动流程的总览图，然后再每一个模块展开说明。 BIOS 当我们按下电源按键后，计算机硬件会自动读取主板上的BIOS（Basic Input/Output System）来加载硬件信息以及硬件系统的自我测试。BIOS也是一套程序，它知道如何与硬件进行交互。BIOS首先会对硬件进行检查，判断计算机硬件是否能满足运行的基本条件，这叫做“硬件自检”（Power-On Self-Test，简称 POST）。 硬件自检后，BIOS 会将控制权交给下一段启动程序。这时，BIOS需要知道，”下一阶段的启动程序”具体存放在哪一个设备。也就是说，BIOS需要有一个外部存储设备的排序，排在前面的设备就是优先转交控制权的设备。这种排序叫做”启动顺序”（Boot Sequence）。 因此，BIOS按照”启动顺序”，把控制权转交给排在第一位的存储设备。 MBR 系统读取位列第一的可启动存储设备。计算机先读取该设备的第一个扇区，也就是读取最前面的512个字节。这最前面的512个字节，就叫做”主引导记录”（Master boot record，缩写为MBR）。MBR 只有512字节，放不了太多东西，它主要告诉计算机从该设备的哪一个分区（partition）来装载引导加载程序（boot loader）。Boot Loader 储存有操作系统（OS）的相关信息，比如操作系统名称，操作系统内核（kernel）所在位置等。它的主要功能就是加载内核到内存中去执行。常用的 boot loader 有 GRUB 和 LILO 。 那我们经常说到的多操作系统是怎么回事呢？其实每个文件系统（或分区）的最前面会保留一个引导扇区（boot selector），这个引导扇区可以安装 boot loader。这样我们在每个 boot loader 中对应不同的操作系统，在读取 MBR 的时候选择我们需要启动的 boot loader 即可。 kernel 随后，boot loader 会帮助我们加载内核，内核就会开始检测硬件与加载驱动程序。没错，内核会以自己的功能重新检测一遍硬件，而不一定会使用 BIOS 检测到的硬件信息。也就是说，内核此时才开始接管 BIOS 后的工作。 Kernel 实际上是一个用来操作计算机的程序，它是计算机操作系统的内核，主要的任务是管理计算机的硬件资源，充当软件和硬件的接口。操作系统上的任何操作都要通过 kernel 传达给硬件。 init process 在内核加载完毕以后，此时内核会主动调用第一个进程，那就是 /sbin/init，它的作用就是初始化系统环境。使用pstree命令会发现init的进程编号（PID）是1，也就是说init是第一个运行的程序，其他所有进程都从它衍生，都是它的子进程。 许多程序需要开机启动。它们在Windows叫做”服务”（service），在 Linux 就叫做”守护进程”（daemon）。 init 进程的一大任务，就是去运行这些开机启动的程序。但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动 Apache，用作桌面就不需要。Linux 允许为不同的场合，分配不同的开机启动程序，这就叫做”运行级别”（run level）。也就是说，启动时根据”运行级别”，确定要运行哪些程序。 基本上，依据有无网络与有无 X Window ，Linux 将 run level 划分为7个等级（0-6）。其中0是关机，1是单用户模式，6是重启。而 2-5，一般来说都是多用户模式。 Linux 在启动各个服务前会先执行一系列的初始脚本（rc.sysinit）。这些脚本执行如下功能：设置计算机名称，时区，检测文件系统，挂载硬盘，清空临时文件，设置网络…… 之后会根据运行级别的不同，系统会运行 rc0.d 到 rc6.d 目录中的相应的脚本程序，来完成相应的初始化工作和启动相应的服务。rc*.d目录中存放的是该运行级别中需要执行的服务脚本的软链接文件（即快捷方式）。 除此之外，Linux 还会运行一些其他的初始脚本。运行完后，操作系统已经完全准备好了，只是，还没有人可以登录！！！init 会给出登录（login）对话框，或者是图形化的登录界面。 login 输入用户名密码登录成功后，系统会为用户分配一个用户 ID（UID），和一个组 ID（GID）。这两个 ID 就好像身份证一样会一直伴随用户，用于检测用户执行程序时的身份验证。 当用户登录成功后，一个完整的操作系统就展现在用户的面前了。哈哈！ 总结 结合一开始给出的流程图，Linux 的启动流程可以概括为以下几个主要步骤： 加载 BIOS 的硬件信息与硬件自检，并依据设置取得第一个可启动的设备； 读取并执行第一个启动设备内的MBR的 boot loader； 依据 boot loader 的设置加载内核，内核会开始检测硬件与加载驱动程序； 在内核 Kernel 加载完毕后，Kernel 会主动调用 init 进程，而 init 会取得 run-level 信息； init 执行 rc.sysinit 初始化系统的操作环境（网络、时区等）； init 启动 run-level 的各个服务； 用户登录 要注意在一开始的流程图中 init 虽然只用了一个模块展现出来，但其实在启动过程中 init 占了很大的比重。 参考文献 Linux 的启动流程 计算机是如何启动的？ Linux开机启动 (bootstrap) 鸟哥的Linux私房菜.基础学习篇 ","date":"2014-03-05","objectID":"/posts/e3f5fe56/:0:0","tags":["linux","启动流程"],"title":"Linux基础：启动流程","uri":"/posts/e3f5fe56/"},{"categories":["Linux/Unix"],"content":"和朋友今天正好聊到CentOS的自动化安装光盘制作问题，就顺便把自己之前的测试过程发出来。希望能够帮到大家。 直接发下自己之前做的时候的工作记录了，因为是工作中使用，添加了一些所需的软件包之类的东西，其实您也完全可以自由发挥，直接装完系统，一个优化好的LNMP等等众多软件都已经安装好了的系统也是完全可能的，想想网上的那些一键安装的ISO… 所以大家加油哦！后期我也会完善本篇文章的具体注释的。 定制步骤 安装一个干净的操作系统.包括基本的系统和所需要的工具等. 比如:对于http,mysql等软件,建议使用编译的方式安装, 然后打包放进去,可以减少许多依赖包的麻烦. 安装系统后,收集系统已安装的软件包,使用脚本统一转存到一个目录中. 在安装光盘复制images镜像,从光盘启动centos安装所需的文件等. 定义自己的kickstart安装脚本. 按照之前转存的软件(rpm)包, 重新生成光盘的report信息. 打包生成ISO文件，及MD5效验码. 光盘结构介绍 isolinux目录存放光盘启动时的安装界面信息 images目录包括了必要的启动映像文件 CentOS目录存放安装软件包及信息 .discinfo文件是安装价质的识别信息 安装时默认第一项是text自动安装，也可以选择第二项进行手动安装… 安装完成后的ISO IP地址：172.16.0.110 root密码：passw0rd 操作过程记录 一、挂载光盘，使用脚本拷贝相关软件包到/ISO/Packages目录下 [root@CentOS ~]# mkdir /mnt/cdrom [root@CentOS ~]# mount /dev/cdrom /mnt/cdrom [root@CentOS~]# /usr/bin/rsync -a --exclude=Packages/ --exclude=repodata/ /mnt/cdrom/ /ISO/ [root@CentOS ~]# mkdir -p /ISO/{Packages,repodata} [root@CentOS ~]# vi copy.sh #!/bin/bash cd /root awk '/Installing/{print $2}' install.log | sed 's/^*://g' \u003epackage.txt DVD='/mnt/cdrom/Packages' PACKDIR='/root/package.txt' NEW_DVD='/ISO/Packages' while read LINE do cp ${DVD}/${LINE}*.rpm ${NEW_DVD} || echo \"$LINE don't cp.......\" done \u003c package.txt rm -f package.txt [root@CentOS ~]# chmod +x copy.sh [root@CentOS ~]# ./copy.sh [root@CentOS ~]# ll /ISO/Packages/ |wc -l 285 二、定制kickstart安装脚本ks.cfg [root@CentOS ~]# cd /ISO [root@CentOS ISO]# cp ~/anaconda-ks.cfg isolinux/ks.cfg ks.cfg文件内容如下 # Kickstart file automatically generated by anaconda. #version=DEVEL install text cdrom lang en_US.UTF-8 keyboard us network --onboot no --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$x8.IJeCQkCgkVmt7$1xpLAdczrfqxYlvkVwMAus6nLPFk6sl45X6CuTsmpFlAko6/NEFyuJXvMgZujfAu5V9T04hZ1P5ZMlR0TZtdK0 firewall --service=ssh authconfig --enableshadow --passalgo=sha512 selinux --enforcing timezone --utc Asia/Shanghai bootloader --location=mbr --driveorder=sda --append=\"crashkernel=auto rhgb quiet\" # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work #clearpart --linux --drives=sda #volgroup VolGroup --pesize=4096 pv.008002 #logvol / --fstype=ext4 --name=lv_root --vgname=VolGroup --grow --size=1024 --maxsize=51200 #logvol swap --name=lv_swap --vgname=VolGroup --grow --size=4000 --maxsize=4000 #part /boot --fstype=ext4 --size=500 #part pv.008002 --grow --size=1 clearpart --all zerombr part /boot--fstype=ext4 --size=200 part swap --size=2048 part / --fstype=ext4 --size=20000 part /data --fstype=ext4 --grow --size=200 repo --name=\"CentOS\" --baseurl=file:///mnt/source --cost=100 %packages @base @console-internet @core @debugging @directory-client @hardware-monitoring @java-platform @large-systems @network-file-system-client @performance @perl-runtime @server-platform @server-policy pax oddjob sgpio device-mapper-persistent-data samba-winbind certmonger pam_krb5 krb5-workstation perl-DBD-SQLite %end 三、修改/ISO/isolinux/isolinux.cfg文件，默认isolinux.cfg的权限为444，只能读，无法修改 [root@CentOS ISO]# chmod 644 isolinux/isolinux.cfg [root@CentOS ISO]# vi isolinux/isolinux.cfg isolinux.cfg文件内容如下 default vesamenu.c32 #prompt 1 timeout 100 ###10秒钟 display boot.msg menu background splash.jpg menu title Welcome to use CentOS 6.4! menu color border 0 #ffffffff #00000000 menu color sel 7 #ffffffff #ff000000 menu color title 0 #ffffffff #00000000 menu color tabmsg 0 #ffffffff #00000000 menu color unsel 0 #ffffffff #00000000 menu color hotsel 0 #ff000000 #ffffffff menu color hotkey 7 #ffffffff #ff000000 menu color scrollbar 0 #ffffffff #00000000 label linux menu label ^Auto Install Xlogin Linux System menu default kernel vmlinuz append ks=cdrom:/isolinux/ks.cfg initrd=initrd.img ###ks文件路径 label vesa menu label Install system with ^basic video driver kernel vmlinuz append initrd=initrd.img xdriver=vesa nomodeset label rescue menu label ^Rescue installed system kernel vmlinuz append initrd=initrd.img rescue label local menu label Boot from","date":"2013-03-23","objectID":"/posts/ef3dfd58/:0:0","tags":["linux","iso","centos"],"title":"定制CentOS 6.4自动化安装ISO镜像光盘","uri":"/posts/ef3dfd58/"},{"categories":["Linux/Unix","Shell"],"content":"在linux shell编程中，经常用到日期的加减运算，以前都是自己通过expr函数计算，很麻烦。 其实date命令本身提供了日期的加减运算，非常方便。 例如：得到昨天的时间 date +%Y%m%d –date=”-1 day” date的用法: date [OPTION]… [+FORMAT] date [-u|–utc|–universal] [MMDDhhmm[[CC]YY][.ss]] date 可以用来显示或设定系统的日期与时间。 在显示方面，使用者可以设定欲显示的格式，格式设定为一个加号后接数个标记，其中可用的标记列表如下: %% : 显示一个 %（百分号）字符。 %n : 下一行 %t : 跳格 %H : 小时(00..23) %I : 小时(01..12) %k : 小时(0..23) %l : 小时(1..12) %M : 分钟(00..59) %p : 显示本地 AM 或 PM %r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M) %s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数 %S : 秒(00..61) %T : 直接显示时间 (24 小时制) %X : 相当于 %H:%M:%S %Z : 显示时区 %a : 星期几 (Sun..Sat) %A : 星期几 (Sunday..Saturday) %b : 月份 (Jan..Dec) %B : 月份 (January..December) %c : 直接显示日期与时间 %d : 日 (01..31) %D : 直接显示日期 (mm/dd/yy) %h : 同 %b %j : 一年中的第几天 (001..366) %m : 月份 (01..12) %U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形) %w : 一周中的第几天 (0..6) %W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形) %x : 直接显示日期 (mm/dd/yy) %y : 年份的最后两位数字 (00.99) %Y : 完整年份 (0000..9999) 在设定时间方面 date -s //设置当前时间，只有root权限才能设置，其他只能查看。 date -s 20080523 //设置成20080523，这样会把具体时间设置成空00:00:00 date -s 01:01:01 //设置具体时间，不会对日期做更改 date -s “01:01:01 2008-05-23″ //这样可以设置全部时间 date -s “01:01:01 20080523″ //这样可以设置全部时间 date -s “2008-05-23 01:01:01″ //这样可以设置全部时间 date -s “20080523 01:01:01″ //这样可以设置全部时间 加减 date +%Y%m%d //显示前天年月日 date +%Y%m%d –date=”+1 day” //显示前一天的日期 date +%Y%m%d –date=”-1 day” //显示后一天的日期 date +%Y%m%d –date=”-1 month” //显示上一月的日期 date +%Y%m%d –date=”+1 month” //显示下一月的日期 date +%Y%m%d –date=”-1 year” //显示前一年的日期 date +%Y%m%d –date=”+1 year” //显示下一年的日期 ","date":"2013-03-11","objectID":"/posts/9cd3e9e8/:0:0","tags":["date","shell","linux"],"title":"Linux Shell date命令的用法","uri":"/posts/9cd3e9e8/"},{"categories":["编程语言","regex"],"content":"最近在看鸟哥 Linux，看到正则表达式这块，以前看到这些恐怖的字符总是觉得恶心，今天就咬牙系统的学习了下正则表达式。然后有了这篇笔记。主要总结正则表达式的一些关键知识点。 字面值：a b c d 1 2 3 4 等等。 字符类：. [abc] [a-z] \\d \\w \\s - . 表示“任何字符” - [abc] 括号表示“找到集合里任意一个字符”。 - \\d 表示“一个数字”，等同于[0-9] - \\w 表示“一个单词字符”，等同于[0-9A-Za-z_] - \\s 表示“一个空格，tab，回车或一个换行符” - 否定字符类：[^abc] \\D \\W \\S 乘法器：{4} {3,16} {1,} ? * + {3,16} 表示找到重复 3 到 16 个前一个正则字符 ? 表示“没有或一个” * 表示“没有或多个” + 表示“一个或多个” 乘法器是贪婪的除非你在之后使用 ? , 即优先找到最长的 分支和组合： (Septem|Octo|Novem|Decem)ber 管道符号 | 表示“或” 圆括号表示组合 ，比如 在一周中找到一天，使用 (Mon|Tues|Wednes|Thurs|Fri|Satur|Sun)day。 词、行和文本边界： \\b 表示词边界 ^ 表示行开始 $ 表示行结束 ^$ 表示的就是空白行了 反向捕获组：\\1 \\2 \\3 等等。捕获组从左到右进行编号，只要计算左圆括号。（在替换表达式和匹配表达式中同时生效） 比如有一段字符，我们需要前面的横杠去掉，尾巴的数字去掉， 英文句号换成中文顿号 -1.文章标题1 -2.文章标题2 -3.文章标题3 -4.文章标题4 -5.文章标题5 则可以使用正则表达式 -(\\d{1,})\\.(.*)\\d 来匹配。然后使用 \\1、\\2 来替换。 向后引用： 在同样的表达式中引用同一个捕获组。 表达式 (xi)\\1(ha)\\2 能匹配 xixihaha 元字符列表：. \\ [ ] { } ? * + | ( ) ^ $ 字符类中使用到元字符列表：[ ] \\ - ^ 你总是可以使用反斜杆对元字符进行转义：\\ 参考资料： RegExr：一款在线学习、构建和测试正则表达式的工具 TRY REGEX：交互式正则表达式的教学网站 55分钟学会正则表达式：很好的入门文章 ","date":"2013-03-05","objectID":"/posts/469df0ac/:0:0","tags":["正则表达式"],"title":"正则表达式学习","uri":"/posts/469df0ac/"},{"categories":["Linux/Unix"],"content":"将下列脚本保存为可执行脚本文件，比如叫traff.sh。☺️ #!/bin/bash while [ \"1\" ] do eth=$1 RXpre=$(cat /proc/net/dev | grep $eth | tr : \" \" | awk '{print $2}') TXpre=$(cat /proc/net/dev | grep $eth | tr : \" \" | awk '{print $10}') sleep 1 RXnext=$(cat /proc/net/dev | grep $eth | tr : \" \" | awk '{print $2}') TXnext=$(cat /proc/net/dev | grep $eth | tr : \" \" | awk '{print $10}') clear echo -e \"\\t RX `date +%k:%M:%S` TX\" RX=$(($RXnext-$RXpre)) TX=$(($TXnext-$TXpre)) if [[ $RX -lt 1024 ]];then RX=\"${RX}B/s\" elif [[ $RX -gt 1048576 ]];then RX=$(echo $RX | awk '{print $1/1048576 \"MB/s\"}') else RX=$(echo $RX | awk '{print $1/1024 \"KB/s\"}') fi if [[ $TX -lt 1024 ]];then TX=\"${TX}B/s\" elif [[ $TX -gt 1048576 ]];then TX=$(echo $TX | awk '{print $1/1048576 \"MB/s\"}') else TX=$(echo $TX | awk '{print $1/1024 \"KB/s\"}') fi echo -e \"$eth \\t $RX $TX \" done 本脚本可自定义欲查看接口，精确到小数，并可根据流量大小灵活显示单位。 此脚本的采集间隔为1秒。 此脚本不需要额外再安装软件，可在急用情况下应付一下，比如临时想看一下是否有流量通过，大概为多少等。 一些流量查看软件由于计算的精确度不同，所以与此脚本显示的数值不可能一致，此脚本的显示结果与du meter对比过，相差很小。还有就是传输工具本身显示的传输速度并不准确。 用法为： chmod +x ./traff.sh 将文件改成可执行脚本。 ./traff.sh eth0即可开始监看接口eth0流量，按ctrl+c退出。 ","date":"2013-01-26","objectID":"/posts/3b1b6dcd/:0:0","tags":["流量","网卡"],"title":"实时查看linux网卡流量","uri":"/posts/3b1b6dcd/"},{"categories":["Linux/Unix"],"content":"查了半天系统环境变量HISTTIMEFORMAT丝毫不见踪迹 原来在bash man中才有收录 #man bash HISTTIMEFORMAT If this variable is set and not null, its value is used as a format string for strftime(3) to print the time stamp associated with each history entry displayed by the history builtin. If this variable is set, time stamps are written to the history file so they may be preserved across shell sessions. 如果这个变量被设置，且不为空,使用它的值作为格式字符串strftime（3）打印时间戳与历史命令内建显示的每个条目相关联的历史.如果这个变量被设置，时间戳会被写入历史文件，这样的话他们可能会保留在shell会话。 查看HISTTIMEFORMAT具体参数 #man strftime 取了两条记录 %F Equivalent to %Y-%m-%d (the ISO 8601 date format). (C99) %T The time in 24-hour notation (%H:%M:%S). (SU) [root@jerome-1 conf]# HISTTIMEFORMAT=\"%F %T\" 常用到的一些显示方式 下面这条相当于上面的方式 [root@jerome-1 conf]# HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S\" [root@jerome-1 conf]# history | tail 1091 2011-03-17 12:57:57 history 可将以下两条加入到/etc/profile文件当中 export HISTTIMEFORMAT=\"%F %T\" ","date":"2013-01-26","objectID":"/posts/f26d5bcc/:0:0","tags":["history"],"title":"history命令显示时间记录","uri":"/posts/f26d5bcc/"},{"categories":["数据库","SQLServer"],"content":"单位托管有服务器,或者经常在家里休息时单位服务器出现问题时,相信用远程桌面或pcanywhere的朋友遇到过莫名其妙断线而不能再连接的情况。这时,如果服务器如果安装有SQL server,则可用如下的方法重启服务器解决。 本地用SQL server连接上服务器后,在SQL查询工具里执行如下命令: xp_cmdshell 'shutdown -r -t 80' 用SQL在80秒后重新启动电脑 shutdown -a 取消重新启动 shutdown.exe -a 取消关机 shutdown.exe -d [p]:xx:yy 列出系统关闭的原因代码。 shutdown.exe -f 强行关闭应用程序。 shutdown.exe -m \\计算机名　控制远程计算机。 shutdown.exe -i 显示图形用户界面，但必须是Shutdown的第一个参数。 shutdown.exe -l 注销当前用户。 shutdown.exe -r 关机并重启。 shutdown.exe -t 时间 设置关机倒计时。默认值是 30 秒。 shutdown.exe -c \"消息内容\" 输入关机对话框中的消息内容(不能超127个字符)。 远程关闭/重启pcanywhere xp_cmdshell net stop awhost32 xp_cmdshell net start awhost32 ","date":"2012-12-11","objectID":"/posts/58a4edf/:0:0","tags":["mssql"],"title":"使用MSSQL远程重启服务器的方法","uri":"/posts/58a4edf/"},{"categories":["数据库","JDBC"],"content":"Microsoft SQL Server Microsoft SQL Server JDBC Driver （一般用来连接 SQLServer 2000） 驱动程序包名:msbase.jar mssqlserver.jar msutil.jar 驱动程序类名:com.microsoft.jdbc.sqlserver.SQLServerDriver JDBC URL: jdbc:microsoft:sqlserver://\u003cserver_name\u003e:\u003cport\u003e 默认端口1433，如果服务器使用默认端口则port可以省略 Microsoft SQL Server 2005 JDBC Driver 驱动程序包名:sqljdbc.jar 驱动程序类名: com.microsoft.sqlserver.jdbc.SQLServerDriver JDBC URL: jdbc:sqlserver://\u003cserver_name\u003e:\u003cport\u003e 默认端口1433，如果服务器使用默认端口则port可以省略 Oracle Oracle Thin JDBC Driver 驱动程序包名:ojdbc14.jar 驱动程序类名: oracle.jdbc.driver.OracleDriver JDBC URL: jdbc:oracle:thin:@//\u003chost\u003e:\u003cport\u003e/ServiceName 或 jdbc:oracle:thin:@\u003chost\u003e:\u003cport\u003e:\u003cSID\u003e IBM DB2 IBM DB2 Universal Driver Type 4 驱动程序包名:db2jcc.jar db2jcc_license_cu.jar 驱动程序类名: com.ibm.db2.jcc.DB2Driver JDBC URL: jdbc:db2://\u003chost\u003e[:\u003cport\u003e]/\u003cdatabase_name\u003e IBM DB2 Universal Driver Type 2 驱动程序包名:db2jcc.jar db2jcc_license_cu.jar 驱动程序类名: com.ibm.db2.jcc.DB2Driver JDBC URL: jdbc:db2://\u003chost\u003e[:\u003cport\u003e]/\u003cdatabase_name\u003e MySQL MySQL Connector/J Driver 驱动程序包名:mysql-connector-java-x.x.xx-bin.jar 驱动程序类名: com.mysql.jdbc.Driver JDBC URL: jdbc:mysql://\u003chost\u003e:\u003cport\u003e/\u003cdatabase_name\u003e 默认端口3306，如果服务器使用默认端口则port可以省略 MySQL Connector/J Driver 允许在URL中添加额外的连接属性 jdbc:mysql://\u003chost\u003e:\u003cport\u003e/\u003cdatabase_name\u003e?property1=value1\u0026property2=value2 Informix Informix JDBC Driver 驱动程序包名:ifxjdbc.jar 驱动程序类名: com.informix.jdbc.IfxDriver JDBC URL: jdbc:informix-sqli://{\u003cip-address\u003e|\u003chost-name\u003e}:\u003cport-number\u003e[/\u003cdbname\u003e]: INFORMIXSERVER=\u003cserver-name\u003e Sybase Sybase Adaptive Server Enterprise JDBC Driver 驱动程序包名:jconn2.jar 或jconn3.jar 驱动程序类名: com.sybase.jdbc2.jdbc.SybDriver (com.sybase.jdbc3.jdbc.SybDriver) JDBC URL: jdbc:sybase:Tds:\u003chost\u003e:\u003cport\u003e默认端口5000 Sybase Adaptive Server Anywhere or Sybase IQ JDBC Driver 驱动程序包名:jconn2.jar 或jconn3.jar 驱动程序类名: com.sybase.jdbc2.jdbc.SybDriver (com.sybase.jdbc3.jdbc.SybDriver) JDBC URL: jdbc:sybase:Tds:\u003chost\u003e:\u003cport\u003e?ServiceName=\u003cdatabase_name\u003e 默认端口2638 PostgreSQL PostgreSQL Native JDBC Driver 驱动程序包名:驱动程序类名: org.postgresql.Driver JDBC URL: jdbc:postgresql://\u003chost\u003e:\u003cport\u003e/\u003cdatabase_name\u003e 默认端口5432 Teradata Teradata Driver for the JDBC Interface 驱动程序包名:terajdbc4.jar tdgssjava.jar gui.jar 驱动程序类名: com.ncr.teradata.TeraDriver JDBC URL: Type 4: jdbc:teradata://DatabaseServerName/Param1,Param2,… Type 3: jdbc:teradata://GatewayServerName:PortNumber/DatabaseServerName/Param1,Param2,… Netezza Netezza JDBC Driver 驱动程序包名:terajdbc4.jar tdgssjava.jar gui.jar 驱动程序类名: org.netezza.Driver JDBC URL: jdbc:netezza://\u003chost\u003e:\u003cport\u003e/\u003cdatabase_name\u003e ","date":"2012-10-17","objectID":"/posts/c65535ee/:0:0","tags":["jdbc","url"],"title":"常用数据库驱动和JDBC URL","uri":"/posts/c65535ee/"},{"categories":["Linux/Unix"],"content":"expect是一种能够按照脚本内容里面设定的方式与交互式程序进行”会话”的程序。根据脚本内容，Expect可以知道程序会提示或反馈什么内容以及 什么是正确的应答。它是一种可以提供”分支和嵌套结构”来引导程序流程的解释型脚本语言。 shell功能很强大,但是不能实现有交互功能的多机器之前的操作,例如ssh和ftp.而expect可以帮助我们来实现. 安装expect yum install expect 其实expect根bash形势上差不多的. 实例 #!/wp-content/bin/expect -f set ip [lindex $argv 0 ] //接收第一个参数,并设置IP set password [lindex $argv 1 ] //接收第二个参数,并设置密码 set timeout 10 //设置超时时间 spawn ssh root@$ip //发送ssh请滶 expect { //返回信息匹配 \" *yes/no \" { send \" yes\\r \"; exp_continue} //第一次ssh连接会提示yes/no,继续 \" *password: \" { send \" $password\\r \" } //出现密码提示,发送密码 } interact //交互模式,用户会停留在远程服务器上面. 运行结果如下: root@ubuntu:/home/w23ta0# ./test.exp 192.168.1.130 admin spawn ssh root@192.168.1.130 Last login: Fri Sep 7 10:47:43 2012 from 192.168.1.142 [root@linux ~]# 这个例子有统一的接口,根据IP和密码可以连接到不同的机器. 如果你嫌输入IP和密码麻烦,看下面的例子 #!/wp-content/bin/expect -f set ip 192.168.1.130 set password admin set timeout 10 spawn ssh root@$ip expect { \" *yes/no \" { send \" yes\\r \"; exp_continue} \" *password: \" { send \" $password\\r \" } } interact 运行结果如下: root@ubuntu:/home/w23ta0# ./web.exp spawn ssh root@192.168.1.130 Last login: Fri Sep 7 12:59:02 2012 from 192.168.1.142 [root@linux ~]# ssh远程登录到服务器,并且执行命令,执行完后并退出 #!/wp-content/bin/expect -f set ip 192.168.1.130 set password admin set timeout 10 spawn ssh root@$ip expect { \" *yes/no \" { send \" yes\\r \"; exp_continue} \" *password: \" { send \" $password\\r \" } } expect \" #* \" send \" pwd\\r \" send \" exit\\r \" expect eof 运行结果如下: root@ubuntu:/home/w23ta0# ./test3.exp spawn ssh root@192.168.1.130 root@192.168.1.130's password: Last login: Fri Sep 7 14:05:07 2012 from 116.246.27.90 [root@localhost ~]# pwd /root [root@localhost ~]# exit logout Connection to 192.168.1.130 closed. 远程登录到ftp,并且下载文件 #!/wp-content/bin/expect -f set ip [lindex $argv 0 ] set dir [lindex $argv 1 ] set file [lindex $argv 2 ] set timeout 10 spawn ftp $ip expect \" Name* \" send \" zwh\\r \" expect \" Password:* \" send \" zwh\\r \" expect \" ftp\u003e* \" send \" lcd $dir\\r \" expect { \" *file \" { send_user \" local $_dir No such file or directory \";send \" quit\\r \" } \" *now* \" { send \" get $dir/$file $dir/$file\\r \"} } expect { \" *Failed \" { send_user \" remote $file No such file \";send \" quit\\r \" } \" *OK \" { send_user \" $file has been download\\r \";send \" quit\\r \"} } expect eof 运行结果如下: root@ubuntu:/home/w23ta0# ./test2.exp 192.168.1.130 /var/www/www aaa.html spawn ftp 192.168.1.130 Connected to 192.168.1.130. 220 (vsFTPd 2.0.5) Name (192.168.1.130:root): zwh 331 Please specify the password. Password: 230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. ftp\u003e lcd /var/www/www Local directory now /var/www/www ftp\u003e get /var/www/www/aaa.html /var/www/www/aaa.html local: /var/www/www/aaa.html remote: /var/www/www/aaa.html 200 PORT command successful. Consider using PASV. 150 Opening BINARY mode data connection for /var/www/www/aaa.html (66 bytes). 226 File send OK. 66 bytes received in 0.00 secs (515.6 kB/s) quit aaa.html has been download 221 Goodbye. ","date":"2012-10-10","objectID":"/posts/fc7dce9e/:0:0","tags":["expect","ssh","ftp"],"title":"linux expect自动登录ssh,ftp","uri":"/posts/fc7dce9e/"},{"categories":["Linux/Unix"],"content":"initrd.img是一个小的映象，包含一个最小的linux系统。通常的步骤是先启动内核，然后内核挂载initrd.img，并执行里面的脚本来进一步挂载各种各样的模块，然后发现真正的root分区，挂载并执行/sbin/init… initrd.img当然是可选的了，如果没有initrd.img,内核就试图直接挂载root分区。 说initrd.img文件还会提到另外一个名角—vmlinuz。vmlinuz是可引导的、压缩的内核。“vm”代表 “Virtual Memory”。Linux 支持虚拟内存，不像老的操作系统比如DOS有640KB内存的限制。Linux能够使用硬盘空间作为虚拟内存，因此得名“vm”。另外：vmlinux是未压缩的内核，vmlinuz是vmlinux的压缩文件。 为什么要initrd.img 系统内核vmlinuz被加载到内存后开始提供底层支持，在内核的支持下各种模块，服务等被加载运行。这样当然是大家最容易接受的方式，曾经的linux就是这样的运行的。假设你的硬盘是scsi 接口而你的内核又不支持这种接口时，你的内核就没有办法访问硬盘，当然也没法加载硬盘上的文件系统，怎么办？把内核加入scsi驱动源码然后重新编译出一个新的内核文件替换原来vmlinuz。 需要改变标准内核默认提供支持的例子还有很多，如果每次都需要编译内核就太麻烦了。所以后来的linux就提供了一个灵活的方法来解决这些问题—initrd.img。initrd.img文件就是个ram disk的映像文件。ramdisk是用一部分内存模拟成磁盘，让操作系统访问。ram disk是标准内核文件认识的设备(/dev/ram0)文件系统也是标准内核认识的文件系统。内核加载这个ram disk作为根文件系统并开始执行其中的”某个文件”（2.6内核是 init文件）来加载各种模块，服务等。经过一些配置和运行后，就可以去物理磁盘加载真正的root分区了，然后又是一些配置等，最后启动成功。也就是你只需要定制适合自己的 initrd.img 文件就可以了。这要比重编内核简单多了，省时省事低风险。 ","date":"2012-09-16","objectID":"/posts/9390f1b0/:0:0","tags":["initrd","vmlinux","vmlinuz"],"title":"核心文件initrd.img、vmlinux 和vmlinuz","uri":"/posts/9390f1b0/"},{"categories":["Linux/Unix"],"content":"在管理服务器时，我通常选择使用 SSH 方式。以下是一则 SSH 使用技巧，希望对你有用。 创建快捷方式 当你在执行 ssh 命令登录服务器时，有没有被需要输入命令后面的一长串参数感到厌烦呢？比如，名为 serveradmin@domain.com 的用户要登录到 example.com 主机上，需执行： ssh serveradmin@domain.com@example.com 你当然可以使用 alias，但 SSH 本身也提供有相应的解决方案──你可以为需要经常访问的远程主机创建快捷方式。 找找看你的用户主目录下是否有 .ssh，若没有，则使用 mkdir 创建一个； 使用你喜欢的文本编辑器（如 Vim）来创建 config 配置文件： vim ~/.ssh/config 仍以前面的例子来说明，假设我要创建的快捷方式名为 lt，则加入下面的内容，其中 HostName 为主机名，User 为用户名： Host lt HostName example.com User serveradmin@domain.com 保存编辑。 现在，你只要执行ssh lt就可以了。 ","date":"2012-09-15","objectID":"/posts/b42cf71/:0:0","tags":["ssh"],"title":"SSH 使用技巧一则:创建快捷方式","uri":"/posts/b42cf71/"},{"categories":["Web相关","Nginx"],"content":"最近抽出了一点时间，研究了使用.htaccess 开启网页gzip压缩的问题。 大家都知道网页打开速度与dns，服务器，页面代码，网站结构，统统都相关。 网页压缩的问题。因为本人的大部分网站都是PHP的，所以，基本需要.htaccess来解决。 在.htaccess文件中请加入以下代码即可： \u003cIfModule mod_deflate.c\u003e ExpiresActive On ExpiresDefault A600 ExpiresByType image/x-icon A2592000 ExpiresByType application/x-javascript A2592000 ExpiresByType text/css A604800 ExpiresByType image/gif A2592000 ExpiresByType image/png A2592000 ExpiresByType image/jpeg A2592000 ExpiresByType text/plain A86400 ExpiresByType application/x-shockwave-flash A2592000 ExpiresByType video/x-flv A2592000 ExpiresByType application/pdf A2592000 ExpiresByType text/html A600 # Insert filters AddOutputFilter DEFLATE html xml php js css AddOutputFilterByType DEFLATE text/plain AddOutputFilterByType DEFLATE text/html AddOutputFilterByType DEFLATE text/xml AddOutputFilterByType DEFLATE text/css AddOutputFilterByType DEFLATE application/xml AddOutputFilterByType DEFLATE application/xhtml+xml AddOutputFilterByType DEFLATE application/rss+xml AddOutputFilterByType DEFLATE application/javascript AddOutputFilterByType DEFLATE application/x-javascript AddOutputFilterByType DEFLATE application/x-httpd-php AddOutputFilterByType DEFLATE application/x-httpd-fastphp AddOutputFilterByType DEFLATE image/svg+xml # Drop problematic browsers BrowserMatch ^Mozilla/4 gzip-only-text/html BrowserMatch ^Mozilla/4.0[678] no-gzip BrowserMatch !no-gzip !gzip-only-text/html # Make sure proxies don't deliver the wrong conten Header append Vary User-Agent env=!dont-vary \u003c/IfModule\u003e 如果没有这个文件，可以自己新建。然后上传到空间就可以了。 这时候，你可以使用站长工具测试一下。 推荐chinaz.com站长工具。 ","date":"2012-08-24","objectID":"/posts/4ff7f2ee/:0:0","tags":["htaccess"],"title":".htaccess实现网页Gzip压缩","uri":"/posts/4ff7f2ee/"},{"categories":["Web相关","Apache"],"content":"国内的很多Linux型主机默认是不开启.htaccess的，从而导致不支持伪静态。而国外的虚拟主机基本上都是支持此服务的，我曾经问过国内的主机提供商为何不开启.htaccess服务，他们的回答很可笑，说是减轻服务器的负担，呵，这真是符合了中国的国情，真让你不知以何种语言反击之。 这里给一些菜鸟扫扫盲，很多站长都单纯的以为.htaccess就是伪静态，把.htaccess当成伪静态的代名词，以为.htaccess就起到.htaccess的作用，其实它的作用比你想象的大得多，除了伪静态，还有我们熟知的404啊、301跳转啊等，都可以通过.htaccess来实现，下面来给大家介绍一下如何在Linux型主机下开启.htaccess的支持，前提你有这个权限，一般这个针对的是服务器或者VPS，虚拟主机基本上是没门，除非你要求提供商帮你开启。另一种情况是有些童鞋在本地搭建PHP+MySQL+Apache的时候用得着此方法，本地的一键安装包有xampp 和phpnow等，我个人推荐使用phpnow，简单易用，完全傻瓜式。如果你使用phpnow搭建的话你就不用往下看了，因为默认是开启的。 方法如下： 第一：在Apache文件夹下的conf文件夹中找到httpd.conf，记事本或者类似的编辑工具打开后Ctrl+F查找 LoadModule rewrite_module，找到 LoadModule rewrite_module modules/mod_rewrite.so 所在的那一行，确定这一行前面没有#，就说明已经加载了伪静态模块，假如这一行前面有#，请去掉，phpnow安装后默认是没有#的。 第二：让Apache服务器支持.htaccess，如何让自己的本地Apache服务器支持\".htaccess\"呢?其实只要简单修改一下 apache的httpd.conf设置就可以让支持.htaccess了。打开httpd.conf文件，用文本编辑器打开后,查找 Options FollowSymLinks AllowOverride None 改为 Options FollowSymLinks AllowOverride All 是确定是否已经加载了伪静态模块 是修改这一处的设置。操作完后测试一下.htaccess是否已生效，如还未生效，请重启Apache服务。 ","date":"2012-08-20","objectID":"/posts/28e6d681/:0:0","tags":["htaccess"],"title":"让Linux主机开启.htaccess支持","uri":"/posts/28e6d681/"},{"categories":["Linux/Unix"],"content":"vmlinuz 是一个为内核映像， vmlinuz里面有gzip的一段代码。 initrd.img 是作为避免在vmlinuz里编译所有的驱动模块，所以使用了一个中间层的技术 initrd有两种格式，一种是较早的2.4.x中的image-initrd格式，里面以/linuxrc为主导。另一种是cpio-initrd 看了网上的资料，想学着看看 initrd里是什么个样子 cp /boot/initrd.imgxxx initrd.img.gz gunzip initrd.img.gz # 这个如果不加后缀gz 就得使用 gunzip -S .img xx.img mkdir initrd mv initrd.img.gz initrd cd initrd cpio -ivmd \u003c initrd.img #用cpio格式打的包，释放出来，ok，就可以看到了。 编译内核： centos 6.2： make mrproper // 新内核不用，检查依赖对不对 make menuconfig //配置选项 make modules_install //安装modules /lib/modules 对应的文件夹 make install // 将 vmlinuz 和 initrd.img 放到 /boot 下，并填写对应的 /boot/grub/menu.lst 自己可以看看 ","date":"2012-08-16","objectID":"/posts/96df565/:0:0","tags":["initrd.img","vmlinuz"],"title":"Linux initrd.img 解压分析","uri":"/posts/96df565/"},{"categories":["Windows"],"content":"今天看了一个帖子，win7系统通过笔记本的无线网卡，启用虚拟Wifi功能共享上网，自己尝试了一下，感觉很好用，至少没有无线路由的自己，手机可以上wifi了，更新软件玩微信等等，都方便多了，好了，废话不多说，先介绍下吧。 启动承载网络 查看笔记本网卡是否支持”启动承载网络”的功能，使用管理员运行cmd命令， netsh wlan show driver 显示无线网卡驱动信息，如下图所示，如果功能是”否”，说明你的无线网卡不支持这个功能，如果为”是”就继续跟我尝试这个功能吧。【确定的方法，还可以查看任务管理器，无线网卡的”驱动程序详细信息”，里面是否有vwifibus.sys驱动程序文件，大家也可以通过这个方法确定】 设置SSID和密码 确定你的无线网卡有这个功能后，开始启动virtaul wifi.同样是命令行 netsh wlan set hostednetwork mode=allow ssid=Windows7AP key=password 启动后，可以查看”网络共享中心”-“更改适配器设置”，里面会多出一个”Microsoft Virtual WiFi Miniport Adapter”，你也可以重命名这个网络连接，当然这个对于网络连接是没有任何影响的，我重命名改成了Virtual WiFi，主要是之前看着太长了，哈哈。 开启共享上网 打开”网络共享中心”-“更改适配器设置”【在左侧的栏里面】-找到你现在上网用的连接，右键属性，点击共享的标签，勾选第一个选项卡【如下图】，在下面的输入框点击，弹出列表，选择你的Microsoft Virtual WiFi Miniport Adapter网络连接，我这里刚刚重命名了，所以选择Virtual WiFi，确定。 打开无线网 在命令行中输入：netsh wlan start hostednetwork 启动后，用手机搜这个无线网，就可以咯，哈哈，我现在已经通过这个方式上网了，如果你只有一台电脑能通过网线上网，又有其它需求，不妨试一下。当然，这一项有可能报错，是因为你没有启动无线网卡，哥、通过无线网卡上网，不启动怎么行呢？！好了，不废话了，我去玩微信了，大家拜咯~ ","date":"2012-07-10","objectID":"/posts/19719f8d/:0:0","tags":["windows","wifi"],"title":"Win7笔记本电脑启用虚拟Wifi共享上网","uri":"/posts/19719f8d/"},{"categories":["数据库","Mysql"],"content":"Mysql服务的启动和停止 service mysql start service mysql stop 登陆Mysql 语法如下： mysql -u用户名 -p用户密码 键入命令 mysql -uroot -p 回车后提示你输入密码，输入12345，然后回车即可进入到mysql中了，mysql的提示符是： mysql\u003e 注意，如果是连接到另外的机器上，则需要加入一个参数-h机器IP 增加新用户 格式：grant 权限 on 数据库.* to 用户名@登录主机 identified by “密码” 例如：增加一个用户user1密码为password1，让其可以在本机上登录， 并对所有数据库有查询、插入、修改、删除的权限。 首先用以root用户连入mysql，然后键入以下命令： grant select,insert,update,delete on *.* to user1@localhost Identified by \"password1\"; 如果希望该用户能够在任何机器上登陆mysql，则将localhost改为\"%\"。 grant select,insert,update,delete on *.* to user1@% Identified by \"password1\"; 如果你不想user1有密码，可以再打一个命令将密码去掉。 grant select,insert,update,delete on mydb.* to user1@localhost identified by \"\"; 操作数据库 登录到mysql中，然后在mysql的提示符下运行下列命令，每个命令以分号结束。 显示数据库列表。 show databases; 缺省有两个数据库：mysql和test。 mysql库存放着mysql的系统和用户权限信息，我们改密码和新增用户，实际上就是对这个库进行操作。 显示库中的数据表： use mysql; show tables; 显示数据表的结构： describe 表名; 建库与删库： create database 库名; drop database 库名; 建表与删表： use 库名; create table 表名(字段列表); drop table 表名; 清空表中记录： delete from 表名; 显示表中的记录： select * from 表名; 导出和导入数据 导出数据： mysqldump –opt test \u003e mysql.test 即将数据库test数据库导出到mysql.test文件，后者是一个文本文件 如：mysqldump -u root -p123456 –databases dbname \u003e mysql.dbname 就是把数据库dbname导出到文件mysql.dbname中。 导入数据: mysqlimport -u root -p123456 \u003c mysql.dbname。 不用解释了吧。 将文本数据导入数据库: 文本数据的字段数据之间用tab键隔开。 use test; load data local infile \"文件名\" into table 表名; 实例 使用SHOW语句找出在服务器上当前存在什么数据库 mysql\u003e SHOW DATABASES; 创建一个数据库MYSQLDATA mysql\u003e CREATE DATABASE MYSQLDATA; 选择你所创建的数据库 mysql\u003e USE MYSQLDATA; 按回车键出现Database changed 时说明操作成功! 查看现在的数据库中存在什么表 mysql\u003e SHOW TABLES; 创建一个数据库表 mysql\u003e CREATE TABLE MYTABLE (name VARCHAR(20), sex CHAR(1)); 显示表的结构： mysql\u003e DESCRIBE MYTABLE; 往表中加入记录 mysql\u003e insert into MYTABLE values (\"w23ta0\",\"M\"); 用文本方式将数据装入数据库表中(例如D:/mysql.txt) mysql\u003e LOAD DATA LOCAL INFILE \"D:/mysql.txt\" INTO TABLE MYTABLE; 导入.sql文件命令(例如D:/mysql.sql) mysql\u003euse database; mysql\u003esource d:/mysql.sql; 删除表 mysql\u003edrop TABLE MYTABLE; 清空表 mysql\u003edelete from MYTABLE; 更新表中数据 mysql\u003eupdate MYTABLE set sex=\"f\" where name=’w23ta0'; 备份数据库 mysqldump -u root 库名\u003exxx.data 连接到远程主机上的MYSQL 假设远程主机的IP为：110.110.110.110，用户名为root,密码为abcd123。则键入以下命令： mysql -h110.110.110.110 -uroot -pabcd123 注意:u与root可以不用加空格，其它也一样 退出MYSQL命令： exit (回车) ","date":"2012-06-30","objectID":"/posts/6e8d2cb0/:0:0","tags":["mysql"],"title":"Mysql常用命令行大全","uri":"/posts/6e8d2cb0/"},{"categories":["Linux/Unix"],"content":"有些朋友购买了vps后由于他是从原来的win主机搬迁过来，备份打包的数据是rar格式的，那在CentOS下怎么解压呢？ Google一下，找到解决办法： wget http://www.rarsoft.com/rar/rarlinux-3.9.3.tar.gz tar -xvf rarlinux-3.9.3.tar.gz cd rar make 看见下面这些信息就是安装成功了 mkdir -p /wp-content/local/bin mkdir -p /wp-content/local/lib cp rar unrar /wp-content/local/bin cp rarfiles.lst /etc cp default.sfx /wp-content/local/lib 但有的时候在运行命令rar时,出现下面这个问题: rar: /lib/i686/nosegneg/libc.so.6: version `GLIBC_2.7′ not found (required by rar) 解决办法： cp rar_static /wp-content/local/bin/rar 使用举例 rar x lvtao.rar //解压 lvtao.rar 到当前目录 rar lvtao.rar ./lvtao.net/ //将 lvtao.net 目录打包为lvtao.rar ","date":"2012-06-11","objectID":"/posts/e41f398b/:0:0","tags":["centos","rar"],"title":"让Centos支持打包、解压RAR文件包","uri":"/posts/e41f398b/"},{"categories":["Linux/Unix"],"content":"公司买的Dell R410的机器，装的Debian的系统，安装过程中会提示找不到网络设备驱，去Dell 官方查看R410网卡驱动没有找到Debian版本的（Redhat的倒是有），上网查资料得知Debian从5开始就不支持Broadcom的网卡驱动（偶装的就是5,，悲催啊）。去broadcom下载源码包netxtreme2-5.0.17.tar.gz。 下载地址：http://www.broadcom.com/support/ethernet_nic/downloaddrivers.php 首先安装操作系统，我装的是debian-6.0.2.1-amd64版本的。安装过程中提示找不到网络设备驱动，不用管它，直接继续安装。系统装好后ifconfig查看网卡信息，果然只能看到lo，找不到eth0的信息。 把下载的驱动包netxtreme2-5.0.17.tar.gz 通过U盘拷贝到系统并解压缩。 #mount /dev/sdb1 /mnt #cp netxtreme2-5.0.17.tar.gz /home #cd /home #tar -zxvf netxtreme2-5.0.17.tar.gz 检查系统有没有安装make和gcc #make -v #gcc -v 安装了的话会输出版本信息，没有安装的话会提示commond not found。（确定系统安装了make和gcc的可以跳转到第六步，没有装的继续） 4. 创建本地源 由于gcc的依赖关系比较多，决定做个本地源，先把安装盘挂载上，把里面的软件包拷贝出来。 #mount /dev/cdrom /mnt #mkdir –p /wp-content/local/debian/pools #cp -R /mnt/pools /wp-content/local/debian/pools #mkdir –p /wp-content/local/debian/dists/sid/main/binary-amd64 #cd /wp-content/local/debian/pools/main/d/dpkg #dpkg –I dpkg-dev_1.15.8.11_all.deb；dpkg –I libdpkg-perl_1.15.8.11_all.deb #ls -1 pools | sed ‘s/_.*$/ extra BOGUS/’ | uniq \u003e override (把pools目录下所有的deb包包名写入文件override中) #dpkg-scanpackages pools override \u003e dists/sid/main/binary-amd64/Packages (把所有包的包名、版本号、依赖关系等信息写入文件Packages中) #vi /dists/sid/main/Release 输入以下内容： Archive: sid Version: lenny Component: main Origin: Local Label: Local Architecture: amd64 #echo \"deb file:/wp-content/local/debian sid main\" \u003e\u003e /etc/apt/source.list 安装make和gcc。 #apt-get install update #apt-get install make #apt-get install gcc 编译 #cd /home/netxtreme2-6.2.23\\netxtreme2-6.2.23\\bnx2-2.0.23b\\src #make 不排除个别人品好的直接make成功，我反正是失败了。错误提示如下: make -C SUBDIRS=/wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src modules make: *** SUBDIRS=/wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src: No such file or directory. Stop. make: *** [default] Error 2 No such file or directory，找不到文件或目录。英语好的建议直接看Makefile，英语不好的,还是google一下吧！ 我找到的解释为： 发现(/lib/modules/$(KVER)/build )路径并不存在,如下： #ls /lib/modules/2.6.26-2-686/build ls: cannot access /lib/modules/2.6.26-2-686/build: No such file or directory 对应的解决办法是安装以下包: gcc-4.1-base_4.1.2-25_amd64.deb cpp-4.1_4.1.2-25_amd64.deb linux-kbuild-2.6.26_2.6.26-3_amd64.deb linux-headers-2.6.26-2-common_2.6.26-21lenny3_amd64.deb linux-headers-2.6.26-2-amd64_2.6.26-21lenny3_amd64.deb binutils_2.18.1~cvs20080103-7_amd64.deb 全部装好后，重新make。正常人此时都应该make成功了。 Make-C/lib/modules/2.6.26-2-amd64/build SUBDIRS=/wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src modules make[1]: Entering directory /wp-content/src/linux-headers-2.6.26-2-amd64' CC [M] /wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src/bnx2.o CC [M] /wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src/cnic.o Building modules, stage 2. MODPOST 2 modules CC /wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src/bnx2.mod.o LD [M] /wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src/bnx2.ko CC /wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src/cnic.mod.o LD [M] /wp-content/local/src/network/netxtreme2-5.0.17/bnx2-1.9.20b/src/cnic.ko make[1]: Leaving directory /wp-content/src/linux-headers-2.6.26-2-amd64′ 挂在bnx2.ko模块 Make成功后再src目录下应该有个bnx2.ko模块。 #rmmod bnx2.ko 把系统原来的模块删掉 #insmod bnx2.ko 加载我们刚刚编译好的模块。 #cp bnx2.ko /lib/modules/2.6.26-2-amd64/kernel/drivers/net/ 配置好网络地址和DNS后，随便ping个地址。Ok，可以ping同了，编译完成，reboot下再次进入系统，ifconfig又只剩下lo了。 编辑开机脚本。 #vi eth0_start.sh #!/bin/sh cd /home/netxtreme2-6.2.23\\netxtreme2-6.2.23\\bnx2-2.0.23b\\src rmmod bnx2.ko insmod bnx2.ko /etc/init.d/networking restart #cat eth0_start.sh \u003e\u003e /etc/init.d/rc.local 再次reboot，开机进入系统，ifconfig搞定！ ","date":"2012-06-10","objectID":"/posts/d8443074/:0:0","tags":["dell","r410","debian"],"title":"Dell R410 debian 64位网卡驱动","uri":"/posts/d8443074/"}]